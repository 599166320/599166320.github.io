[{"title":"16.springboot + mybatis + 多数据源 （AOP实现）","date":"2017-11-16T15:10:37.000Z","path":"2017/11/16/spring-boot-16-multi-source-aop/","text":"1、ShopDao package com.xxx.firstboot.dao; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.stereotype.Repository; import com.xxx.firstboot.domain.Shop; import com.xxx.firstboot.mapper.ShopMapper; @Repository public class ShopDao { @Autowired private ShopMapper mapper; /** * 获取shop */ public Shop getShop(int id) { return mapper.getShop(id); } } 说明：只是去掉了设置数据源key的那一句代码 2、DataSourceAspect package com.xxx.firstboot.common.datasource; import org.aspectj.lang.JoinPoint; import org.aspectj.lang.annotation.Aspect; import org.aspectj.lang.annotation.Before; import org.springframework.stereotype.Component; import com.xxx.firstboot.dao.ShopDao; @Aspect @Component public class DataSourceAspect { @Before(&quot;execution(* com.xxx.firstboot.dao.*.*(..))&quot;) public void setDataSourceKey(JoinPoint point){ //连接点所属的类实例是ShopDao if(point.getTarget() instanceof ShopDao){ DatabaseContextHolder.setDatabaseType(DatabaseType.mytestdb2); }else{//连接点所属的类实例是UserDao（当然，这一步也可以不写，因为defaultTargertDataSource就是该类所用的mytestdb） DatabaseContextHolder.setDatabaseType(DatabaseType.mytestdb); } } // @Around(&quot;execution(* com.xxx.firstboot.dao.*.*(..))&quot;) // public Object setDataSourceKeyByAround(ProceedingJoinPoint point) throws Throwable{ // if(point.getTarget() instanceof ShopDao){ // DatabaseContextHolder.setDatabaseType(DatabaseType.mytestdb2); // }else{//连接点所属的类实例是UserDao（当然，这一步也可以不写，因为defaultTargertDataSource就是该类所用的mytestdb） // DatabaseContextHolder.setDatabaseType(DatabaseType.mytestdb); // } // return point.proceed();//执行目标方法 // } } 说明：列出了两种切面方法，在这里推荐使用前者，原因： @Around：需要写执行目标方法的那一行代码，而这一行代码可能会抛异常，还需要抛出或捕获 对于切点表达式，可以抽取出来，进行重复利用。如上代码可以改为如下： package com.xxx.firstboot.common.datasource; import org.aspectj.lang.JoinPoint; import org.aspectj.lang.annotation.Aspect; import org.aspectj.lang.annotation.Before; import org.aspectj.lang.annotation.Pointcut; import org.springframework.stereotype.Component; import com.xxx.firstboot.dao.ShopDao; @Aspect @Component public class DataSourceAspect { /** * 使用空方法定义切点表达式 */ @Pointcut(&quot;execution(* com.xxx.firstboot.dao.*.*(..))&quot;) public void declareJointPointExpression() { } /** * 使用定义切点表达式的方法进行切点表达式的引入 */ @Before(&quot;declareJointPointExpression()&quot;) public void setDataSourceKey(JoinPoint point) { // 连接点所属的类实例是ShopDao if (point.getTarget() instanceof ShopDao) { DatabaseContextHolder.setDatabaseType(DatabaseType.mytestdb2); } else {// 连接点所属的类实例是UserDao（当然，这一步也可以不写，因为defaultTargertDataSource就是该类所用的mytestdb） DatabaseContextHolder.setDatabaseType(DatabaseType.mytestdb); } } } 注意：该切点表达式也可以用在其他切面类中，引入的时候使用”全类名.切点方法名()”，例：@Before(“com.xxx.firstboot.common.datasource.DataSourceAspect.declareJointPointExpression()”)","tags":[{"name":"java","slug":"java","permalink":"http://dennis.pathto.top/tags/java/"},{"name":"spring","slug":"spring","permalink":"http://dennis.pathto.top/tags/spring/"},{"name":"spring-boot","slug":"spring-boot","permalink":"http://dennis.pathto.top/tags/spring-boot/"}]},{"title":"How to Install Oracle Java 8 on Ubuntu 12.04 LTS","date":"2017-11-16T15:10:37.000Z","path":"2017/11/16/ubuntu-0-ubuntu-install-jdk8/","text":"Step #1: Install Capability to Manage Repositoriespython-software-properties allows for easy management of your distribution and independent repositories: sudo apt-get install python-software-properties Step #2: Add the WebUpd8 Team Personal Package Archive (PPA)Add the PPA: sudo apt-add-repository ppa:webupd8team/java Step #3: The InstallationAs a matter of best practice we’ll update our packages: sudo apt-get update then let’s install Oracle Java 8 with the PPA installer: sudo apt-get install oracle-java8-installer tep #4: Verify InstallationNow verify that Java is installed and is of version 1.8.x: java -version Your result should be similar to: java version &quot;1.8.0_45&quot; Java(TM) SE Runtime Environment (build 1.8.0_45-b14) Java HotSpot(TM) 64-Bit Server VM (build 25.45-b02, mixed mode)","tags":[{"name":"linux","slug":"linux","permalink":"http://dennis.pathto.top/tags/linux/"},{"name":"ubuntu","slug":"ubuntu","permalink":"http://dennis.pathto.top/tags/ubuntu/"}]},{"title":"Ubuntu 安装 端口转发工具rinetd","date":"2017-11-16T15:10:37.000Z","path":"2017/11/16/ubuntu-0-port-forward/","text":"1.下载 第一中方式 用 apt-get install rinetd 或者从官网下载 2.配置，端口转发的配置在 /etc/rinetd.conf配置规则 0.0.0.0 8080 172.19.94.3 8080 0.0.0.0 2222 192.168.0.103 3389 1.2.3.4 80 192.168.0.10 80 说明一下（0.0.0.0表示本机绑定所有可用地址） 将所有发往本机8080端口的请求转发到172.19.94.3的8080端口 将所有发往本机2222端口的请求转发到192.168.0.103的3389端口 将所有发往1.2.3.4的80端口请求转发到192.168.0.10的80端口 命令格式是 bindaddress bindport connectaddress connectport 绑定的地址 绑定的端口 连接的地址 连接的端口 或 [Source Address] [Source Port] [Destination Address] [Destination Port] 源地址 源端口 目的地址 目的端口 3.打开 启动程序 pkill rinetd ##关闭进程 rinetd -c /etc/rinetd.conf ##启动转发 把这条命令加到/etc/rc.local里面就可以开机自动运行 好像不添加也行 rj.baidu.com/soft/detail/10203.html","tags":[{"name":"linux","slug":"linux","permalink":"http://dennis.pathto.top/tags/linux/"},{"name":"ubuntu","slug":"ubuntu","permalink":"http://dennis.pathto.top/tags/ubuntu/"}]},{"title":"15.spring-boot多数据源","date":"2017-11-16T15:10:33.000Z","path":"2017/11/16/spring-boot-15-multi-source/","text":"在实际开发中，我们一个项目可能会用到多个数据库，通常一个数据库对应一个数据源。 代码结构： image 简要原理： 1）DatabaseType列出所有的数据源的key—key 2）DatabaseContextHolder是一个线程安全的DatabaseType容器，并提供了向其中设置和获取DatabaseType的方法 3）DynamicDataSource继承AbstractRoutingDataSource并重写其中的方法determineCurrentLookupKey()，在该方法中使用DatabaseContextHolder获取当前线程的DatabaseType 4）MyBatisConfig中生成2个数据源DataSource的bean—value 5）MyBatisConfig中将1）和4）组成的key-value对写入到DynamicDataSource动态数据源的targetDataSources属性（当然，同时也会设置2个数据源其中的一个为DynamicDataSource的defaultTargetDataSource属性中） 6）将DynamicDataSource作为primary数据源注入到SqlSessionFactory的dataSource属性中去，并且该dataSource作为transactionManager的入参来构造DataSourceTransactionManager 7）使用的时候，在dao层或service层先使用DatabaseContextHolder设置将要使用的数据源key，然后再调用mapper层进行相应的操作，建议放在dao层去做（当然也可以使用spring aop+自定注解去做） 注意：在mapper层进行操作的时候，会先调用determineCurrentLookupKey()方法获取一个数据源（获取数据源：先根据设置去targetDataSources中去找，若没有，则选择defaultTargetDataSource），之后在进行数据库操作。 1、假设有两个数据库，配置如下 application.properties #the first datasource jdbc.driverClassName = com.mysql.jdbc.Driver jdbc.url = jdbc:mysql://xxx:3306/mytestdb?zeroDateTimeBehavior=convertToNull&amp;amp;useUnicode=true&amp;amp;characterEncoding=utf-8 jdbc.username = root jdbc.password = 123 #the second datasource jdbc2.driverClassName = com.mysql.jdbc.Driver jdbc2.url = jdbc:mysql://xxx:3306/mytestdb2?zeroDateTimeBehavior=convertToNull&amp;amp;useUnicode=true&amp;amp;characterEncoding=utf-8 jdbc2.username = root jdbc2.password = 123 说明：在之前的配置的基础上，只增加了上述的第二个数据源。 2、DatabaseType package com.xxx.firstboot.common.datasource; /** * 列出所有的数据源key（常用数据库名称来命名） * 注意： * 1）这里数据源与数据库是一对一的 * 2）DatabaseType中的变量名称就是数据库的名称 */ public enum DatabaseType { mytestdb,mytestdb2 } 作用：列举数据源的key。 3、DatabaseContextHolder package com.xxx.firstboot.common.datasource; /** * 作用： * 1、保存一个线程安全的DatabaseType容器 */ public class DatabaseContextHolder { private static final ThreadLocal&lt;DatabaseType&gt; contextHolder = new ThreadLocal&lt;&gt;(); public static void setDatabaseType(DatabaseType type){ contextHolder.set(type); } public static DatabaseType getDatabaseType(){ return contextHolder.get(); } } 作用：构建一个DatabaseType容器，并提供了向其中设置和获取DatabaseType的方法 4、DynamicDataSource package com.xxx.firstboot.common.datasource; import org.springframework.jdbc.datasource.lookup.AbstractRoutingDataSource; /** * 动态数据源（需要继承AbstractRoutingDataSource） */ public class DynamicDataSource extends AbstractRoutingDataSource { protected Object determineCurrentLookupKey() { return DatabaseContextHolder.getDatabaseType(); } } 作用：使用DatabaseContextHolder获取当前线程的DatabaseType 5、MyBatisConfig package com.xxx.firstboot.common; import java.util.HashMap; import java.util.Map; import java.util.Properties; import javax.sql.DataSource; import org.apache.ibatis.session.SqlSessionFactory; import org.mybatis.spring.SqlSessionFactoryBean; import org.mybatis.spring.annotation.MapperScan; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.beans.factory.annotation.Qualifier; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; import org.springframework.context.annotation.Primary; import org.springframework.core.env.Environment; import org.springframework.core.io.support.PathMatchingResourcePatternResolver; import org.springframework.jdbc.datasource.DataSourceTransactionManager; import com.alibaba.druid.pool.DruidDataSourceFactory; import com.xxx.firstboot.common.datasource.DatabaseType; import com.xxx.firstboot.common.datasource.DynamicDataSource; /** * springboot集成mybatis的基本入口 1）创建数据源(如果采用的是默认的tomcat-jdbc数据源，则不需要) * 2）创建SqlSessionFactory 3）配置事务管理器，除非需要使用事务，否则不用配置 */ @Configuration // 该注解类似于spring配置文件 @MapperScan(basePackages = &quot;com.xxx.firstboot.mapper&quot;) public class MyBatisConfig { @Autowired private Environment env; /** * 创建数据源(数据源的名称：方法名可以取为XXXDataSource(),XXX为数据库名称,该名称也就是数据源的名称) */ @Bean public DataSource myTestDbDataSource() throws Exception { Properties props = new Properties(); props.put(&quot;driverClassName&quot;, env.getProperty(&quot;jdbc.driverClassName&quot;)); props.put(&quot;url&quot;, env.getProperty(&quot;jdbc.url&quot;)); props.put(&quot;username&quot;, env.getProperty(&quot;jdbc.username&quot;)); props.put(&quot;password&quot;, env.getProperty(&quot;jdbc.password&quot;)); return DruidDataSourceFactory.createDataSource(props); } @Bean public DataSource myTestDb2DataSource() throws Exception { Properties props = new Properties(); props.put(&quot;driverClassName&quot;, env.getProperty(&quot;jdbc2.driverClassName&quot;)); props.put(&quot;url&quot;, env.getProperty(&quot;jdbc2.url&quot;)); props.put(&quot;username&quot;, env.getProperty(&quot;jdbc2.username&quot;)); props.put(&quot;password&quot;, env.getProperty(&quot;jdbc2.password&quot;)); return DruidDataSourceFactory.createDataSource(props); } /** * @Primary 该注解表示在同一个接口有多个实现类可以注入的时候，默认选择哪一个，而不是让@autowire注解报错 * @Qualifier 根据名称进行注入，通常是在具有相同的多个类型的实例的一个注入（例如有多个DataSource类型的实例） */ @Bean @Primary public DynamicDataSource dataSource(@Qualifier(&quot;myTestDbDataSource&quot;) DataSource myTestDbDataSource, @Qualifier(&quot;myTestDb2DataSource&quot;) DataSource myTestDb2DataSource) { Map&lt;Object, Object&gt; targetDataSources = new HashMap&lt;&gt;(); targetDataSources.put(DatabaseType.mytestdb, myTestDbDataSource); targetDataSources.put(DatabaseType.mytestdb2, myTestDb2DataSource); DynamicDataSource dataSource = new DynamicDataSource(); dataSource.setTargetDataSources(targetDataSources);// 该方法是AbstractRoutingDataSource的方法 dataSource.setDefaultTargetDataSource(myTestDbDataSource);// 默认的datasource设置为myTestDbDataSource return dataSource; } /** * 根据数据源创建SqlSessionFactory */ @Bean public SqlSessionFactory sqlSessionFactory(DynamicDataSource ds) throws Exception { SqlSessionFactoryBean fb = new SqlSessionFactoryBean(); fb.setDataSource(ds);// 指定数据源(这个必须有，否则报错) // 下边两句仅仅用于*.xml文件，如果整个持久层操作不需要使用到xml文件的话（只用注解就可以搞定），则不加 fb.setTypeAliasesPackage(env.getProperty(&quot;mybatis.typeAliasesPackage&quot;));// 指定基包 fb.setMapperLocations( new PathMatchingResourcePatternResolver().getResources(env.getProperty(&quot;mybatis.mapperLocations&quot;)));// return fb.getObject(); } /** * 配置事务管理器 */ @Bean public DataSourceTransactionManager transactionManager(DynamicDataSource dataSource) throws Exception { return new DataSourceTransactionManager(dataSource); } } 作用： 通过读取application.properties文件生成两个数据源（myTestDbDataSource、myTestDb2DataSource） 使用以上生成的两个数据源构造动态数据源dataSource @Primary：指定在同一个接口有多个实现类可以注入的时候，默认选择哪一个，而不是让@Autowire注解报错（一般用于多数据源的情况下） @Qualifier：指定名称的注入，当一个接口有多个实现类的时候使用（在本例中，有两个DataSource类型的实例，需要指定名称注入） @Bean：生成的bean实例的名称是方法名（例如上边的@Qualifier注解中使用的名称是前边两个数据源的方法名，而这两个数据源也是使用@Bean注解进行注入的） 通过动态数据源构造SqlSessionFactory和事务管理器（如果不需要事务，后者可以去掉） 6、使用 ShopMapper: package com.xxx.firstboot.mapper; import org.apache.ibatis.annotations.Param; import org.apache.ibatis.annotations.Result; import org.apache.ibatis.annotations.Results; import org.apache.ibatis.annotations.Select; import com.xxx.firstboot.domain.Shop; public interface ShopMapper { @Select(&quot;SELECT * FROM t_shop WHERE id = #{id}&quot;) @Results(value = { @Result(id = true, column = &quot;id&quot;, property = &quot;id&quot;), @Result(column = &quot;shop_name&quot;, property = &quot;shopName&quot;) }) public Shop getShop(@Param(&quot;id&quot;) int id); } ShopDao: package com.xxx.firstboot.dao; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.stereotype.Repository; import com.xxx.firstboot.common.datasource.DatabaseContextHolder; import com.xxx.firstboot.common.datasource.DatabaseType; import com.xxx.firstboot.domain.Shop; import com.xxx.firstboot.mapper.ShopMapper; @Repository public class ShopDao { @Autowired private ShopMapper mapper; /** * 获取shop */ public Shop getShop(int id) { DatabaseContextHolder.setDatabaseType(DatabaseType.mytestdb2); return mapper.getShop(id); } } 注意：首先设置了数据源的key，然后调用mapper（在mapper中会首先根据该key从动态数据源中查询出相应的数据源，之后取出连接进行数据库操作） ShopService: package com.xxx.firstboot.service; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.stereotype.Service; import com.xxx.firstboot.dao.ShopDao; import com.xxx.firstboot.domain.Shop; @Service public class ShopService { @Autowired private ShopDao dao; public Shop getShop(int id) { return dao.getShop(id); } } ShopController: package com.xxx.firstboot.web; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.web.bind.annotation.RequestMapping; import org.springframework.web.bind.annotation.RequestMethod; import org.springframework.web.bind.annotation.RequestParam; import org.springframework.web.bind.annotation.RestController; import com.xxx.firstboot.domain.Shop; import com.xxx.firstboot.service.ShopService; import io.swagger.annotations.Api; import io.swagger.annotations.ApiOperation; @RestController @RequestMapping(&quot;/shop&quot;) @Api(&quot;shopController相关api&quot;) public class ShopController { @Autowired private ShopService service; @ApiOperation(&quot;获取shop信息,测试多数据源&quot;) @RequestMapping(value = &quot;/getShop&quot;, method = RequestMethod.GET) public Shop getShop(@RequestParam(&quot;id&quot;) int id) { return service.getShop(id); } } 补：其实DatabaseContextHolder和DynamicDataSource完全可以合为一个类 遗留：在实际开发中，一个dao类只会用到一个数据源，如果dao类中的方法很多的话，每一个方法前边都要添加一个设置数据源的一句话，代码有些冗余，可以使用AOP切面。 具体的实现方式见 第九章 springboot + mybatis + 多数据源 （AOP实现） 很多朋友反映遇到数据源循环依赖的问题，可以试一下将MyBatisConfig中的相关代码换成这样试试 @Bean public SqlSessionFactory sqlSessionFactory(@Qualifier(&quot;myTestDbDataSource&quot;) DataSource myTestDbDataSource, @Qualifier(&quot;myTestDb2DataSource&quot;) DataSource myTestDb2DataSource) throws Exception{ SqlSessionFactoryBean fb = new SqlSessionFactoryBean(); fb.setDataSource(this.dataSource(myTestDbDataSource, myTestDb2DataSource)); fb.setTypeAliasesPackage(env.getProperty(&quot;mybatis.typeAliasesPackage&quot;)); fb.setMapperLocations(new PathMatchingResourcePatternResolver().getResources(env.getProperty(&quot;mybatis.mapperLocations&quot;))); return fb.getObject(); }","tags":[{"name":"java","slug":"java","permalink":"http://dennis.pathto.top/tags/java/"},{"name":"spring","slug":"spring","permalink":"http://dennis.pathto.top/tags/spring/"},{"name":"spring-boot","slug":"spring-boot","permalink":"http://dennis.pathto.top/tags/spring-boot/"}]},{"title":"14.spring-boot后台运行进程","date":"2017-11-16T15:10:28.000Z","path":"2017/11/16/spring-boot-14-background-job/","text":"在pom.xml中添加Spring Boot的插件，并注意设置executable配置 &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;executable&gt;true&lt;/executable&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; 在完成上述配置后，构建一个可执行的jar包 mvn package chmod 777 yourapp.jar 创建软连接到/etc/init.d/目录下 sudo ln -s /var/yourapp/yourapp.jar /etc/init.d/yourapp 在完成软连接创建之后，我们就可以通过如下命令对yourapp.jar应用来控制启动、停止、重启操作了 /etc/init.d/yourapp start|stop|restart 自定义配置文件 在jar包所在的目录下有下面的文件 [root@dennis yourapp]# cat yourapp.conf JAVA_HOME=/usr/local/jdk1.8.0_144 LOG_FOLDER=/usr/local/yourapp/log 注意conf文件的名字一定要和jar的名字一样，否则配置文件不起作用","tags":[{"name":"java","slug":"java","permalink":"http://dennis.pathto.top/tags/java/"},{"name":"spring","slug":"spring","permalink":"http://dennis.pathto.top/tags/spring/"},{"name":"spring-boot","slug":"spring-boot","permalink":"http://dennis.pathto.top/tags/spring-boot/"}]},{"title":"ubuntu-防火墙访问控制","date":"2017-11-08T15:37:54.000Z","path":"2017/11/08/ubuntu-firewalld/","text":"Ubuntu默认防火墙安装、启用、配置、端口、查看状态相关信息 Ubuntu附带了一个相对iptables简单很多的防火墙 配置工具：ufw ufw防火墙 即uncomplicated firewall，不复杂的防火墙，繁琐部分的设置还是需要去到iptables 查看防火墙状态 sudo ufw status 防火墙版本 sudo ufw version 安装 sudo apt-get install ufw 启用 sudo ufw enable sudo ufw default deny 运行以上两条命令后，开启了防火墙，并在系统启动时自动开启。 关闭所有外部对本机的访问，但本机访问外部正常。 开启/禁用 sudo ufw allow|deny [service] 打开或关闭某个端口 开启/关闭防火墙 (默认设置是’disable’) sudo ufw enable|disable eg: sudo ufw allow 3306 为了使mysql可以远程访问，开启mysql的3306端口 指定协议 ufw allow 80/tcp","tags":[{"name":"linux","slug":"linux","permalink":"http://dennis.pathto.top/tags/linux/"},{"name":"ubuntu","slug":"ubuntu","permalink":"http://dennis.pathto.top/tags/ubuntu/"}]},{"title":"linux-shell文件问题","date":"2017-10-05T09:50:53.000Z","path":"2017/10/05/linux-0-shell-file-problem/","text":"今天，在windows创建了一个用于自动化部署的shell文件-deploy.sh 在Linux中，失去了效果,很不解 [root@jdu4e00u53f7 dennis]# ./deploy.sh -bash: ./deploy.sh: /bin/sh^M: bad interpreter: No such file or directory 原来.sh文件的格式为dos格式。而linux只能执行格式为unix格式的脚本 解决办法 首先用vi命令打开文件 [root@jdu4e00u53f7 dennis]# vi deploy.sh 在vi命令模式中使用 :set ff 命令 :set off 可以看到改文件的格式为dos image 修改文件format为unix 方法一：使用vi修改文件format set ff=unix 执行完后再通过set ff命令查看文件格式，结果如下： fileformat=unix 方法二：直接使用dos2unix命令修改 [root@jdu4e00u53f7 dennis]# dos2unix deploy.sh dos2unix: converting file test.sh to UNIX format ... 修改完后再次执行./deploy.sh，执行正确","tags":[{"name":"linux","slug":"linux","permalink":"http://dennis.pathto.top/tags/linux/"},{"name":"shell","slug":"shell","permalink":"http://dennis.pathto.top/tags/shell/"}]},{"title":"subversion+centos7","date":"2017-10-05T09:34:57.000Z","path":"2017/10/05/svn-0-centos7/","text":"subversion 简介 Subversion是一个自由开源的版本控制系统。在Subversion管理下，文件和目录可以超越时空。Subversion将文件存放在中心版本库里，这个版本库很像一个普通的文件服务器，不同的是，它可以记录每一次文件和目录的修改情况，这样就可以借此将数据恢复到以前的版本，并可以查看数据的更改细节。正因为如此，许多人将版本控制系统当作一种神奇的“时间机器”。 subversion 官网：http://subversion.apache.org/ subversion 安装 [root@linuxprobe~]# yum -y install subversion 创建源仓库，以“/var/svn/repos/project”为例 [root@linuxprobe ~]# mkdir -p /var/svn/repos/project [root@linuxprobe ~]# svnadmin create /var/svn/repos/project # 创建源仓库 [root@linuxprobe ~]# svn mkdir file:///var/svn/repos/project/trunk -m &quot;create&quot; Committed revision 1. [root@linuxprobe ~]# svn mkdir file:///var/svn/repos/project/branches -m &quot;create&quot; # 创建分支 Committed revision 2. [root@linuxprobe ~]# svn mkdir file:///var/svn/repos/project/tags -m &quot;create&quot; # 创建标签 Committed revision 3. 导入已存在的代码文件到SVN仓库，导入/home/project目录的文件 [root@linuxprobe ~]# ll /home/project/ total 0 -rw-r--r-- 1 root root 0 Nov 1 11:57 index.go -rw-r--r-- 1 root root 0 Nov 1 11:57 index.html -rw-r--r-- 1 root root 0 Nov 1 11:57 index.php -rw-r--r-- 1 root root 0 Nov 1 11:58 index.py -rw-r--r-- 1 root root 0 Nov 1 11:58 info.php [root@linuxprobe ~]# svn import /home/project file:///var/svn/repos/project/trunk -m &quot;initial import&quot; Adding /home/project/index.html Adding /home/project/index.go Adding /home/project/index.php Adding /home/project/index.py Adding /home/project/info.php Committed revision 4. # 确认 [root@linuxprobe ~]# svn list file:///var/svn/repos/project/trunk index.go index.html index.php index.py info.php 启动svnserver，svnserve监听TCP 3690，防火墙开启端口通信 # svn server 端 [root@linuxprobe ~]# systemctl start svnserve # svn client 端 [root@vdevops ~]# yum -y install svn [root@vdevops ~]# svn list svn://linuxprobe.org/repos/project branches/ tags/ trunk/ # 导出代码到本地 [root@vdevops ~]# svn checkout svn://linuxprobe.org/repos/project A project/tags A project/trunk A project/trunk/info.php A project/trunk/index.html A project/trunk/index.go A project/trunk/index.php A project/trunk/index.py A project/branches Checked out revision 4. 如果没有启动svnserve，通过端口无法连接到svn server，可以通过ssh的方式连接到svn server # svn server 端 [root@linuxprobe ~]# systemctl stop svnserve # svn client端 [root@vdevops ~]# svn list svn+ssh://root@linuxprobe.org/var/svn/repos/project root@linuxprobe.org&apos;s password: branches/ tags/ trunk/ subversion 访问控制设置访问控制“/var/svn/repos/project”[root@linuxprobe ~]# vi /var/svn/repos/project/conf/svnserve.conf # line 9: add (prohibit anonymous access) [general] anon-access = none # line 28: uncomment password-db = passwd # line 35: uncomment authz-db = authz [root@linuxprobe ~]# vi /var/svn/repos/project/conf/passwd # define username and password for this repository [users] shaon= password wang = password devops = password [root@linuxprobe ~]# vi /var/svn/repos/project/conf/authz # define groups and users [groups] developer = devops,wang # allow read/write on document root for developer group [/] @developer = rw # allow read on trunk folder for fedora user [/trunk] shaon = r svn client 客户端测试[root@vdevops trunk]# svn --username shaon list svn://linuxprobe.org/repos/project/trunk Authentication realm: &lt;svn://linuxprobe.org:3690&gt; LinuxProbe Repository Password for &apos;shaon&apos;: ----------------------------------------------------------------------- ATTENTION! Your password for authentication realm: &lt;svn://linuxprobe.org:3690&gt; LinuxProbe Repository # 仓库名称 can only be stored to disk unencrypted! You are advised to configure your system so that Subversion can store passwords encrypted, if possible. See the documentation for details. You can avoid future appearances of this warning by setting the value of the &apos;store-plaintext-passwords&apos; option to either &apos;yes&apos; or &apos;no&apos; in &apos;/root/.subversion/servers&apos;. ----------------------------------------------------------------------- Store password unencrypted (yes/no)? yes #记住密码 index.go index.html index.php index.py info.php","tags":[{"name":"svn","slug":"svn","permalink":"http://dennis.pathto.top/tags/svn/"}]},{"title":"CentOS 7下用firewall-cmd控制端口与端口转发","date":"2017-10-05T09:17:19.000Z","path":"2017/10/05/linux-0-firewalld/","text":"firewalld 守护进程firewall-cmd命令需要firewalld进程处于运行状态。我们可以使用systemctl status/start/stop/restart firewalld来控制这个守护进程。firewalld进程为防火墙提供服务。当我们修改了某些配置之后（尤其是配置文件的修改），firewall并不会立即生效。可以通过两种方式来激活最新配置systemctl restart firewalld和firewall-cmd –reload两种方式，前一种是重启firewalld服务，建议使用后一种“重载配置文件”。重载配置文件之后不会断掉正在连接的tcp会话，而重启服务则会断开tcp会话。 控制端口/服务可以通过两种方式控制端口的开放，一种是指定端口号另一种是指定服务名。虽然开放http服务就是开放了80端口，但是还是不能通过端口号来关闭，也就是说通过指定服务名开放的就要通过指定服务名关闭；通过指定端口号开放的就要通过指定端口号关闭。还有一个要注意的就是指定端口的时候一定要指定是什么协议，tcp还是udp。知道这个之后以后就不用每次先关防火墙了，可以让防火墙真正的生效。 firewall-cmd --add-service=mysql # 开放mysql端口 firewall-cmd --remove-service=http # 阻止http端口 firewall-cmd --list-services # 查看开放的服务 firewall-cmd --add-port=3306/tcp # 开放通过tcp访问3306 firewall-cmd --remove-port=80tcp # 阻止通过tcp访问3306 firewall-cmd --add-port=233/udp # 开放通过udp访问233 firewall-cmd --list-ports # 查看开放的端口 伪装IP防火墙可以实现伪装IP的功能，下面的端口转发就会用到这个功能。 firewall-cmd --query-masquerade # 检查是否允许伪装IP firewall-cmd --add-masquerade # 允许防火墙伪装IP firewall-cmd --remove-masquerade# 禁止防火墙伪装IP 端口转发端口转发可以将指定地址访问指定的端口时，将流量转发至指定地址的指定端口。转发的目的如果不指定ip的话就默认为本机，如果指定了ip却没指定端口，则默认使用来源端口。如果配置好端口转发之后不能用，可以检查下面两个问题： 1.比如我将80端口转发至8080端口，首先检查本地的80端口和目标的8080端口是否开放监听了 2.其次检查是否允许伪装IP，没允许的话要开启伪装IP # 将80端口的流量转发至8080 firewall-cmd --add-forward-port=port=80:proto=tcp:toport=8080 # 将80端口的流量转发至 firewall-cmd --add-forward-port=port=80:proto=tcp:toaddr=192.168.1.0.1192.168.0.1 # 将80端口的流量转发至192.168.0.1的8080端口 firewall-cmd --add-forward-port=port=80:proto=tcp:toaddr=192.168.0.1:toport=8080 1.当我们想把某个端口隐藏起来的时候，就可以在防火墙上阻止那个端口访问，然后再开一个不规则的端口，之后配置防火墙的端口转发，将流量转发过去。 2.端口转发还可以做流量分发，一个防火墙拖着好多台运行着不同服务的机器，然后用防火墙将不同端口的流量转发至不同机器。 总结以上就是这篇文章的全部内容了，希望本文的内容对大家的学习或者工作能带来一定的帮助，如果有疑问大家可以留言交流，谢谢大家对脚本之家的支持。","tags":[{"name":"linux","slug":"linux","permalink":"http://dennis.pathto.top/tags/linux/"},{"name":"centos7","slug":"centos7","permalink":"http://dennis.pathto.top/tags/centos7/"}]},{"title":"15.不同主机的容器使用openvswitch互联","date":"2017-10-03T14:58:26.000Z","path":"2017/10/03/docker-openvswitch-15/","text":"使用openvswitch网桥的方式来对容器网络进行管理，实现容器互通。Open vSwitch是一个高质量的、多层虚拟交换机。通过构建隧道的方式使网络能够互相通信。 配置192.168.159.159删除之前的容器[root@docker01 ~]# docker rm -f 531b067ba5e9 531b067ba5e9 删除ip转发[root@docker01 ~]# route -n Kernel IP routing table Destination Gateway Genmask Flags Metric Ref Use Iface 0.0.0.0 192.168.159.2 0.0.0.0 UG 100 0 0 eth0 172.16.0.0 192.168.159.164 255.255.0.0 UG 0 0 0 eth0 172.17.0.0 0.0.0.0 255.255.0.0 U 0 0 0 docker0 172.18.0.0 0.0.0.0 255.255.0.0 U 0 0 0 br-cb66f459da67 172.19.0.0 0.0.0.0 255.255.0.0 U 0 0 0 br-b45027b77aee 192.168.159.0 0.0.0.0 255.255.255.0 U 100 0 0 eth0 [root@docker01 ~]# route del -net 172.16.0.0/16 gw 192.168.159.164 [root@docker01 ~]# route -n Kernel IP routing table Destination Gateway Genmask Flags Metric Ref Use Iface 0.0.0.0 192.168.159.2 0.0.0.0 UG 100 0 0 eth0 172.17.0.0 0.0.0.0 255.255.0.0 U 0 0 0 docker0 172.18.0.0 0.0.0.0 255.255.0.0 U 0 0 0 br-cb66f459da67 172.19.0.0 0.0.0.0 255.255.0.0 U 0 0 0 br-b45027b77aee 192.168.159.0 0.0.0.0 255.255.255.0 U 100 0 0 eth0 配置192.168.159.164删除之前的容器[root@docker02 ~]# docker rm -f 8e0b23b12c08 8e0b23b12c08 删除ip转发[root@docker02 ~]# route -n Kernel IP routing table Destination Gateway Genmask Flags Metric Ref Use Iface 0.0.0.0 192.168.159.2 0.0.0.0 UG 100 0 0 eth0 172.16.0.0 0.0.0.0 255.255.0.0 U 0 0 0 docker0 172.17.0.0 192.168.159.159 255.255.0.0 UG 0 0 0 eth0 172.18.0.0 0.0.0.0 255.255.0.0 U 0 0 0 br-cb66f459da67 172.19.0.0 0.0.0.0 255.255.0.0 U 0 0 0 br-b45027b77aee 192.168.159.0 0.0.0.0 255.255.255.0 U 100 0 0 eth0 [root@docker02 ~]# route del -net 172.17.0.0/16 gw 192.168.159.159 [root@docker02 ~]# route -n Kernel IP routing table Destination Gateway Genmask Flags Metric Ref Use Iface 0.0.0.0 192.168.159.2 0.0.0.0 UG 100 0 0 eth0 172.16.0.0 0.0.0.0 255.255.0.0 U 0 0 0 docker0 172.18.0.0 0.0.0.0 255.255.0.0 U 0 0 0 br-cb66f459da67 172.19.0.0 0.0.0.0 255.255.0.0 U 0 0 0 br-b45027b77aee 192.168.159.0 0.0.0.0 255.255.255.0 U 100 0 0 eth0 两个服务器都安装openvswitchyum install gcc make python-developenssl-devel kernel-develgraphviz kernel-debug-devel autoconf automake rpm-build redhat-rpm-config libtool selinux-policy-devel -y cd /usr/local/src wget http://openvswitch.org/releases/openvswitch-2.7.3.tar.gz mkdir -p ~/rpmbuild/SOURCES cp openvswitch-2.7.3.tar.gz ~/rpmbuild/SOURCES/ tar -xvf openvswitch-2.7.3.tar.gz sed &apos;s/openvswitch-kmod, //g&apos; openvswitch-2.7.3/rhel/openvswitch.spec&gt; openvswitch-2.7.3/rhel/openvswitch_no_kmod.spec rpmbuild -bb --without check openvswitch-2.7.3/rhel/openvswitch_no_kmod.spec [root@docker01 src]# rpmbuild -bb --without check openvswitch-2.7.3/rhel/openvswitch_no_kmod.spec 错误：构建依赖失败 python-six 被 openvswitch-2.7.3-1.x86_64 依赖 openssl-devel 被 openvswitch-2.7.3-1.x86_64 依赖 安装python-six,openssl-devel yum install -y python-six yum install -y openssl-devel 重新执行rpmbuild -bb --without check openvswitch-2.7.3/rhel/openvswitch_no_kmod.spec [root@docker02 src]# cd ~/rpmbuild/RPMS/x86_64/ [root@docker02 x86_64]# ls openvswitch-2.7.3-1.x86_64.rpm openvswitch-debuginfo-2.7.3-1.x86_64.rpm openvswitch-devel-2.7.3-1.x86_64.rpm #本地安装openvswitch yum localinstall -y openvswitch-2.7.3-1.x86_64.rpm systemctl start openvswitch yum -y install bridge-utils 创建gre隧道配置192.168.159.159ovs-vsctl add-br br0 ovs-vsctl add-port br0 gre1 -- set interface gre1 type=gre option:remote_ip=192.168.159.164 brctl addif docker0 br0 ip link set dev br0 up ip link set dev docker0 up iptables -t nat -F;iptables -F ip route add 172.16.0.0/16 dev docker0 配置192.168.159.164ovs-vsctl add-br br0 ovs-vsctl add-port br0 gre1 -- set interface gre1 type=gre option:remote_ip=192.168.159.159 brctl addif docker0 br0 ip link set dev br0 up ip link set dev docker0 up iptables -t nat -F;iptables -F ip route add 172.17.0.0/16 dev docker0 测试192.168.159.159[root@4318057f90a5 /]# ping 172.16.0.2 PING 172.16.0.2 (172.16.0.2) 56(84) bytes of data. 64 bytes from 172.16.0.2: icmp_seq=1 ttl=63 time=1.13 ms From 172.17.0.1 icmp_seq=2 Redirect HostFrom 172.17.0.1: icmp_seq=2 Redirect Host(New nexthop: 172.16.0.2) 64 bytes from 172.16.0.2: icmp_seq=2 ttl=63 time=0.841 ms 64 bytes from 172.16.0.2: icmp_seq=3 ttl=63 time=0.871 ms From 172.17.0.1 icmp_seq=4 Redirect HostFrom 172.17.0.1: icmp_seq=4 Redirect Host(New nexthop: 172.16.0.2) 64 bytes from 172.16.0.2: icmp_seq=4 ttl=63 time=18.6 ms 64 bytes from 172.16.0.2: icmp_seq=5 ttl=63 time=0.805 ms 64 bytes from 172.16.0.2: icmp_seq=6 ttl=63 time=0.814 ms From 172.17.0.1 icmp_seq=7 Redirect HostFrom 172.17.0.1: icmp_seq=7 Redirect Host(New nexthop: 172.16.0.2) 64 bytes from 172.16.0.2: icmp_seq=7 ttl=63 time=0.825 ms 64 bytes from 172.16.0.2: icmp_seq=8 ttl=63 time=0.790 ms 64 bytes from 172.16.0.2: icmp_seq=9 ttl=63 time=0.854 ms ^C --- 172.16.0.2 ping statistics --- 9 packets transmitted, 9 received, +3 errors, 0% packet loss, time 8745ms rtt min/avg/max/mdev = 0.790/2.846/18.683/5.600 ms 192.168.159.159的容器成功连接到到192.168.159.164上面的容器,有少数的丢包 测试192.168.159.164[root@0149ce2b0c24 /]# ping 172.17.0.2 PING 172.17.0.2 (172.17.0.2) 56(84) bytes of data. 64 bytes from 172.17.0.2: icmp_seq=1 ttl=63 time=1.68 ms From 172.16.0.1 icmp_seq=2 Redirect HostFrom 172.16.0.1: icmp_seq=2 Redirect Host(New nexthop: 172.17.0.2) 64 bytes from 172.17.0.2: icmp_seq=2 ttl=63 time=0.977 ms From 172.16.0.1 icmp_seq=3 Redirect HostFrom 172.16.0.1: icmp_seq=3 Redirect Host(New nexthop: 172.17.0.2) 64 bytes from 172.17.0.2: icmp_seq=3 ttl=63 time=1.37 ms 64 bytes from 172.17.0.2: icmp_seq=4 ttl=63 time=0.815 ms ^C --- 172.17.0.2 ping statistics --- 4 packets transmitted, 4 received, +2 errors, 0% packet loss, time 3578ms rtt min/avg/max/mdev = 0.815/1.213/1.684/0.342 ms 192.168.159.164的容器成功连接到到192.168.159.159上面的容器,有少数的丢包","tags":[{"name":"docker","slug":"docker","permalink":"http://dennis.pathto.top/tags/docker/"},{"name":"cloud","slug":"cloud","permalink":"http://dennis.pathto.top/tags/cloud/"}]},{"title":"14.ip转发的方式实现机器的容器互联互通","date":"2017-10-03T14:57:45.000Z","path":"2017/10/03/docker-ip-forward-14/","text":"ip转发的方式实现机器的容器互联互通 网络架构 image 容器的网段默认主机分配的都是172.17.0.1/16网段的IP地址，可以修改/usr/lib/systemd/system/docker.service配置文件，自定义网络 配置192.168.159.164服务器添加–bip=172.16.0.1/16到ExecStart所在的行中 ExecStart=/usr/bin/dockerd -H unix:///var/run/docker.sock -H tcp://0.0.0.0:2375 --bip=172.16.0.1/16 重启docker[root@docker02 ~]# systemctl daemon-reload [root@docker02 ~]# systemctl restart docker 启用ip转发[root@docker02 ~]# vi /etc/sysctl.conf [root@docker02 ~]# sysctl -p net.ipv4.ip_forward = 1 net.ipv4.conf.all.rp_filter = 0 net.ipv4.conf.default.rp_filter = 0 运行一个mysql的docker容器[root@docker02 ~]# docker run -dit workpress/mysql:1.0 /bin/bash 8e0b23b12c08fd78dc48e465ac8df542c9bbbb060fdb9d3bf08628d6994b1625 [root@docker02 ~]# docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 8e0b23b12c08 workpress/mysql:1.0 &quot;/bin/bash&quot; About a minute ago Up About a minute 3306/tcp musing_almeida [root@docker02 ~]# docker exec -it 8e0b23b12c08 /bin/bash [root@8e0b23b12c08 /]# ip addr 1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever 8: eth0@if9: &lt;BROADCAST,MULTICAST,UP,LOWER_UP,M-DOWN&gt; mtu 1500 qdisc noqueue state UP link/ether 02:42:ac:10:00:02 brd ff:ff:ff:ff:ff:ff inet 172.16.0.2/16 scope global eth0 valid_lft forever preferred_lft forever 配置192.168.159.159启动docker[root@docker01 ~]# docker run -dit workpress/mysql:1.0 /bin/bash 531b067ba5e974028943afd3135fe933a27390478c1bc50b3c36f1275eee2512 [root@docker01 ~]# docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 531b067ba5e9 workpress/mysql:1.0 &quot;/bin/bash&quot; About a minute ago Up About a minute 3306/tcp confident_mahavira [root@docker01 ~]# docker exec -it 531b067ba5e9 /bin/bash [root@531b067ba5e9 /]# ip addr 1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever 8: eth0@if9: &lt;BROADCAST,MULTICAST,UP,LOWER_UP,M-DOWN&gt; mtu 1500 qdisc noqueue state UP link/ether 02:42:ac:11:00:02 brd ff:ff:ff:ff:ff:ff inet 172.17.0.2/16 scope global eth0 valid_lft forever preferred_lft forever 测试是否连通192.168.159.164上面的docker[root@531b067ba5e9 /]# ping 172.16.0.2 PING 172.16.0.2 (172.16.0.2) 56(84) bytes of data. ^C --- 172.16.0.2 ping statistics --- 7 packets transmitted, 0 received, 100% packet loss, time 6144ms 默认情况下两台机器的容器是没法连通的 启用ip转发[root@docker01 ~]# vi /etc/sysctl.conf [root@docker01 ~]# sysctl -p net.ipv4.ip_forward = 1 net.ipv4.conf.all.rp_filter = 0 net.ipv4.conf.default.rp_filter = 0 [root@docker01 ~]# route add -net 172.16.0.0/16 gw 192.168.159.164 重启登录测试[root@docker01 ~]# docker exec -it 531b067ba5e9 /bin/bash [root@531b067ba5e9 /]# ping 172.16.0.2 PING 172.16.0.2 (172.16.0.2) 56(84) bytes of data. 64 bytes from 172.16.0.2: icmp_seq=1 ttl=62 time=1.42 ms 64 bytes from 172.16.0.2: icmp_seq=2 ttl=62 time=0.740 ms 64 bytes from 172.16.0.2: icmp_seq=3 ttl=62 time=1.44 ms ^C --- 172.16.0.2 ping statistics --- 3 packets transmitted, 3 received, 0% packet loss, time 2195ms rtt min/avg/max/mdev = 0.740/1.204/1.444/0.328 ms 可以发现，192.168.159.159上面的容器可以ping通192.168.159.164上面的容器了 再次配置192.168.159.164[root@docker02 ~]# route add -net 172.17.0.0/16 gw 192.168.159.159 [root@docker02 ~]# docker exec -it 8e0b23b12c08 /bin/bash [root@8e0b23b12c08 /]# ping 172.17.0.2 PING 172.17.0.2 (172.17.0.2) 56(84) bytes of data. 64 bytes from 172.17.0.2: icmp_seq=1 ttl=62 time=2.23 ms 64 bytes from 172.17.0.2: icmp_seq=2 ttl=62 time=0.746 ms ^C --- 172.17.0.2 ping statistics --- 2 packets transmitted, 2 received, 0% packet loss, time 1487ms rtt min/avg/max/mdev = 0.746/1.489/2.233/0.744 ms 测试发现，192.168.159.164上面的容器可以ping通192.168.159.159上面的容器了","tags":[{"name":"docker","slug":"docker","permalink":"http://dennis.pathto.top/tags/docker/"},{"name":"cloud","slug":"cloud","permalink":"http://dennis.pathto.top/tags/cloud/"}]},{"title":"13.几种网络互联的方式","date":"2017-10-03T14:57:09.000Z","path":"2017/10/03/docker-network-model-13/","text":"查看默认的几种网络驱动[root@docker01 ~]# docker network ls NETWORK ID NAME DRIVER SCOPE 755f59e30dcd bridge bridge local b45027b77aee composemultipleworkpress_default bridge local cb66f459da67 composeworkpress_default bridge local 41d112090834 host host local 0bfa2196fd1c none null local 除此之外，还有contain的网络驱动,Docker的overlay插件驱动 桥接默认使用的是桥接[root@docker01 ~]# docker exec -it bridge /bin/bash [root@441f3d9f9583 /]# ifconfig lo Link encap:Local Loopback inet addr:127.0.0.1 Mask:255.0.0.0 UP LOOPBACK RUNNING MTU:65536 Metric:1 RX packets:0 errors:0 dropped:0 overruns:0 frame:0 TX packets:0 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:0 RX bytes:0 (0.0 b) TX bytes:0 (0.0 b) 查看那些容器使用了桥接模式[root@docker01 ~]# docker network inspect none [ { &quot;Name&quot;: &quot;none&quot;, &quot;Id&quot;: &quot;0bfa2196fd1cffacecd16ef1525a48a242525f7bf1cf601a2add611c14edddbf&quot;, &quot;Created&quot;: &quot;2017-08-07T16:26:55.396665908Z&quot;, &quot;Scope&quot;: &quot;local&quot;, &quot;Driver&quot;: &quot;null&quot;, &quot;EnableIPv6&quot;: false, &quot;IPAM&quot;: { &quot;Driver&quot;: &quot;default&quot;, &quot;Options&quot;: null, &quot;Config&quot;: [] }, &quot;Internal&quot;: false, &quot;Attachable&quot;: false, &quot;Ingress&quot;: false, &quot;ConfigFrom&quot;: { &quot;Network&quot;: &quot;&quot; }, &quot;ConfigOnly&quot;: false, &quot;Containers&quot;: { &quot;441f3d9f9583e65f4829710a61f04a015ba8ac1c28fc9e67fc61945940564f44&quot;: { &quot;Name&quot;: &quot;bridge&quot;, &quot;EndpointID&quot;: &quot;edfaab0b5fdd95fef87411e872cd409d9d952f62653f15088aba27359ee3b990&quot;, &quot;MacAddress&quot;: &quot;&quot;, &quot;IPv4Address&quot;: &quot;&quot;, &quot;IPv6Address&quot;: &quot;&quot; } }, &quot;Options&quot;: {}, &quot;Labels&quot;: {} } ] Host的网络方式Host方式与主机共用network命名空间，直接使用本地网卡，不用经过nat转换，包的转发效率就搞很多;但是这样，启动一个容器和本地端口就不能冲突了，而且也是存在安全隐患，也不推荐这样用。 使用host模式启动一个docker[root@docker01 ~]# docker run -i -t --net=host workpress/mysql:1.0 /bin/bash [root@docker01 /]# ip addr 1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever inet6 ::1/128 scope host valid_lft forever preferred_lft forever 2: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP qlen 1000 link/ether 00:0c:29:11:2a:80 brd ff:ff:ff:ff:ff:ff inet 192.168.159.159/24 brd 192.168.159.255 scope global eth0 valid_lft forever preferred_lft forever inet6 fe80::20c:29ff:fe11:2a80/64 scope link valid_lft forever preferred_lft forever 3: br-b45027b77aee: &lt;NO-CARRIER,BROADCAST,MULTICAST,UP&gt; mtu 1500 qdisc noqueue state DOWN link/ether 02:42:71:00:ee:66 brd ff:ff:ff:ff:ff:ff inet 172.19.0.1/16 scope global br-b45027b77aee valid_lft forever preferred_lft forever 4: docker0: &lt;NO-CARRIER,BROADCAST,MULTICAST,UP&gt; mtu 1500 qdisc noqueue state DOWN link/ether 02:42:9f:e8:65:22 brd ff:ff:ff:ff:ff:ff inet 172.17.0.1/16 scope global docker0 valid_lft forever preferred_lft forever 5: br-cb66f459da67: &lt;NO-CARRIER,BROADCAST,MULTICAST,UP&gt; mtu 1500 qdisc noqueue state DOWN link/ether 02:42:cc:2c:4b:75 brd ff:ff:ff:ff:ff:ff inet 172.18.0.1/16 scope global br-cb66f459da67 valid_lft forever preferred_lft forever 可以看到docker 容器内部的ip地址就是宿主机的ip地址 在容器内部启动mysql[root@docker01 /]# service mysqld start Initializing MySQL database: WARNING: The host &apos;docker01&apos; could not be looked up with resolveip. This probably means that your libc libraries are not 100 % compatible with this binary MySQL version. The MySQL daemon, mysqld, should work normally with the exception that host name resolving will not work. This means that you should use IP addresses instead of hostnames when specifying MySQL privileges ! Installing MySQL system tables... OK Filling help tables... OK To start mysqld at boot time you have to copy support-files/mysql.server to the right place for your system PLEASE REMEMBER TO SET A PASSWORD FOR THE MySQL root USER ! To do so, start the server, then issue the following commands: /usr/bin/mysqladmin -u root password &apos;new-password&apos; /usr/bin/mysqladmin -u root -h docker01 password &apos;new-password&apos; Alternatively you can run: /usr/bin/mysql_secure_installation which will also give you the option of removing the test databases and anonymous user created by default. This is strongly recommended for production servers. See the manual for more instructions. You can start the MySQL daemon with: cd /usr ; /usr/bin/mysqld_safe &amp; You can test the MySQL daemon with mysql-test-run.pl cd /usr/mysql-test ; perl mysql-test-run.pl Please report any problems with the /usr/bin/mysqlbug script! [ OK ] Starting mysqld: [ OK ] 通过观察mysql的启动日志，可以知道，需要设置用户的账号密码，执行一下安全相关的脚本 设置root用户密码[root@docker01 /]# /usr/bin/mysqladmin -u root password &apos;new-password&apos; 登录mysql[root@docker01 /]# mysql -uroot -pnew-password Welcome to the MySQL monitor. Commands end with ; or \\g. Your MySQL connection id is 9 Server version: 5.1.73 Source distribution Copyright (c) 2000, 2013, Oracle and/or its affiliates. All rights reserved. Oracle is a registered trademark of Oracle Corporation and/or its affiliates. Other names may be trademarks of their respective owners. Type &apos;help;&apos; or &apos;\\h&apos; for help. Type &apos;\\c&apos; to clear the current input statement. mysql&gt; 退出docker容器[root@docker01 /]# exit 容器和宿主机中可以看到mysql监听的端口[root@docker01 /]# netstat -ntlp Active Internet connections (only servers) Proto Recv-Q Send-Q Local Address Foreign Address State PID/Program name tcp 0 0 0.0.0.0:3306 0.0.0.0:* LISTEN - tcp 0 0 0.0.0.0:22 0.0.0.0:* LISTEN - tcp 0 0 127.0.0.1:25 0.0.0.0:* LISTEN - tcp 0 0 :::22 :::* LISTEN - tcp 0 0 ::1:25 :::* LISTEN - tcp 0 0 :::2375 :::* LISTEN - [root@docker01 /]# exit exit [root@docker01 ~]# netstat -ntlp Active Internet connections (only servers) Proto Recv-Q Send-Q Local Address Foreign Address State PID/Program name tcp 0 0 0.0.0.0:3306 0.0.0.0:* LISTEN 3917/mysqld tcp 0 0 0.0.0.0:22 0.0.0.0:* LISTEN 1481/sshd tcp 0 0 127.0.0.1:25 0.0.0.0:* LISTEN 2629/master tcp6 0 0 :::22 :::* LISTEN 1481/sshd tcp6 0 0 ::1:25 :::* LISTEN 2629/master tcp6 0 0 :::2375 :::* LISTEN 2704/dockerd host模式的优点:提高了包的转发效率 缺点:要避免端口冲突 container复用方式指定方法： –net=”container:name or id”，使得两个启动的容器都是使用相同的网络命名空间也就意味着，两个的IP，MAC地址是一样的。 [root@docker01 ~]# docker run -dit workpress/nginx:1.0 /bin/bash 805b53a77104403f3e8d2fc8156e8e784200836eeaad0d392248b0e50a1a045a root@docker01 ~]# docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 805b53a77104 workpress/nginx:1.0 &quot;/bin/bash&quot; 4 seconds ago Up 3 seconds 80/tcp suspicious_pare [root@docker01 ~]# docker exec -it 805b53a77104 /bin/bash [root@805b53a77104 /]# ip addr 1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever 6: eth0@if7: &lt;BROADCAST,MULTICAST,UP,LOWER_UP,M-DOWN&gt; mtu 1500 qdisc noqueue state UP link/ether 02:42:ac:11:00:02 brd ff:ff:ff:ff:ff:ff inet 172.17.0.2/16 scope global eth0 valid_lft forever preferred_lft forever 另外起一个会话[root@docker01 ~]# docker exec -it 2d5fab44c292 /bin/bash [root@805b53a77104 /]# ip addr 1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever 6: eth0@if7: &lt;BROADCAST,MULTICAST,UP,LOWER_UP,M-DOWN&gt; mtu 1500 qdisc noqueue state UP link/ether 02:42:ac:11:00:02 brd ff:ff:ff:ff:ff:ff inet 172.17.0.2/16 scope global eth0 valid_lft forever preferred_lft forever 可以看到，上面的两个docker实在同一个命名空间的,拥有相同额网络配置信息 查看相关桥接情况[root@docker01 ~]# docker network inspect bridge [ { &quot;Name&quot;: &quot;bridge&quot;, &quot;Id&quot;: &quot;755f59e30dcdc3f97352ee75976f01ee14fa463a7dc947de7cb443edf2515755&quot;, &quot;Created&quot;: &quot;2017-10-03T13:16:58.799908274Z&quot;, &quot;Scope&quot;: &quot;local&quot;, &quot;Driver&quot;: &quot;bridge&quot;, &quot;EnableIPv6&quot;: false, &quot;IPAM&quot;: { &quot;Driver&quot;: &quot;default&quot;, &quot;Options&quot;: null, &quot;Config&quot;: [ { &quot;Subnet&quot;: &quot;172.17.0.0/16&quot;, &quot;Gateway&quot;: &quot;172.17.0.1&quot; } ] }, &quot;Internal&quot;: false, &quot;Attachable&quot;: false, &quot;Ingress&quot;: false, &quot;ConfigFrom&quot;: { &quot;Network&quot;: &quot;&quot; }, &quot;ConfigOnly&quot;: false, &quot;Containers&quot;: { &quot;805b53a77104403f3e8d2fc8156e8e784200836eeaad0d392248b0e50a1a045a&quot;: { &quot;Name&quot;: &quot;suspicious_pare&quot;, &quot;EndpointID&quot;: &quot;8be7038f680cb706ea736cda0eaf7c9d80e48573a46b80efb7e3b10c75bdef06&quot;, &quot;MacAddress&quot;: &quot;02:42:ac:11:00:02&quot;, &quot;IPv4Address&quot;: &quot;172.17.0.2/16&quot;, &quot;IPv6Address&quot;: &quot;&quot; } }, &quot;Options&quot;: { &quot;com.docker.network.bridge.default_bridge&quot;: &quot;true&quot;, &quot;com.docker.network.bridge.enable_icc&quot;: &quot;true&quot;, &quot;com.docker.network.bridge.enable_ip_masquerade&quot;: &quot;true&quot;, &quot;com.docker.network.bridge.host_binding_ipv4&quot;: &quot;0.0.0.0&quot;, &quot;com.docker.network.bridge.name&quot;: &quot;docker0&quot;, &quot;com.docker.network.driver.mtu&quot;: &quot;1500&quot; }, &quot;Labels&quot;: {} } ]","tags":[{"name":"docker","slug":"docker","permalink":"http://dennis.pathto.top/tags/docker/"},{"name":"cloud","slug":"cloud","permalink":"http://dennis.pathto.top/tags/cloud/"}]},{"title":"11.docker_compose构建workpress","date":"2017-10-02T15:07:01.000Z","path":"2017/10/02/docker-compose-workpress-11/","text":"Docker compose容器编排入门安装curl -L https://get.daocloud.io/docker/compose/releases/download/1.11.2/docker-compose-`uname -s`-`uname -m` &gt; /usr/local/bin/docker-compose chmod +x /usr/local/bin/docker-compose 相关命令 参数 说明 build 构建或重建服务 help 命令帮助 kill 杀掉容器 logs 显示容器的输出内容 port 打印绑定的开放端口 ps 显示容器 pull 拉取服务镜像 restart 重启服务 rm 删除停止的容器 run 运行一个一次性命令 scale 设置服务的容器数目 start 开启服务 stop 停止服务 up 创建并启动容器 配置compose[root@docker01 mysql]# docker-compose version docker-compose version 1.11.2, build dfed245 docker-py version: 2.1.0 CPython version: 2.7.13 OpenSSL version: OpenSSL 1.0.1t 3 May 2016 [root@docker01 compose-workpress]# cat compose-workpress.yml version: &quot;2&quot; services: php: image: workpress/php:1.0 volumes: - /web:/web nginx: image: workpress/nginx:1.0 ports: - 80:80 volumes: - /web:/web links: - php mysql: image: workpress/mysql:1.0 ports: - 3306:3306 volumes: - /opt/data:/var/lib/mysql compose只是为了方便docker容器的管理，并且依赖于前面dockerfile创建的镜像 构建和启动[root@docker01 compose-workpress]# docker-compose -f compose-workpress.yml up -d Starting composeworkpress_php_2 Starting composeworkpress_mysql_1 Starting composeworkpress_php_1 Creating composeworkpress_nginx_1 [root@docker01 compose-workpress]# docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES b925b02a893e workpress/nginx:1.0 &quot;/usr/local/nginx/...&quot; 4 seconds ago Up 3 seconds 0.0.0.0:80-&gt;80/tcp composeworkpress_nginx_1 82b2384664e6 registry &quot;/entrypoint.sh /e...&quot; About an hour ago Up 21 minutes 0.0.0.0:5000-&gt;5000/tcp clever_jang 807d0ea56ab1 workpress/php:1.0 &quot;/usr/local/php/sb...&quot; 7 weeks ago Up 6 seconds 9000/tcp composeworkpress_php_2 1fb8e1f8a56e workpress/php:1.0 &quot;/usr/local/php/sb...&quot; 7 weeks ago Up 4 seconds 9000/tcp composeworkpress_php_1 04ab02885e42 workpress/mysql:1.0 &quot;/bin/bash /opt/st...&quot; 7 weeks ago Up 5 seconds 0.0.0.0:3306-&gt;3306/tcp composeworkpress_mysql_1 查看相关启动日志[root@docker01 compose-workpress]# docker-compose -f compose-workpress.yml logs Attaching to composeworkpress_nginx_1, composeworkpress_php_2, composeworkpress_php_1, composeworkpress_mysql_1 mysql_1 | 170808 18:37:04 mysqld_safe Logging to &apos;/var/log/mysqld.log&apos;. mysql_1 | 170808 18:37:04 mysqld_safe Starting mysqld daemon with databases from /var/lib/mysql mysql_1 | 171001 21:27:48 mysqld_safe Logging to &apos;/var/log/mysqld.log&apos;. mysql_1 | 171001 21:27:48 mysqld_safe Starting mysqld daemon with databases from /var/lib/mysql 查看相关状态[root@docker01 compose-workpress]# docker-compose -f compose-workpress.yml ps Name Command State Ports --------------------------------------------------------------------------------------- composeworkpress_mysql_1 /bin/bash /opt/startup.sh Up 0.0.0.0:3306-&gt;3306/tcp composeworkpress_nginx_1 /usr/local/nginx/sbin/nginx Up 0.0.0.0:80-&gt;80/tcp composeworkpress_php_1 /usr/local/php/sbin/php-fpm Up 9000/tcp composeworkpress_php_2 /usr/local/php/sbin/php-fpm Up 9000/tcp 停止和删除mysql容器[root@docker01 compose-workpress]# docker-compose -f compose-workpress.yml stop mysql Stopping composeworkpress_mysql_1 ... done [root@docker01 compose-workpress]#docker-compose -f compose-workpress.yml rm mysql 停止全部compose管理的容器[root@docker01 compose-workpress]# docker-compose -f compose-workpress.yml stop Stopping composeworkpress_nginx_1 ... done Stopping composeworkpress_php_2 ... done Stopping composeworkpress_php_1 ... done 构建复杂的workpress集群目录结构[root@docker01 compose-multiple-workpress]# tree -L 2 --charset ASCII . |-- 1 |-- docker-compose.yml `-- nginx |-- Dockerfile |-- nginx-1.11.10 |-- nginx.conf `-- nginx_default.conf 2 directories, 5 files docker-compose.yml[root@docker01 compose-multiple-workpress]# cat docker-compose.yml version: &quot;2&quot; services: web_a: image: workpress/nginx:1.0 volumes: - /web_a:/web expose: - 80 web_b: image: workpress/nginx:1.0 volumes: - /web_b:/web expose: - 80 web_c: image: workpress/nginx:1.0 volumes: - /web_c:/web expose: - 80 nginx: build: nginx ports: - 80:80 links: - web_a - web_b - web_c nginx容器的配置文件Dockerfile[root@docker01 nginx]# cat Dockerfile #lnmp centos 6.0 from centos:centos6 MAINTAINER dennis52o1314@163.com ENV APP_DIR /web add nginx-1.11.10 /nginx-1.11.10 RUN yum -y groupinstall &quot;Development Tools&quot; &quot;Server Platform Deveopment&quot; RUN yum -y install openssl-devel pcre-devel RUN useradd nginx -s /sbin/nologin RUN cd /nginx-1.11.10 &amp;&amp; ./configure --prefix=/usr/local/nginx --user=nginx --group=nginx --with-http_ssl_module --with-http_flv_module --with-http_stub_status_module --with-http_gzip_static_module --with-pcre &amp;&amp; make &amp;&amp; make install RUN mkdir /usr/local/nginx/conf/vhosts RUN mkdir /var/log/nginx ADD nginx.conf /usr/local/nginx/conf/nginx.conf ADD nginx_default.conf /usr/local/nginx/conf/vhosts/default.conf EXPOSE 80 CMD [&quot;/usr/local/nginx/sbin/nginx&quot;] nginx_default.conf[root@docker01 nginx]# cat nginx_default.conf upstream web_up{ server web_a max_fails=3 fail_timeout=20s weight=2; server web_b max_fails=3 fail_timeout=20s weight=2; server web_c max_fails=3 fail_timeout=20s weight=2; } server { listen 80 default_server; server_name localhost; #charset koi8-r; location / { proxy_pass http://web_up; proxy_set_header Host ; proxy_set_header X-Real-IP ; proxy_set_header X-Forwared-For ; } } 创建三个目录，/web_a,/web_b,/web_c，分表放index.html文件到下面mkdir /web_a mkdir /web_b mkdir /web_c cat&gt;/web_a/index.html&lt;&lt;EOF web_a EOF cat&gt;/web_b/index.html&lt;&lt;EOF web_b EOF cat&gt;/web_c/index.html&lt;&lt;EOF web_c EOF [root@docker01 compose-multiple-workpress]# docker-compose up -d Creating composemultipleworkpress_web_c_1 Creating composemultipleworkpress_web_b_1 Creating composemultipleworkpress_web_a_1 Creating composemultipleworkpress_nginx_1 [root@docker01 compose-multiple-workpress]# 如果出现下面的问题 WARNING: Image for service nginx was built because it did not already exist. To rebuild this image you must use `docker-compose build` or `docker-compose up --build`. 需要先执行docker-compose build再执行docker-compose up -d 查看一下运行状态[root@docker01 compose-multiple-workpress]# docker-compose ps 设置php的数量docker-compose -f compose-workpress.yml scale php=2 停止容器docker-compose -f compose-workpress.yml stop","tags":[{"name":"docker","slug":"docker","permalink":"http://dennis.pathto.top/tags/docker/"},{"name":"cloud","slug":"cloud","permalink":"http://dennis.pathto.top/tags/cloud/"}]},{"title":"10.docker push问题","date":"2017-10-02T15:06:56.000Z","path":"2017/10/02/docker-push-error-10/","text":"docker registry push错误“server gave HTTP response to HTTPS client” 系统环境：centos7 docker版本： 1.12.3（注意版本，可能存在不同版本设置不同的情况） docker registry版本：2.4.1 问题： 成功安装docker registry，在浏览器中输入http://192.168.159.159:5000/v2,成功返回json数据。在push 到docker registry时，报： [root@docker01 mysql]# docker push 192.168.159.159:5000/nginx The push refers to a repository [192.168.159.159:5000/nginx] Get https://192.168.159.159:5000/v2/: http: server gave HTTP response to HTTPS client 这个问题可能是由于客户端采用https，docker registry未采用https服务所致。一种处理方式是把客户对地址“192.168.159.159:5000”请求改为http。 目前很多文章都是通过修改docker的配置文件“etc/systemconfig/docker”，重启docker来解决这个问题。但发现docker1.12.3版本并无此文件，根据网上创建此文件，并填入相应内容，重启docker无效果，仍然报此错误。 解决方法： 在”/etc/docker/“目录下，创建”daemon.json“文件。在文件中写入： { &quot;insecure-registries&quot;:[&quot;192.168.159.159:5000&quot;] } 保存退出后，重启docker。问题解决： [root@docker01 mysql]# systemctl restart docker [root@docker01 mysql]# docker start 82b2384664e6 82b2384664e6 [root@docker01 mysql]# docker push 192.168.159.159:5000/nginx The push refers to a repository [192.168.159.159:5000/nginx] 2a7ae0eb82d1: Pushed 9b0e680891f9: Pushed 454e2d722383: Pushed 34b2304ded0d: Pushed window server 2016,默认安装docker的配置文件在“C:\\ProgramData\\docker\\config\\”。可以在该目录下创建”daemon.json“文件，解决此问题。","tags":[{"name":"docker","slug":"docker","permalink":"http://dennis.pathto.top/tags/docker/"},{"name":"cloud","slug":"cloud","permalink":"http://dennis.pathto.top/tags/cloud/"}]},{"title":"9.docker本地仓库","date":"2017-10-02T15:06:51.000Z","path":"2017/10/02/docker-local-dockerhub-9/","text":"下载镜像仓库[root@docker01 mysql]# docker pull registry Using default tag: latest latest: Pulling from library/registry 90f4dba627d6: Pull complete Digest: sha256:0f8fe61fa337b8ef02217702ba979b47a7d68717d4628f31592ebff85915f3ba Status: Downloaded newer image for registry:latest [root@docker01 mysql]# docker images REPOSITORY TAG IMAGE ID CREATED SIZE registry latest 28525f9a6e46 12 days ago 33.2MB 启动并且挂载镜像仓库到本地磁盘[root@docker01 mysql]# docker run -d -p 5000:5000 -v /registry:/var/lib/registry registry 82b2384664e6f360e636f1fadf31ca3adf762906139a3c79ba73e67d0b157c0d [root@docker01 mysql]# docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 82b2384664e6 registry &quot;/entrypoint.sh /e...&quot; 7 seconds ago Up 5 seconds 0.0.0.0:5000-&gt;5000/tcp clever_jang 给一个本地镜像打个标签然后上传[root@docker01 mysql]# docker tag workpress/nginx:1.0 192.168.159.159:5000/nginx:1.1 [root@docker01 mysql]# docker images REPOSITORY TAG IMAGE ID CREATED SIZE registry latest 28525f9a6e46 12 days ago 33.2MB workpress/nginx 1.0 2fbed074486c 7 weeks ago 652MB 192.168.159.159:5000/nginx 1.1 2fbed074486c 7 weeks ago 652MB 直接上传到仓库docker push 192.168.159.159:5000/nginx:1.1 查看挂载目录是否有镜像[root@docker01 mysql]# ls /registry/ docker 关于本地镜像的查看[root@docker01 mysql]# curl http://192.168.159.159:5000/v2/_catalog {&quot;repositories&quot;:[&quot;nginx&quot;]} 有1个镜像，可以获取他的标签信息以便下载[root@docker01 mysql]# curl http://192.168.159.159:5000/v2/nginx/tags/list {&quot;name&quot;:&quot;nginx&quot;,&quot;tags&quot;:[&quot;1.1&quot;]} 直接下载镜像docker pull 192.168.159.159:5000/nginx:1.1 192.168.159.159:5000是仓库地址docker -rmi 只能删除本地的，不能删除仓库里面的","tags":[{"name":"docker","slug":"docker","permalink":"http://dennis.pathto.top/tags/docker/"},{"name":"cloud","slug":"cloud","permalink":"http://dennis.pathto.top/tags/cloud/"}]},{"title":"8.使用Dockerfile搭建自己的博客","date":"2017-10-02T15:06:46.000Z","path":"2017/10/02/docker-dockerfile-workpress-8/","text":"Dockerfile 目录结构[root@docker01 file]# tree -L 2 --charset ASCII . |-- mysql | |-- Dockerfile | |-- epel-6.repo | |-- my.cnf | `-- startup.sh |-- nginx | |-- Dockerfile | |-- nginx-1.11.10 | |-- nginx-1.11.10.tar.gz | |-- nginx.conf | `-- nginx_default.conf | `-- php-fpm |-- Centos-6.repo |-- Dockerfile |-- epel-6.repo |-- php-5.6.31 `-- php-5.6.31.tar.gz mysql,nginx,php的yum源Centos-6.repo[root@docker01 php-fpm]# cat Centos-6.repo # CentOS-Base.repo [base] name=CentOS-$releasever - Base - mirrors.aliyun.com failovermethod=priority baseurl=http://mirrors.aliyun.com/centos/$releasever/os/$basearch/ http://mirrors.aliyuncs.com/centos/$releasever/os/$basearch/ #mirrorlist=http://mirrorlist.centos.org/?release=$releasever&amp;arch=$basearch&amp;repo=os gpgcheck=1 gpgkey=http://mirrors.aliyun.com/centos/RPM-GPG-KEY-CentOS-6 #released updates [updates] name=CentOS-$releasever - Updates - mirrors.aliyun.com failovermethod=priority baseurl=http://mirrors.aliyun.com/centos/$releasever/updates/$basearch/ http://mirrors.aliyuncs.com/centos/$releasever/updates/$basearch/ #mirrorlist=http://mirrorlist.centos.org/?release=$releasever&amp;arch=$basearch&amp;repo=updates gpgcheck=1 gpgkey=http://mirrors.aliyun.com/centos/RPM-GPG-KEY-CentOS-6 #additional packages that may be useful [extras] name=CentOS-$releasever - Extras - mirrors.aliyun.com failovermethod=priority baseurl=http://mirrors.aliyun.com/centos/$releasever/extras/$basearch/ http://mirrors.aliyuncs.com/centos/$releasever/extras/$basearch/ #mirrorlist=http://mirrorlist.centos.org/?release=$releasever&amp;arch=$basearch&amp;repo=extras gpgcheck=1 gpgkey=http://mirrors.aliyun.com/centos/RPM-GPG-KEY-CentOS-6 #additional packages that extend functionality of existing packages [centosplus] name=CentOS-$releasever - Plus - mirrors.aliyun.com failovermethod=priority baseurl=http://mirrors.aliyun.com/centos/$releasever/centosplus/$basearch/ http://mirrors.aliyuncs.com/centos/$releasever/centosplus/$basearch/ #mirrorlist=http://mirrorlist.centos.org/?release=$releasever&amp;arch=$basearch&amp;repo=centosplus gpgcheck=1 enabled=0 gpgkey=http://mirrors.aliyun.com/centos/RPM-GPG-KEY-CentOS-6 #contrib - packages by Centos Users [contrib] name=CentOS-$releasever - Contrib - mirrors.aliyun.com failovermethod=priority baseurl=http://mirrors.aliyun.com/centos/$releasever/contrib/$basearch/ http://mirrors.aliyuncs.com/centos/$releasever/contrib/$basearch/ #mirrorlist=http://mirrorlist.centos.org/?release=$releasever&amp;arch=$basearch&amp;repo=contrib gpgcheck=1 enabled=0 gpgkey=http://mirrors.aliyun.com/centos/RPM-GPG-KEY-CentOS-6[root@docker01 php-fpm]# [root@docker01 php-fpm]# cat Centos-6.repo # CentOS-Base.repo # # The mirror system uses the connecting IP address of the client and the # update status of each mirror to pick mirrors that are updated to and # geographically close to the client. You should use this for CentOS updates # unless you are manually picking other mirrors. # # If the mirrorlist= does not work for you, as a fall back you can try the # remarked out baseurl= line instead. # # [base] name=CentOS-$releasever - Base - mirrors.aliyun.com failovermethod=priority baseurl=http://mirrors.aliyun.com/centos/$releasever/os/$basearch/ http://mirrors.aliyuncs.com/centos/$releasever/os/$basearch/ #mirrorlist=http://mirrorlist.centos.org/?release=$releasever&amp;arch=$basearch&amp;repo=os gpgcheck=1 gpgkey=http://mirrors.aliyun.com/centos/RPM-GPG-KEY-CentOS-6 #released updates [updates] name=CentOS-$releasever - Updates - mirrors.aliyun.com failovermethod=priority baseurl=http://mirrors.aliyun.com/centos/$releasever/updates/$basearch/ http://mirrors.aliyuncs.com/centos/$releasever/updates/$basearch/ #mirrorlist=http://mirrorlist.centos.org/?release=$releasever&amp;arch=$basearch&amp;repo=updates gpgcheck=1 gpgkey=http://mirrors.aliyun.com/centos/RPM-GPG-KEY-CentOS-6 #additional packages that may be useful [extras] name=CentOS-$releasever - Extras - mirrors.aliyun.com failovermethod=priority baseurl=http://mirrors.aliyun.com/centos/$releasever/extras/$basearch/ http://mirrors.aliyuncs.com/centos/$releasever/extras/$basearch/ #mirrorlist=http://mirrorlist.centos.org/?release=$releasever&amp;arch=$basearch&amp;repo=extras gpgcheck=1 gpgkey=http://mirrors.aliyun.com/centos/RPM-GPG-KEY-CentOS-6 #additional packages that extend functionality of existing packages [centosplus] name=CentOS-$releasever - Plus - mirrors.aliyun.com failovermethod=priority baseurl=http://mirrors.aliyun.com/centos/$releasever/centosplus/$basearch/ http://mirrors.aliyuncs.com/centos/$releasever/centosplus/$basearch/ #mirrorlist=http://mirrorlist.centos.org/?release=$releasever&amp;arch=$basearch&amp;repo=centosplus gpgcheck=1 enabled=0 gpgkey=http://mirrors.aliyun.com/centos/RPM-GPG-KEY-CentOS-6 #contrib - packages by Centos Users [contrib] name=CentOS-$releasever - Contrib - mirrors.aliyun.com failovermethod=priority baseurl=http://mirrors.aliyun.com/centos/$releasever/contrib/$basearch/ http://mirrors.aliyuncs.com/centos/$releasever/contrib/$basearch/ #mirrorlist=http://mirrorlist.centos.org/?release=$releasever&amp;arch=$basearch&amp;repo=contrib gpgcheck=1 enabled=0 gpgkey=http://mirrors.aliyun.com/centos/RPM-GPG-KEY-CentOS-6 epel-6.repo[root@docker01 php-fpm]# cat epel-6.repo [epel] name=Extra Packages for Enterprise Linux 6 - $basearch baseurl=http://mirrors.aliyun.com/epel/6/$basearch http://mirrors.aliyuncs.com/epel/6/$basearch #mirrorlist=https://mirrors.fedoraproject.org/metalink?repo=epel-6&amp;arch=$basearch failovermethod=priority enabled=1 gpgcheck=0 gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-EPEL-6 [epel-debuginfo] name=Extra Packages for Enterprise Linux 6 - $basearch - Debug baseurl=http://mirrors.aliyun.com/epel/6/$basearch/debug http://mirrors.aliyuncs.com/epel/6/$basearch/debug #mirrorlist=https://mirrors.fedoraproject.org/metalink?repo=epel-debug-6&amp;arch=$basearch failovermethod=priority enabled=0 gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-EPEL-6 gpgcheck=0 [epel-source] name=Extra Packages for Enterprise Linux 6 - $basearch - Source baseurl=http://mirrors.aliyun.com/epel/6/SRPMS http://mirrors.aliyuncs.com/epel/6/SRPMS #mirrorlist=https://mirrors.fedoraproject.org/metalink?repo=epel-source-6&amp;arch=$basearch failovermethod=priority enabled=0 gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-EPEL-6 gpgcheck=0 构建nginx镜像Dockerfile[root@docker01 nginx]# cat Dockerfile #lnmp centos 6.0 from centos:centos6 MAINTAINER dennis52o1314@163.com ENV APP_DIR /web add nginx-1.11.10 /nginx-1.11.10 RUN yum -y groupinstall &quot;Development Tools&quot; &quot;Server Platform Deveopment&quot; RUN yum -y install openssl-devel pcre-devel RUN useradd nginx -s /sbin/nologin RUN cd /nginx-1.11.10 &amp;&amp; ./configure --prefix=/usr/local/nginx --user=nginx --group=nginx --with-http_ssl_module --with-http_flv_module --with-http_stub_status_module --with-http_gzip_static_module --with-pcre &amp;&amp; make &amp;&amp; make install RUN mkdir /usr/local/nginx/conf/vhosts RUN mkdir /var/log/nginx ADD nginx.conf /usr/local/nginx/conf/nginx.conf ADD nginx_default.conf /usr/local/nginx/conf/vhosts/default.conf EXPOSE 80 CMD [&quot;/usr/local/nginx/sbin/nginx&quot;] nginx.conf[root@docker01 nginx]# cat nginx.conf user nginx; worker_processes 1; daemon off; error_log /var/log/nginx/error.log warn; pid /var/run/nginx.pid; events { worker_connections 1024; } http { default_type application/octet-stream; log_format main &apos;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &apos; &apos;$status $body_bytes_sent &quot;$http_referer&quot; &apos; &apos;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&apos;; access_log /var/log/nginx/access.log main; sendfile on; tcp_nopush on; tcp_nodelay on; keepalive_timeout 65; types_hash_max_size 2048; gzip on; gzip_disable &quot;msie6&quot;; gzip_vary on; gzip_proxied any; gzip_comp_level 6; gzip_types text/plain text/css application/json application/x-javascript text/xml application/xml application/xml+rss text/javascript; include /usr/local/nginx/conf/vhosts/*.conf; } nginx相关php配置nginx_default.conf[root@docker01 nginx]# cat nginx_default.conf server { listen 80 default_server; server_name localhost; #charset koi8-r; location / { root /web; index index.php index.html index.htm; } # redirect server error pages to the static page /50x.html # error_page 500 502 503 504 /50x.html; location = /50x.html { root APP_DIR; } # Disable nginx log write favicon.ico location = /favicon.ico { log_not_found off; access_log off; } # pass the PHP scripts to FastCGI server listening on port 9000 # location ~ \\.php$ { root /web; fastcgi_pass php:9000; #fastcgi_pass unix:/tmp/php-fpm.sock; fastcgi_index index.php; fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name; include fastcgi_params; } } 构建nginx镜像 [root@docker01 nginx]# docker build -t workpress/nginx:1.0 . 查看workpress/nginx镜像 [root@docker01 nginx]# docker images REPOSITORY TAG IMAGE ID CREATED SIZE workpress/nginx 1.0 2fbed074486c 7 weeks ago 652MB composemultipleworkpress_nginx latest 85bccc12873c 7 weeks ago 652MB &lt;none&gt; &lt;none&gt; 47bbd62f8b03 7 weeks ago 652MB workpress/mysql 1.0 6549c4af7357 7 weeks ago 359MB workpress/php 1.0 44e9179f7098 7 weeks ago 1.2GB &lt;none&gt; &lt;none&gt; 8e3e252129d5 7 weeks ago 626MB centos centos6 7ea307891843 8 weeks ago 194MB centos latest 328edcd84f1b 8 weeks ago 193MB daocloud.io/library/nginx latest b8efb18f159b 2 months ago 107MB phpDockerfile[root@docker01 php-fpm]# cat Dockerfile from centos:centos6 ADD Centos-6.repo /etc/yum.repos.d/CentOS-Base.repo ADD epel-6.repo /etc/yum.repos.d/epel.repo add php-5.6.31 /php-5.6.31 run yum -y groupinstall &quot;Desktop Platform Development&quot; run yum -y install libmcrypt-devel bzip2-devel gcc openssl-devel php-mcrypt libmcrypt run cd /php-5.6.31 &amp;&amp; ./configure --prefix=/usr/local/php --with-mysql=mysqlnd --with-pdo-mysql=mysqlnd --with-mysqli=mysqlnd --with-openssl --enable-mbstring --with-freetype-dir --with-jpeg-dir --with-png-dir --with-zlib --with-libxml-dir=/usr --enable-xml --enable-sockets --with-mcrypt --with-bz2 --enable-fpm --with-gd &amp;&amp; make &amp;&amp; make install run cp /php-5.6.31/php.ini-production /usr/local/php/etc/php.ini run mv /usr/local/php/etc/php-fpm.conf.default /usr/local/php/etc/php-fpm.conf run useradd -M -s /sbin/nologin php run sed -i -e &apos;s\\;pid = run/php-fpm.pid\\pid = run/php-fpm.pid\\g&apos; -e &apos;s\\nobody\\php\\g&apos; -e &apos;s\\listen = 127.0.0.1:9000\\listen = 0.0.0.0:9000\\g&apos; /usr/local/php/etc/php-fpm.conf run sed -i &apos;s\\;daemonize = yes\\daemonize = no\\g&apos; /usr/local/php/etc/php-fpm.conf EXPOSE 9000 CMD [&quot;/usr/local/php/sbin/php-fpm&quot;] 构建php镜像docker build -t workpress/php:1.0 . mysqlDockerfile[root@docker01 mysql]# cat Dockerfile FROM centos:centos6 MAINTAINER dennis52o1314@163.com RUN yum install -y mysql-server mysql ADD ./startup.sh /opt/startup.sh RUN chmod +x /opt/startup.sh EXPOSE 3306 CMD [&quot;/bin/bash&quot;,&quot;/opt/startup.sh&quot;] my.cnf[root@docker01 mysql]# cat my.cnf [mysqld] datadir=/var/lib/mysql socket=/var/lib/mysql/mysql.sock user=mysql # Disabling symbolic-links is recommended to prevent assorted security risks symbolic-links=0 [mysqld_safe] log-error=/var/log/mysqld.log pid-file=/var/lib/mysql/mysqld.pid startup.sh[root@docker01 mysql]# cat startup.sh #!/bin/bash if [ ! -f /var/lib/mysql/ibdata1 ]; then mysql_install_db /usr/bin/mysqld_safe &amp; sleep 10s mysql -e &quot;grant all privileges on *.* to &apos;root&apos;@&apos;%&apos; identified by &apos;123456&apos;; FLUSH PRIVILEGES;&quot; killall mysqld sleep 10s fi /usr/bin/mysqld_safe 构建mysql镜像docker build -t workpress/mysql:1.0 . 启动博客系统docker run -dit --name php -v /web:/web workpress/php:1.0 docker run -dit --name web -p 80:80 -v /web:/web --link php:php workpress/nginx:1.0 docker run -dit --name mysql -p 3306:3306 -v /opt/data:/var/lib/mysql workpress/mysql:1.0","tags":[{"name":"docker","slug":"docker","permalink":"http://dennis.pathto.top/tags/docker/"},{"name":"cloud","slug":"cloud","permalink":"http://dennis.pathto.top/tags/cloud/"}]},{"title":"7.dockerfile","date":"2017-10-02T15:06:41.000Z","path":"2017/10/02/docker-dockerfile-7/","text":"使用dockerfile构建一个nginx镜像准备配置文件mkdir nginx [root@bogon nginx]# vi epel-6.repo [epel] name=Extra Packages for Enterprise Linux 6 - $basearch baseurl=http://mirrors.aliyun.com/epel/6/$basearch http://mirrors.aliyuncs.com/epel/6/$basearch #mirrorlist=https://mirrors.fedoraproject.org/metalink?repo=epel-6&amp;arch=$basearch failovermethod=priority enabled=1 gpgcheck=0 gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-EPEL-6 [epel-debuginfo] name=Extra Packages for Enterprise Linux 6 - $basearch - Debug baseurl=http://mirrors.aliyun.com/epel/6/$basearch/debug http://mirrors.aliyuncs.com/epel/6/$basearch/debug #mirrorlist=https://mirrors.fedoraproject.org/metalink?repo=epel-debug-6&amp;arch=$basearch failovermethod=priority enabled=0 gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-EPEL-6 gpgcheck=0 [epel-source] name=Extra Packages for Enterprise Linux 6 - $basearch - Source baseurl=http://mirrors.aliyun.com/epel/6/SRPMS http://mirrors.aliyuncs.com/epel/6/SRPMS #mirrorlist=https://mirrors.fedoraproject.org/metalink?repo=epel-source-6&amp;arch=$basearch failovermethod=priority enabled=0 gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-EPEL-6 gpgcheck=0 [root@bogon nginx]# cat Dockerfile #author dennis from centos:centos6 ADD epel-6.repo /etc/yum.repos.d RUN yum install -y net-tools RUN yum install -y iputils RUN yum install -y nginx RUN echo &quot;daemon off;&quot;&gt;&gt; /etc/nginx/nginx.conf CMD service nginx start 上面运行nginx前台运行，可以保证容器不会自动退出,容器没有一个运行的进程是会自动退出的,如果不这样运行，也要运行一个其他的长运行的进程，如top命令 [root@bogon nginx]# docker build -t mynginx:1.0 . [root@bogon nginx]# docker images REPOSITORY TAG IMAGE ID CREATED SIZE mynginx 1.0 f5387b3daae3 22 seconds ago 446MB test latest b5e4ce650f0d 5 hours ago 194MB redis latest b6dddb991dfa 9 days ago 107MB centos centos6 5dedbd63518e 2 weeks ago 194MB daocloud.io/library/nginx 1.13.2 2f7f7bce8929 2 months ago 107MB #mynginx就是使用docker file构建的镜像 通过自己构建的镜像，启动容器[root@bogon nginx]# docker run -it --name mynginx01 f5387b3daae3 /bin/bash #新建另一个ssh回话，启动另一个容器 [root@bogon ~]# docker run -it --name mynginx02 f5387b3daae3 /bin/bash 容器连通性测试mynginx01[root@2887c1ce177b /]# ping 172.17.0.5 PING 172.17.0.5 (172.17.0.5) 56(84) bytes of data. 64 bytes from 172.17.0.5: icmp_seq=1 ttl=64 time=0.289 ms 64 bytes from 172.17.0.5: icmp_seq=2 ttl=64 time=0.176 ms ^C --- 172.17.0.5 ping statistics --- 2 packets transmitted, 2 received, 0% packet loss, time 1947ms rtt min/avg/max/mdev = 0.176/0.232/0.289/0.058 ms mynginx02[root@db8d5e5bb1a2 /]# ip a 1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN qlen 1 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever 72: eth0@if73: &lt;BROADCAST,MULTICAST,UP,LOWER_UP,M-DOWN&gt; mtu 1500 qdisc noqueue state UP link/ether 02:42:ac:11:00:05 brd ff:ff:ff:ff:ff:ff inet 172.17.0.5/16 scope global eth0 valid_lft forever preferred_lft forever [root@db8d5e5bb1a2 /]# ping 172.17.0.5 PING 172.17.0.5 (172.17.0.5) 56(84) bytes of data. 64 bytes from 172.17.0.5: icmp_seq=1 ttl=64 time=0.098 ms 64 bytes from 172.17.0.5: icmp_seq=2 ttl=64 time=0.090 ms ^C --- 172.17.0.5 ping statistics --- 2 packets transmitted, 2 received, 0% packet loss, time 1453ms rtt min/avg/max/mdev = 0.090/0.094/0.098/0.004 ms 宿主机[root@bogon ~]# ping 172.17.0.5 PING 172.17.0.5 (172.17.0.5) 56(84) bytes of data. 64 bytes from 172.17.0.5: icmp_seq=1 ttl=64 time=0.197 ms 64 bytes from 172.17.0.5: icmp_seq=2 ttl=64 time=0.120 ms ^C --- 172.17.0.5 ping statistics --- 2 packets transmitted, 2 received, 0% packet loss, time 1000ms rtt min/avg/max/mdev = 0.120/0.158/0.197/0.040 ms 结论：同一个宿主机中的容器相互连通的，宿主机也和容器相互连通 单机网络架构 image 同一个系统docker共享同一个网桥 构建一个tomcat镜像创建tomcat目录,新建Dockerfile和相关包[root@node3 tomcat]# tree ├── apache-tomcat-7.0.76.tar.gz ├── Centos-6.repo ├──Dockerfile ├── epel-6.repo ├── jdk-8u121-linux-x64.tar.gz └──supervisord.conf 编写Dockerfile[root@node3 tomcat]# cat Dockerfile #pull down centos image FROM centos:centos6 MAINTAINER dennis52o1314@163.com ADD epel-6.repo /etc/yum.repos.d/ ADD Centos-6.repo /etc/yum.repos.d/ RUN yum install -y supervisor RUN mkdir -p /var/log/supervisor ADD ./apache-tomcat-7.0.76.tar.gz /opt ADD ./jdk-8u121-linux-x64.tar.gz /opt #set environment variable ENV JAVA_HOME /opt/jdk1.8.0_121 ENV PATH $JAVA_HOME/bin:$PATH ENV CATALINA_HOME /opt/apache-tomcat-7.0.76 ENV PATH $PATH:$CATALINA_HOME/bin EXPOSE 8080 COPY supervisord.conf /etc/supervisor/supervisord.conf CMD supervisord -c /etc/supervisor/supervisord.conf","tags":[{"name":"docker","slug":"docker","permalink":"http://dennis.pathto.top/tags/docker/"},{"name":"cloud","slug":"cloud","permalink":"http://dennis.pathto.top/tags/cloud/"}]},{"title":"6.docker-存储","date":"2017-10-02T15:06:36.000Z","path":"2017/10/02/docker-storagy-6/","text":"Volume特点 持久化存储文件 容器间共享文件 修改文件立即生效 docker提出的Vlolume概念，简单来说，就是目录或者是文件，他可以绕过联合文件系统，而以正常的文件或者目录的形式存于宿主机上 为容器添加卷[root@bogon /]# docker run -dit --name test -v /test redis /bin/bash root@9d7e5b04b3ac:/data# ls root@9d7e5b04b3ac:/data# cd / root@9d7e5b04b3ac:/# ls bin boot data dev etc home lib lib64 media mnt opt proc root run sbin srv sys test tmp usr var root@9d7e5b04b3ac:/# cd test root@e96a304b9270:/test# echo &quot;hello,docker&quot;&gt;txt [root@bogon /]# docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES e96a304b9270 redis &quot;docker-entrypoint...&quot; 3 minutes ago Up 3 minutes 6379/tcp test [root@bogon /]# docker inspect e96a304b9270 &quot;Mounts&quot;: [ { &quot;Type&quot;: &quot;volume&quot;, &quot;Name&quot;: &quot;47e324fbd7beb5cc91e7b130108cab3e7c53cc86dcc1b6e3a020d18e878c8366&quot;, &quot;Source&quot;: &quot;/var/lib/docker/volumes/47e324fbd7beb5cc91e7b130108cab3e7c53cc86dcc1b6e3a020d18e878c8366/_data&quot;, &quot;Destination&quot;: &quot;/test&quot;, &quot;Driver&quot;: &quot;local&quot;, &quot;Mode&quot;: &quot;&quot;, &quot;RW&quot;: true, &quot;Propagation&quot;: &quot;&quot; }, { &quot;Type&quot;: &quot;volume&quot;, &quot;Name&quot;: &quot;cd005b9b9b79bfade620ea744741f51e4c05956ed890a0215e07ab6d26b0c94a&quot;, &quot;Source&quot;: &quot;/var/lib/docker/volumes/cd005b9b9b79bfade620ea744741f51e4c05956ed890a0215e07ab6d26b0c94a/_data&quot;, &quot;Destination&quot;: &quot;/data&quot;, &quot;Driver&quot;: &quot;local&quot;, &quot;Mode&quot;: &quot;&quot;, &quot;RW&quot;: true, &quot;Propagation&quot;: &quot;&quot; } ] 上面显示挂在了data和test到容器中 在宿主机中可以看到容器中的文件[root@bogon /]# cat /var/lib/docker/volumes/47e324fbd7beb5cc91e7b130108cab3e7c53cc86dcc1b6e3a020d18e878c8366/_data/txt hello,docker 删除容器和相应的卷docker rm -f -v test 运行一个容器，使用前面容器使用的卷,卷可以被多个容器共享docker run -it --name test2 --volumes-from test nginx /bin/bash 注意：上面创建一个test2容器，使用到了test的卷，这样，即使删除了容器test，相应的卷也不会被删除;在test2中修改文件，可以同步到test 本地文件映射到容器docker run -dit -v /test1/:/test1/ redis /bin/bash 用途：数据库文件放到本地硬盘 备份[root@bogon ~]#docker run -dit --name test01 -v /test1 /bin/bash [root@bogon ~]#docker exec -it test01 /bin/bash [root@f664684c31b1 /]# cat /test1/tt xxxxxxxxx [root@f664684c31b1 /]# exit [root@bogon ~]#docker run --volumes-from test01 -v $(pwd):/backup redis tar cvf /backup/backup.tar /test1 [root@bogon ~]# ls backup.tar #创建一个redis镜像的容器，共享test01容器的卷，打包test1目录，备份到本地磁盘 这个命令运行一个redis镜像的一个容器实例，共享test01容器的卷，把/test1打包成backup.tar,然后复制到本地 恢复到新容器中[root@bogon ~]# docker run -v $(pwd):/backup redis tar xf /backup/backup.tar [root@bogon ~]# docker ps -a CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES ca884f53b748 redis &quot;docker-entrypoint...&quot; 36 seconds ago Exited (0) 35 seconds ago jovial_heisenberg 1c60f322e204 redis &quot;docker-entrypoint...&quot; 25 minutes ago Exited (0) 23 minutes ago naughty_lalande 86abe2926755 redis &quot;docker-entrypoint...&quot; 25 minutes ago Exited (2) 25 minutes ago priceless_heyrovsky c23fea7f72ba redis &quot;docker-entrypoint...&quot; 26 minutes ago Exited (2) 26 minutes ago thirsty_lovelace f664684c31b1 b5e4ce650f0d &quot;/bin/bash&quot; About an hour ago Up About an hour test01 [root@bogon ~]# docker run -dit --name recovery --volumes-from ca884f53b748 redis /bin/bash 7087d6e9db40f4870655b86ef767271cfb073f4b2c7ebe98633c5c053bd111a1 #ca884f53b748是前面解压的容器 [root@bogon ~]# docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 7087d6e9db40 redis &quot;docker-entrypoint...&quot; 7 seconds ago Up 6 seconds 6379/tcp recovery f664684c31b1 b5e4ce650f0d &quot;/bin/bash&quot; About an hour ago Up About an hour test01 [root@bogon ~]# docker exec -it recovery /bin/bash root@7087d6e9db40:/data# ls test1 root@7087d6e9db40:/data# ls test1/ tt root@7087d6e9db40:/data# cat test1/tt xxxxxxxxx root@7087d6e9db40:/data# root@7087d6e9db40:/data# cd .. root@7087d6e9db40:/# ls backup bin boot data dev etc home lib lib64 media mnt opt proc root run sbin srv sys tmp usr var root@7087d6e9db40:/# ls backup/ anaconda-ks.cfg backup.tar centos_latest.tar root@7087d6e9db40:/#","tags":[{"name":"docker","slug":"docker","permalink":"http://dennis.pathto.top/tags/docker/"},{"name":"cloud","slug":"cloud","permalink":"http://dennis.pathto.top/tags/cloud/"}]},{"title":"5.docker容器","date":"2017-10-02T15:06:31.000Z","path":"2017/10/02/docker-container-5/","text":"创建nginx容器docker create nginx 查看全部容器，包括停止的容器docker ps -a 进入运行中的容器[root@bogon ~]# docker exec -it 174a93960fec /bin/bash 停止和启动容器docker stop/start CONTAIN_ID 运行容器docker run nginx #ctrl+c之后会退出 docker run -it nginx /bin/bash #注意:exit会停止容器 起名docker run -d --name web nginx 端口映射docker run -d --name web -P nginx -P 随机端口映射 查看容器的端口映射docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 47bce8f71a7f nginx &quot;nginx -g &apos;daemon off&quot; 3 seconds ago Up 1 seconds 0.0.0.0:32769-&gt;80/tcp, 0.0.0.0:32768-&gt;443/tcp web 指定端口docker run -d --name web -p 80:80 nginx 查看端口映射情况docker inspect web 随机端口映射的容器,给容器停止再启动，容器的IP和端口可能是改变的。","tags":[{"name":"docker","slug":"docker","permalink":"http://dennis.pathto.top/tags/docker/"},{"name":"cloud","slug":"cloud","permalink":"http://dennis.pathto.top/tags/cloud/"}]},{"title":"4.镜像管理","date":"2017-10-02T15:06:26.000Z","path":"2017/10/02/docker-image-management-4/","text":"镜像的概念镜像是一个包含程序运行必要依赖环境和代码的只读文件，它采用分层的文件系统，将每一次改变以读写层的形式增加到原来的只读文件上。镜像是容器运行的基石。 下图展示的是Docker镜像的系统结构。其中，镜像的最底层必须是一个称为启动文件系统(bootfs)的镜像，用户不会与这一层直接打交道。bootfs的上层镜像就是我们熟知的根镜像。 镜像的本质是磁盘上一系列文件的集合。 image 镜像管理 image 查看本地所有镜像 [root@bogon ~]# docker images REPOSITORY TAG IMAGE ID CREATED SIZE centos centos6 5dedbd63518e 2 weeks ago 194MB REPOSITORY：仓库名称。 [namespace/centos]：由命名空间和实际的仓库名称组成。当你再Docker Hub上注册一个账户时，账户名自动成为你的命名空间，该命名空间是用来区分Docke Hub上注册的不同用户或者组织的。 [centos]：只有仓库名。属于顶级命名空间，只用于官方镜像。[dl.dockerpool.com:5000\\centos:7]：指定URL路径的方式。适用于自己搭建的Hub或者第三方Hub上获取镜像。 TAG：用于区分同一个仓库中的不同镜像。 IMAGE ID：镜像的唯一标识：64位HashID。 CREATED：镜像 的创建时间。 SIZE：镜像所占用的虚拟大小，该大小包含了所有共享文件的大小。 通配符，找到符合条件的一系列镜像[root@bogon ~]# docker images ce* REPOSITORY TAG IMAGE ID CREATED SIZE centos centos6 5dedbd63518e 2 weeks ago 194MB docker详细信息docker inspect [NAME]/[CONTAINER ID] [root@bogon ~]# docker inspect 5dedbd63518e [ { &quot;Id&quot;: &quot;sha256:5dedbd63518eeb45b6c9740d9ea6dee99a4a4c3d0202eac25ebc5fd43809f0a0&quot;, &quot;RepoTags&quot;: [ &quot;centos:centos6&quot; ], &quot;RepoDigests&quot;: [ &quot;centos@sha256:4a39ffcea665ed30a7ce6d1418b7d73a2aca05a97706b81b147a231d79e277e1&quot; ], &quot;Parent&quot;: &quot;&quot;, &quot;Comment&quot;: &quot;&quot;, &quot;Created&quot;: &quot;2017-09-13T14:43:07.389546878Z&quot;, &quot;Container&quot;: &quot;4e78ba220ff46b22adabc6ddc29f023b2879e170fa42100bcb57cb8024c67117&quot;, &quot;ContainerConfig&quot;: { &quot;Hostname&quot;: &quot;4e78ba220ff4&quot;, &quot;Domainname&quot;: &quot;&quot;, &quot;User&quot;: &quot;&quot;, &quot;AttachStdin&quot;: false, &quot;AttachStdout&quot;: false, &quot;AttachStderr&quot;: false, &quot;Tty&quot;: false, &quot;OpenStdin&quot;: false, &quot;StdinOnce&quot;: false, &quot;Env&quot;: [ &quot;PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin&quot; ], &quot;Cmd&quot;: [ &quot;/bin/sh&quot;, &quot;-c&quot;, &quot;#(nop) &quot;, &quot;CMD [\\&quot;/bin/bash\\&quot;]&quot; ], &quot;ArgsEscaped&quot;: true, &quot;Image&quot;: &quot;sha256:c0ebbd2d0382b51e2ba9d70eaac0d11f36c1273028605f7ed9b9285acf461187&quot;, &quot;Volumes&quot;: null, &quot;WorkingDir&quot;: &quot;&quot;, &quot;Entrypoint&quot;: null, &quot;OnBuild&quot;: null, &quot;Labels&quot;: { &quot;build-date&quot;: &quot;20170801&quot;, &quot;license&quot;: &quot;GPLv2&quot;, &quot;name&quot;: &quot;CentOS Base Image&quot;, &quot;vendor&quot;: &quot;CentOS&quot; } }, &quot;DockerVersion&quot;: &quot;17.06.2-ce&quot;, &quot;Author&quot;: &quot;&quot;, &quot;Config&quot;: { &quot;Hostname&quot;: &quot;&quot;, &quot;Domainname&quot;: &quot;&quot;, &quot;User&quot;: &quot;&quot;, &quot;AttachStdin&quot;: false, &quot;AttachStdout&quot;: false, &quot;AttachStderr&quot;: false, &quot;Tty&quot;: false, &quot;OpenStdin&quot;: false, &quot;StdinOnce&quot;: false, &quot;Env&quot;: [ &quot;PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin&quot; ], &quot;Cmd&quot;: [ &quot;/bin/bash&quot; ], &quot;ArgsEscaped&quot;: true, &quot;Image&quot;: &quot;sha256:c0ebbd2d0382b51e2ba9d70eaac0d11f36c1273028605f7ed9b9285acf461187&quot;, &quot;Volumes&quot;: null, &quot;WorkingDir&quot;: &quot;&quot;, &quot;Entrypoint&quot;: null, &quot;OnBuild&quot;: null, &quot;Labels&quot;: { &quot;build-date&quot;: &quot;20170801&quot;, &quot;license&quot;: &quot;GPLv2&quot;, &quot;name&quot;: &quot;CentOS Base Image&quot;, &quot;vendor&quot;: &quot;CentOS&quot; } }, &quot;Architecture&quot;: &quot;amd64&quot;, &quot;Os&quot;: &quot;linux&quot;, &quot;Size&quot;: 194318701, &quot;VirtualSize&quot;: 194318701, &quot;GraphDriver&quot;: { &quot;Data&quot;: { &quot;RootDir&quot;: &quot;/var/lib/docker/overlay/bcd6ac9a7fa2e0c6a0e5e414ff97b8819021dbaac1c3648ad135edecb2d44818/root&quot; }, &quot;Name&quot;: &quot;overlay&quot; }, &quot;RootFS&quot;: { &quot;Type&quot;: &quot;layers&quot;, &quot;Layers&quot;: [ &quot;sha256:80716a2ba414a02bb63de844acff6578a25b8583b01cf0a4c2653da50a31e305&quot; ] }, &quot;Metadata&quot;: { &quot;LastTagTime&quot;: &quot;0001-01-01T00:00:00Z&quot; } } ] 在本地寻找镜像/下载/运行docker run,命令运行时会在本地寻找镜像，找不到的时候就会去Docker Hub上面搜索并下载后运行。 [root@bogon ~]# docker run centos:centos6 uname -a Linux 15faceed6d66 3.10.0-514.el7.x86_64 #1 SMP Tue Nov 22 16:42:41 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux 查找镜像docker search [NAME]：下载之前可以通过search命令查找搜索符合的镜像 [root@bogon ~]# docker search nginx NAME DESCRIPTION STARS OFFICIAL AUTOMATED nginx Official build of Nginx. 6934 [OK] jwilder/nginx-proxy Automated Nginx reverse proxy for docker c... 1132 [OK] richarvey/nginx-php-fpm Container running Nginx + PHP-FPM capable ... 450 [OK] jrcs/letsencrypt-nginx-proxy-companion LetsEncrypt container to use with nginx as... 227 [OK] #省略...... NAME：镜像名称。 DESCRIPTION：镜像的简要描述。 STARS：用户对镜像的评分。 OFFICIAL：是否为官方镜像。 AUTOMATED：是否使用了自动构建。 拉取镜像到本地docker pull [NAME]：可以预先将镜像拉到本地。镜像名必须完整地包含命名空间和仓库名。如果一个仓库中存在多个镜像，还必须制定TAG，否则使用默认TAG：latest。 [root@bogon ~]# docker images REPOSITORY TAG IMAGE ID CREATED SIZE centos centos6 5dedbd63518e 2 weeks ago 194MB [root@bogon ~]# docker pull redis Using default tag: latest latest: Pulling from library/redis 065132d9f705: Pull complete be9835c27852: Pull complete f4a0d1212c38: Pull complete 43be9e9f0fb9: Pull complete a1bca8e532ec: Pull complete 382eae952932: Pull complete Digest: sha256:ebb396dc3ac00e8eb4a64c1c022ef41ef16801f31ff98b16916a77fdc7252e67 Status: Downloaded newer image for redis:latest [root@bogon ~]# docker images REPOSITORY TAG IMAGE ID CREATED SIZE redis latest b6dddb991dfa 9 days ago 107MB centos centos6 5dedbd63518e 2 weeks ago 194MB 删除docker rmi [NAME]/[CONTAINER ID] 对于不需要的镜像，可以使用rmi命令删除。与移除容器的命令rm相比，删除镜像的命令多了一个i，i即image的意思。 删除多个:多个镜像之间使用空格隔开。 -f：强制删除，大部分删不掉的情况可能是因为这个镜像被容器依赖了，可以选择先移除容器。 docker rm $(docker ps -a -q)：如果本地有很多已经停止运行的容器，一个个删除很麻烦，可以使用下面的命令将这些容器一次性删除，这样就能减少无用容器对镜像的依赖。 列出所有容器的IDdocker ps -a -q 从dockerhub获取docker浏览器打开网页http://hub.daocloud.io/ image 从daocluod的docker hub中拉取镜像docker pull daocloud.io/library/nginx:1.13.2 镜像命令添加标签[root@bogon ~]# docker images REPOSITORY TAG IMAGE ID CREATED SIZE redis latest b6dddb991dfa 9 days ago 107MB centos centos6 5dedbd63518e 2 weeks ago 194MB daocloud.io/library/nginx 1.13.2 2f7f7bce8929 2 months ago 107MB [root@bogon ~]# docker tag daocloud.io/library/nginx:1.13.2 nginx:1.13.2 [root@bogon ~]# docker images REPOSITORY TAG IMAGE ID CREATED SIZE redis latest b6dddb991dfa 9 days ago 107MB centos centos6 5dedbd63518e 2 weeks ago 194MB daocloud.io/library/nginx 1.13.2 2f7f7bce8929 2 months ago 107MB nginx 1.13.2 2f7f7bce8929 2 months ago 107MB daocloud.io/library/nginx:1.13.2和nginx:1.13.2的存储都是同一个 删除镜像[root@bogon ~]# docker rmi nginx:1.13.2 Untagged: nginx:1.13.2 [root@bogon ~]# docker images REPOSITORY TAG IMAGE ID CREATED SIZE redis latest b6dddb991dfa 9 days ago 107MB centos centos6 5dedbd63518e 2 weeks ago 194MB daocloud.io/library/nginx 1.13.2 2f7f7bce8929 2 months ago 107MB 删除镜像的时候，删除全部tag之后，才会被删除，如果删除的时候使用img_id,会删除镜像;如果被其他镜像依赖，镜像不能被删除 强制删除运行中的容器docker rm -f CONTAIN_ID 查看镜像的具体信息docker inspect f3c5dcc79825 运行一个容器Docker run –dit nginx name ##容器名称 link ##连接某个镜像 port ##端口映射 volum ##持久化存储 镜像的导入导出 docker save -o file.tar image_id [root@bogon ~]# docker images REPOSITORY TAG IMAGE ID CREATED SIZE redis latest b6dddb991dfa 9 days ago 107MB centos centos6 5dedbd63518e 2 weeks ago 194MB daocloud.io/library/nginx 1.13.2 2f7f7bce8929 2 months ago 107MB [root@bogon ~]# ls centos_late* centos_latest.tar 导入[root@bogon ~]# docker load &lt; centos_latest.tar 32d75bc97c41: Loading layer [==========================================&gt;] 134.6 MB/134.6 MB 87f743c24123: Loading layer [===========================================&gt;] 15.87 kB/15.87 kB bbe6cef52379: Loading layer [============================================&gt;] 11.78 kB/11.78 kB 3d515508d4eb: Loading layer [==========================================&gt;] 4.608 kB/4.608 kB 5972ebe5b524: Loading layer [==========================================&gt;] 3.072 kB/3.072 kB Loaded image ID: sha256:104bec311bcdfc882ea08fdd4f5417ecfb1976adea5a0c237e129c728cb7eada 查看导入的image[root@bogon ~]# docker load &lt; centos_latest.tar 80716a2ba414: Loading layer [==================================================&gt;] 202.4MB/202.4MB Loaded image ID: sha256:5dedbd63518eeb45b6c9740d9ea6dee99a4a4c3d0202eac25ebc5fd43809f0a0 [root@bogon ~]# docker images REPOSITORY TAG IMAGE ID CREATED SIZE redis latest b6dddb991dfa 9 days ago 107MB &lt;none&gt; &lt;none&gt; 5dedbd63518e 2 weeks ago 194MB daocloud.io/library/nginx 1.13.2 2f7f7bce8929 2 months ago 107MB 特别注意：导入导出的时候，容易造成层级的都是，出现各种问题，为了安全，不使用这种方式来导入导出 运行导入的镜像[root@bogon ~]# docker run -dit 5dedbd63518e 174a93960feccdd77f560b014dd6328e15973505a382e629cd3959407b864b47 进入容器[root@bogon ~]# docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 174a93960fec 5dedbd63518e &quot;/bin/bash&quot; 5 seconds ago Up 4 seconds suspicious_ptolemy [root@bogon ~]# docker exec -it 174a93960fec /bin/bash [root@174a93960fec /]# [root@174a93960fec /]# echo &quot;hell&quot;&gt; test.txt [root@174a93960fec /]# ls bin dev etc home lib lib64 lost+found media mnt opt proc root sbin selinux srv sys test.txt tmp usr var [root@174a93960fec /]# cat test.txt hello 创建一个已经存在的镜像ID然后用commit提交用commit 提交相关镜像生成一个新镜像： [root@bogon ~]# docker commit -m “ADD test.txt” -a “test” 174a93960fec test sha256:b5e4ce650f0d40da24be8387879bbf58078236fdbc0c41bac7121627c9f7dc16 -m:表示备注信息 -a:作者相关信息。 174a93960fec：就是刚刚我们创建的容器ID test: 表示生成的镜像名称 [root@bogon ~]# docker images REPOSITORY TAG IMAGE ID CREATED SIZE test latest b5e4ce650f0d 41 seconds ago 194MB redis latest b6dddb991dfa 9 days ago 107MB daocloud.io/library/nginx 1.13.2 2f7f7bce8929 2 months ago 107MB [root@bogon ~]# docker run test cat test.txt hello 对镜像的修改，不推荐这种方式，应该使用Dockerfile来操作的 查看镜像的层级[root@bogon ~]# docker history test IMAGE CREATED CREATED BY SIZE COMMENT b5e4ce650f0d 3 minutes ago /bin/bash 140B ADD test.txt 5dedbd63518e 2 weeks ago /bin/sh -c #(nop) CMD [&quot;/bin/bash&quot;] 0B &lt;missing&gt; 2 weeks ago /bin/sh -c #(nop) LABEL name=CentOS Base ... 0B &lt;missing&gt; 2 weeks ago /bin/sh -c #(nop) ADD file:e253dfb8c4027c8... 194MB 本地文件[root@bogon ~]# ll cd /var/lib/docker/ ls: 无法访问cd: 没有那个文件或目录 /var/lib/docker/: 总用量 4 drwx------. 2 root root 24 10月 1 19:42 builder drwx------. 4 root root 150 10月 1 21:36 containers #容器运行相关信息 drwx------. 3 root root 21 10月 1 19:42 image #各层相关信息 drwxr-x---. 3 root root 19 10月 1 19:42 network drwx------. 17 root root 4096 10月 1 21:36 overlay drwx------. 4 root root 32 10月 1 19:42 plugins drwx------. 2 root root 6 10月 1 19:42 swarm drwx------. 2 root root 6 10月 1 21:23 tmp drwx------. 2 root root 6 10月 1 19:42 trust drwx------. 2 root root 25 10月 1 19:42 volumes #数据卷相关信息 centos使用这个来做级联文件系统,ubuntu使用aofs来做级联联合文件系统 [root@bogon ~]# docker inspect test [ &quot;RootFS&quot;: { &quot;Type&quot;: &quot;layers&quot;, &quot;Layers&quot;: [ &quot;sha256:80716a2ba414a02bb63de844acff6578a25b8583b01cf0a4c2653da50a31e305&quot;, &quot;sha256:2d113ac4862223fde011e2bf9604563f13f630e74fdf72f7d27ca6830a07ad5c&quot; ] }, ] 我们通过层级ID可以看到rootfs的相关信息","tags":[{"name":"docker","slug":"docker","permalink":"http://dennis.pathto.top/tags/docker/"},{"name":"cloud","slug":"cloud","permalink":"http://dennis.pathto.top/tags/cloud/"}]},{"title":"3.docker常用的简单管理命令","date":"2017-10-02T15:06:21.000Z","path":"2017/10/02/docker-management-cmd-3/","text":"查看本地docker镜像docker images 在docker容器中执行linux命令#如果本地没有想过镜像，会自动下载 [root@bogon ~]# docker run centos:centos6 uname -a Unable to find image &apos;centos:centos6&apos; locally centos6: Pulling from library/centos 后台运行docker容器docker run -dit -P nginx 查看运行的dockerdocker ps #可以看到CONTAINER_ID 查看docker的日志docker logs CONTAINER_ID 登录到docker容器docker exec -it CONTAINER_ID 停止容器docker stop CONTAINER_ID 查看帮助docker run --help 删除容器docker rm CONTAINER_ID 删除镜像docker rmi IMAGE_ID #注意IMAGE_ID可以使用docker images来看到","tags":[{"name":"docker","slug":"docker","permalink":"http://dennis.pathto.top/tags/docker/"},{"name":"cloud","slug":"cloud","permalink":"http://dennis.pathto.top/tags/cloud/"}]},{"title":"2.安装docker","date":"2017-10-02T15:06:16.000Z","path":"2017/10/02/docker-installation-2/","text":"选择操作系统版本[root@localhost ~]# cat /etc/redhat-release CentOS Linux release 7.3.1611 (Core) 配置网卡固定ip地址，开机激活忘啦,并且能够联网 TYPE=Ethernet BOOTPROTO=static DEFROUTE=yes PEERDNS=yes PEERROUTES=yes IPV4_FAILURE_FATAL=no IPV6INIT=yes IPV6_AUTOCONF=yes IPV6_DEFROUTE=yes IPV6_PEERDNS=yes IPV6_PEERROUTES=yes IPV6_FAILURE_FATAL=no IPV6_ADDR_GEN_MODE=stable-privacy NAME=ens33 UUID=76fc1a45-394d-45bb-8796-6b449d0a77bb DEVICE=ens33 ONBOOT=yes GATEWAY=192.168.100.2 DWADDR=00:0c:29:b9:b3:a6 IPADDR=192.168.100.128 DNS1=114.114.114.114 DNS2=8.8.8.8 配置源由于国内的源比较卡，所以我们推荐使用daocloud的方式 curl -sSL https://get.daocloud.io/docker | sh 配置镜像国内通常默认docker hub的网速不稳定，可以配置daocloud提供的docker hub [root@localhost ~]# curl -sSL https://get.daocloud.io/daotools/set_mirror.sh | sh -s http://681a96df.m.daocloud.io docker version &gt;= 1.12 {&quot;registry-mirrors&quot;: [&quot;http://681a96df.m.daocloud.io&quot;]} Success. You need to restart docker to take effect: sudo systemctl restart docker 查看自己配置的docker hub[root@localhost ~]# cat /etc/docker/daemon.json {&quot;registry-mirrors&quot;: [&quot;http://681a96df.m.daocloud.io&quot;]} 重启dockersystemctl restart docker 查看docker基本信息[root@localhost ~]# docker info Containers: 0 Running: 0 Paused: 0 Stopped: 0 Images: 0 Server Version: 17.09.0-ce Storage Driver: overlay Backing Filesystem: xfs Supports d_type: true Logging Driver: json-file Cgroup Driver: cgroupfs Plugins: Volume: local Network: bridge host macvlan null overlay Log: awslogs fluentd gcplogs gelf journald json-file logentries splunk syslog Swarm: inactive Runtimes: runc Default Runtime: runc Init Binary: docker-init containerd version: 06b9cb35161009dcb7123345749fef02f7cea8e0 runc version: 3f2f8b84a77f73d38244dd690525642a72156c64 init version: 949e6fa Security Options: seccomp Profile: default Kernel Version: 3.10.0-514.el7.x86_64 Operating System: CentOS Linux 7 (Core) OSType: linux Architecture: x86_64 CPUs: 1 Total Memory: 3.686GiB Name: bogon ID: 262X:2R66:O4BX:26JN:JL6S:X4SZ:TM6H:VDAN:JRU3:XZJ6:NPBK:KPKS Docker Root Dir: /var/lib/docker Debug Mode (client): false Debug Mode (server): false Registry: https://index.docker.io/v1/ Experimental: false Insecure Registries: 127.0.0.0/8 Registry Mirrors: http://681a96df.m.daocloud.io/ Live Restore Enabled: false 查看docker服务 image 修改host和port image 重新加载service文件，并且重启docker服务[root@bogon ~]# systemctl daemon-reload [root@bogon ~]# systemctl restart docker 连接远程执行docker命令 [root@bogon ~]# docker -H 192.168.100.129:2375 images REPOSITORY TAG IMAGE ID CREATED SIZE","tags":[{"name":"docker","slug":"docker","permalink":"http://dennis.pathto.top/tags/docker/"},{"name":"cloud","slug":"cloud","permalink":"http://dennis.pathto.top/tags/cloud/"}]},{"title":"13.Spring Boot 热部署","date":"2017-09-24T11:05:12.000Z","path":"2017/09/24/spring-boot-hot-deploy-13/","text":"Spring Boot 热部署实际开发中，修改某个页面数据或逻辑功能都需要重启应用。这无形中降低了开发效率，所以使用热部署是十分必要的。 什么是热部署？应用启动后会把编译好的Class文件加载的虚拟机中，正常情况下在项目修改了源文件是需要全部重新编译并重新加载（需要重启应用）。而热部署就是监听Class文件的变动，只把发生修改的Class重新加载，而不需要重启应用，使得开发变得简便。 Spring Boot 配置实现热部署添加spring-boot-devtools 热部署模块&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; 修改application.yml,开发环境中禁止thymeleaf的cachespring: thymeleaf: cache: false","tags":[{"name":"java","slug":"java","permalink":"http://dennis.pathto.top/tags/java/"},{"name":"spring","slug":"spring","permalink":"http://dennis.pathto.top/tags/spring/"},{"name":"spring-boot","slug":"spring-boot","permalink":"http://dennis.pathto.top/tags/spring-boot/"}]},{"title":"12.spring-boot-properties问题","date":"2017-09-24T11:05:08.000Z","path":"2017/09/24/spring-boot-properties-problem-12/","text":"application.properties配置文件问题 application.properties配置文件名称的第一个字母不能为大写，可能在开发环境中没有问题，但是打包运行的时候会出现问题 uri配置问题属性文件配置了context-path,访问的时候,要在端口后面添加consumer,http://localhost:9000/consumer/user/list server: port: 9000 context-path: /consumer","tags":[{"name":"java","slug":"java","permalink":"http://dennis.pathto.top/tags/java/"},{"name":"spring","slug":"spring","permalink":"http://dennis.pathto.top/tags/spring/"},{"name":"spring-boot","slug":"spring-boot","permalink":"http://dennis.pathto.top/tags/spring-boot/"}]},{"title":"11.spring-boot-Thymeleaf和context path","date":"2017-09-24T11:03:30.000Z","path":"2017/09/24/spring-boot-Thymeleaf-context-path-11/","text":"Thymeleaf 输出context path在页面中&lt;th:action=&quot;@{/edit.html}&quot; /&gt; &lt;a th:href=&quot;@{edit.html}&quot; /&gt; 在javascript中&lt;script th:inline=&quot;javascript&quot;&gt; function edit() { var link = /*[[@{/edit.html}]]*/ &apos;test&apos;; document.getElementById(&quot;user_form&quot;).action = link; } &lt;/script&gt; 文本连接无论是什么形式的文本：字面量’…’，变量表达式求值或消息表达式求值的结果，都可以用’+’进行连接 th:text=&quot;&apos;The name of the user is &apos; + ${user.name}&quot;","tags":[{"name":"java","slug":"java","permalink":"http://dennis.pathto.top/tags/java/"},{"name":"spring","slug":"spring","permalink":"http://dennis.pathto.top/tags/spring/"},{"name":"spring-boot","slug":"spring-boot","permalink":"http://dennis.pathto.top/tags/spring-boot/"}]},{"title":"10.spring-boot使用新特性开发生产者和消费者程序","date":"2017-09-24T11:03:25.000Z","path":"2017/09/24/spring-boot-new-feature-consumer-product-10/","text":"在spring-boot中，引入非常多的新特性，简化了spring中繁琐，臃肿的开发方式 组合注解使用组合注解，通过其名称，就可以非常容易知道其意义，提高代码的可读性 @RestController=@Controller+@ResponseBody @GetMapping=@RequestMapping(method = RequestMethod.GET) http客户端spring-boot提供了专门用于restApi调用的模板类RestTemplate，该模板类使用了单例的设计模式，底层也实现了线程池,http长连接的特性，开发人员非常方便就可以开发出高性能的http客户端程序 列子spring-cloud-consumer-user工程UserController.java package com.example.demo.controller; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.web.bind.annotation.GetMapping; import org.springframework.web.bind.annotation.PathVariable; import org.springframework.web.bind.annotation.RequestMapping; import org.springframework.web.bind.annotation.RestController; import org.springframework.web.client.RestTemplate; import com.example.demo.model.User; @RestController @RequestMapping(value=&quot;/user&quot;) public class UserController { @Autowired private RestTemplate restTemplate; @GetMapping(value=&quot;/get/{id}&quot;) public User get(@PathVariable String id){ return restTemplate.getForObject(&quot;http://localhost:8080/user/get?id=&quot;+id, User.class); } } CoreConfig.java package com.example.demo.config; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; import org.springframework.web.client.RestTemplate; @Configuration public class CoreConfig { @Bean public RestTemplate restTemplateBean(){ return new RestTemplate(); } } User.java package com.example.demo.model; import java.util.Date; public class User { private String id; private String userName; private int age; private Date birthday; public String getId() { return id; } public void setId(String id) { this.id = id; } public String getUserName() { return userName; } public void setUserName(String userName) { this.userName = userName; } public int getAge() { return age; } public void setAge(int age) { this.age = age; } public Date getBirthday() { return birthday; } public void setBirthday(Date birthday) { this.birthday = birthday; } } application.properties server.port=8081 spring-cloud-provider工程UserController.java package com.dennis.controller; import java.util.HashMap; import java.util.Map; import org.springframework.web.bind.annotation.GetMapping; import org.springframework.web.bind.annotation.RequestMapping; import org.springframework.web.bind.annotation.ResponseBody; import org.springframework.web.bind.annotation.RestController; import com.dennis.model.User; @RestController @RequestMapping(value=&quot;/user&quot;) public class UserController { private Map&lt;String, User&gt; umap = new HashMap(); public UserController(){ umap.put(&quot;1&quot;, new User(&quot;1&quot;, &quot;xiaoming&quot;, 30)); umap.put(&quot;2&quot;, new User(&quot;2&quot;, &quot;xiaohong&quot;, 20)); umap.put(&quot;3&quot;, new User(&quot;3&quot;, &quot;zhangsan&quot;, 80)); umap.put(&quot;4&quot;, new User(&quot;4&quot;, &quot;lisi&quot;, 10)); umap.put(&quot;5&quot;, new User(&quot;5&quot;, &quot;wangwu&quot;, 22)); } @GetMapping(value=&quot;/get&quot;) @ResponseBody public User get(String id){ return umap.get(id); } }","tags":[{"name":"java","slug":"java","permalink":"http://dennis.pathto.top/tags/java/"},{"name":"spring","slug":"spring","permalink":"http://dennis.pathto.top/tags/spring/"},{"name":"spring-boot","slug":"spring-boot","permalink":"http://dennis.pathto.top/tags/spring-boot/"}]},{"title":"一个人的思维，决定了他在什么阶层","date":"2017-09-23T16:14:24.000Z","path":"2017/09/24/life-A-person-s-thinking/","text":"image 最近，“阶层固化”一词特别火。很多人都在感叹：阶层上升通道的大门即将关闭。其实，自古以来，每个朝代都有阶层固化。但无论阶层怎么固化，总有5%的穷人可以突围而出。穷不可怕，可怕的是“稀缺”导致的穷人思维。 阶层在代际间得到了传承我家楼上一哥们特别好玩，他最近读了热门文章《城堡的落成：上升通道即将关闭的中国社会》后，便经常开长辈们玩笑。 爷爷来玩，他就怼爷爷：“你当年干嘛去了？咋不参加红军？要是你当年参军，我家至于这样吗？” 爸爸来玩，他就怼爸爸：“你当年干嘛去了？咋不下海创业呢？”要是当年你下海，我家至于这样吗？” 前几天，我在电梯里碰到他，他感叹：“现在阶层固化，寒门再难出贵子了。”寒门难以出贵子，这倒是事实。 北京大学副教授刘云杉做过统计：80年代，北大学生三成出自寒门。90年代，寒门比例开始逐渐下滑。2000年后，寒门比例仅占一成多。 BBC纪录片《人生七年》证实了这一现象，他们用49年跟踪了一群不同阶层的孩子，最后揭露了一个残酷事实：穷人的孩子绝大部分仍然是穷人，富人的孩子绝大部分仍然是富人，阶层在代际间得到了传承。 为什么穷人无法摆脱贫穷呢？很多专家学者都在研究这个问题，但都没有给出一个让人信服的答案。直到十年前，美国经济学家穆来纳森找到心理学家沙菲尔：“我们一起研究这个问题吧！” 经过十年调查研究，他俩终于找到答案。穷人无法摆脱贫穷的罪魁是——稀缺心态。 何谓稀缺心态？就是“越是稀缺什么，就越是在意什么”。 我家邻居王阿姨就是这样，由于她家经济条件不太好，所以她买菜特别喜欢折腾，去小区门口新世纪超市一看：“生菜一斤要三块五，太贵。” 于是，她坐六站公交去沃尔玛，“更贵，四块钱一斤。”于是，她又坐七站路去永辉，“三块钱一斤，太好了。”她买了5斤，乐呵呵地回家了。折腾半天，扣去车费，还倒亏5毛。 穆来纳森说：“人们的视野会因稀缺心态变得狭窄，形成管窥之见，即只能通过‘管子’的孔洞看清少量物体，而无视管外的一切。” 也就是说，稀缺会俘获一个人的大脑。 带宽穆来纳森和沙菲尔提出了“带宽”概念。所谓带宽，就是指一个人心智的容量。 如果这个带宽老是被一种稀缺心态所塞满，就会影响一个人的认知能力和执行控制力。 印度克延比都蔬菜市场很是繁荣。这里，生活着一群很穷的小商贩。每天清晨，他们会向富人借1000卢比，然后去进货，卖完可收回1100卢比，而晚上，他们要还给富人1050卢布。 也就是说，他们一天的收入是50卢比。其实，只要小贩不把这50卢比全花掉，每天省下5卢比用于第二天进货。由于复利效应，他们只需要50天，就不用再去借这1000卢比的本钱了。 从此，他们收入就会节节攀升，这样美好的结果，几乎是触手可及。但是，没有一个小商贩这样做。“他们天天就那样重复着，分出利息达九年之久。” 穆来纳森说：“长期处于稀缺状态的穷人，会被稀缺心态消耗大量带宽，其判断力和认知能力会因过于关注眼前问题而大大降低，而没有多余带宽来考虑投资和长远发展事宜。” 稀缺心态会严重影响认知判断能力，认知判断能力大幅下降会导致短视。也就是说，一个人穷着穷着，就会变傻。 一个富人和穷人的故事一位富人想帮一个穷人致富，那年冬天，就送了他一头牛：“好好用牛耕作，秋天就能脱贫了。” 穷人满怀希望开始奋斗。可没过几天，牛要吃草，人要吃饭，穷人的日子比以前过得更加艰难了。 穷人想：“不如把牛卖了，买几只羊，先杀一只救急，剩下的可以下小羊，小羊长大了拿去卖，可以赚更多的钱。”穷人吃完一只羊，小羊没有生下来， 日子又艰难了，便忍不住又吃了一只。 穷人想：“这样下去不行，不如把羊卖了买鸡，鸡很快就会下蛋，鸡蛋一卖，日子可以好转。” 可等不到鸡下蛋，日子又艰难了，于是，穷人又忍不住杀鸡吃。 杀到只剩一只鸡时，穷人想：“致富是无望了，不如把鸡卖了，打一壶酒，三杯下肚，万事不愁。” 春天，富人带着种子来到穷人家，却发现牛没了，而穷人正在喝酒。 “活该受穷。”富人一跺脚走了。 穆来纳森说：“长期处于稀缺状态的穷人，会被稀缺心态消耗大量带宽，用来进行自我控制的心智资源就会很少，所以容易变得非常冲动。” 稀缺心态会严重影响执行控制力，执行控制力大幅下降会导致冲动。一个人穷着穷着，就会变成冲动的傻子。 穷人就是这样陷入穷的恶性循环的：稀缺金钱→注意力集中到钱上→大脑浮现各种与钱有关的事，变得冲动失去控制力→心智带宽减少→做出错误认知，做出错误决定→放大对于钱的稀缺心态→恶性循环。 富人和穷人的思维很多人喜欢这样说：“如果我有钱，我会比马云做得好。”“如果我有钱，绝对比王思聪厉害。” 其实，未必。长期陷入恶性循环的穷人，即便偶尔暴富，也会很快变成穷人。 美国国家经济研究局做过一个调查：最近20年来，欧美彩票头奖得主，5年之内，破产率达75%。 为什么会这样？“因为他们虽然有钱了，但行事还是穷人思维。” 我有位朋友，创业发了，买了别墅，把农村父母接了过来。从此，我这朋友就头大起来。 最热的天，爸妈也不会开空调。爸妈经常从外面捡一堆破烂回来。家里囤积着各种各样的垃圾袋。………… 尽管他家存款千万，但父母依然扔不掉穷人思维。 阶层固化，其实来源于思维的属性。你的思维，决定了你在什么阶层。穷不可怕，稀缺导致的穷人思维才可怕。 如何才能跳出稀缺导致的穷人思维呢？第一个：把重要的事情强行拉入管道视野。 哈佛大学做过一个著名的人生影响跟踪调查，对象是一群出身环境和智商都差不多的年轻人。 调查结果发现： 27％的人没有理想，生活没有目标。60％的人理想模糊，生活目标模糊。10％的人有理想，制定了短期规划。3％的人有理想，制定了清晰的长期规划。 25年后，这群人的生活状况很有意思： 那3%的人，因为一直有规划地朝着人生理想迈进，所以最后几乎都成了社会顶尖成功人士。那10％的人，因为不断实现短期目标，最后成了社会的中产，做了律师、工程师、企业主管等等。那60％的人，生活在社会中下层，没什么特别成绩，就指望孩子将来有出息。剩下27％的人，成了社会最底层的人，成天抱怨他人，抱怨社会。 这个调查说明了什么——不同的人生规划，让每个人拉开了距离。 所以，要跳出稀缺导致的穷人思维，就要强行把重要的事情拉入管道视野——制定清晰的人生规划，短期的长期的，然后一步一步去实现它。 贫穷的韩信为何能忍受胯下之辱？因为他有坚定不移的人生大理想。 正如苏轼所说：“匹夫见辱，拔剑而起，挺身而斗，此不足为勇也。天下有大勇者，卒然临之而不惊，无故加之而不怒，此其所挟持者甚大，而其志甚远也。” 思维导向专栏作家李刚讲过一件趣事：几年前，他老婆想买一套学区房。他一算存款，连首付都不够。于是建议：攒点钱再说吧！ 当然，最后胳膊没能拧过大腿，老婆东挪西借，硬是把首付给付了。结果才过两年，房价就翻了倍。李刚高兴得不得了：“幸好买了。” 论理财能力，李刚远在老婆之上。 “我有十几年投资经验，再复杂的金融工具，我也一清二楚，而她连买个银行理财产品还要问人家保不保本。”李刚说。 但这件事，李刚一开始就陷入了穷人思维。 “我没有思考学区房是不是一个必须而且合理的目标，而是首先考虑钱够不够。” 这就是穷人思维和富人思维的区别：穷人思维的特点是量入为出，富人思维的特点是目标导向。 穷人思维买房，首先考虑：我存款有多少，月收入多少，再倒过来推算，自己该不该买房，买什么房。 富人思维买房，首先考虑：我要不要买房，想买什么房？然后再算，还差多少，怎么解决。 如何跳出稀缺导致的穷人思维？ 第二个：建立目标导向思维。 正如李刚所说：如果一个目标是合理的，就不能以“资源不足”为理由，去否定这个目标。这是至关重要的一条做事原则。 青年作家李尚龙讲过一个故事：他刚上大学时，宿舍一同学特抠门。有一次，李尚龙手机没电了，便找这同学借电话打给家里。打完，李尚龙把电话还他，转身出了宿舍。 哪知此同学追了出来：“给我五毛钱。”李尚龙以为听错了：“什么？”此同学非常认真地说：“你刚才打了两分钟，给我五毛钱。”李尚龙翻了翻皮夹：“没零钱。”此同学脸色有点不爽起来。 李尚龙说：“要不这样，午餐我请。”此同学脸色舒展来开：“好。”但从此之后，李尚龙便和此人再无交往。没过多久，一宿舍的人都和此人闹僵了。 大学毕业后，此人三年内换了七次工作，因为太过斤斤计较，每个单位都不待见他。 李尚龙说：“他穷的，不仅仅是家庭条件，他穷的，更是视野和格局。” 他以为自己占了便宜，其实吃了大亏。 穷人缺钱，看起来是因为资源不够，实际上最要命的是穷人心态。也就是：越是穷的时候，越是在乎钱，越是在乎钱，就越是影响视野和格局。 如何跳出稀缺导致的穷人思维？ 第三个：越是穷的时候，越是不能在乎钱。 不明白这一点，很多事情及规划都无从谈起。 我邻居，买菜折腾那个王阿姨，去年在地摊上给孙子买了双运动鞋，耐克的仿款，便宜得惊人。 一周后，孙子从学校回来，脚肿了。“鞋子材质不好，不透气……”去医院，医生诊断是真菌感染结果一治，最后花了700多元。 王阿姨后悔得直跺脚：“早知道就买正品了。”这就是穷人思维——忽视“冰山成本”。 何谓冰山成本？就是看得见的成本，往往只是极小部分。更大的成本，藏在看不见的水下。 忽视冰山成本会有一个后果——占小便宜，吃大亏。贪图劣质鞋便宜，结果损伤了脚贪图劣质食品便宜，结果吃坏了肠胃。贪图劣质服装便宜，结果没穿几回就扔了……最终，付出了比买优质产品多得多的成本。 穷人的钱很多都耗费在了这样的冰山成本上。 如何跳出稀缺导致的穷人思维？ 第四个：花钱时必须重视冰山成本。 一心只想着省钱，往往是在浪费钱。不要因贪小便宜而吃大亏。 我童年一直生活在农村大院，院里有位彭姓人家，生了三个子女，当时打疫苗，已经开始收费了。 彭家为了省钱，就把很多疫苗也省了。结果幺女儿得了小儿麻痹症，腿跛了。借了几万元治腿，结果还是无力回天。 每次看到她，我都特别心痛。“就因为父母为了省一点点钱，这个妹妹一辈子都被耽误了。” 这就是穷人思维——忽视身边随时可能发生或必将发生的重大变故。 比如，重大疾病的发生。比如，意外伤害的发生。这些重大变故一旦发生，可能一下就会将我们打回“解放前”。 如何跳出稀缺导致的穷人思维？ 第五个：要规划“余钱”。 就是不管你生活有多拮据多困难，一定要抠出一点余钱来未雨绸缪。比如，买几种必须的保险。比如，该打的疫苗一定要打…… 如果你只关注眼前利益，很可能赢了一时，但输掉了整个一生。 企业家凌军讲过他公司两个员工的故事。两个员工是他同时招录进来的同班同学。刚毕业时，两人都缺钱，于是就把房子租在了北京五环外。 每天上下班需要四小时，很是累人。凌军就建议：“你们可以在离单位近点的地方租房，虽然贵一点，但可以节约很多时间。” 员工马骏听了，在单位附近租了房子。员工张萌没有，他觉得：“太贵了，不能浪费钱，反正我有的是时间。” 三年后，马骏工资翻了两倍。“我把省下来的时间用到了学习上，三年努力，我拿到了注册会计师证。” 而张萌呢，三年工资只涨了800元。他很后悔：“我目光太短浅了。” 如何跳出稀缺导致的穷人思维？ 第六个：要规划“余闲”。 把余闲用在自身素质的升级上——比如读书计划、技能培训等等。穷人之穷，往往是双重匮乏：既缺金钱，又缺时间。 所以，我们一定要学会规划余闲，必要时要像马骏一样学会用钱置换时间。 自古以来，每个朝代都有阶层固化。但无论阶层怎么固化，总有5%的穷人可以突围而出。因为他们跳出了稀缺导致的穷人思维。 电影《1942》里，逃荒路上张国立演的地主说了一句话：“我知道咋从一个穷人变成财主，不出十年，你大爷我还是东家，那时候咱再回来……” 石油大王洛克菲勒也说过一句类似的话：“即使你们把我身上的衣服剥得精光，然后扔在撒哈拉沙漠的中心地带，但只要有一支商队从我身边路过。我就会成为一个新的百万富翁。” 一个人的思维，决定了他在什么阶层。我们和头等舱的距离，差的不只是钱。","tags":[{"name":"life","slug":"life","permalink":"http://dennis.pathto.top/tags/life/"},{"name":"thinking","slug":"thinking","permalink":"http://dennis.pathto.top/tags/thinking/"}]},{"title":"12.elasticsearch聚合查询-demo","date":"2017-09-10T15:35:29.000Z","path":"2017/09/10/elasticsearch-12-aggs-query/","text":"聚合查询介绍&nbsp;&nbsp;&nbsp;&nbsp;elasticsearch1.0带来了改进和新功能，更包括备受期待的框架，它赋予了elasticsearch新的定位:全功能分析引擎。现在.你可以使用elasticsearch作为系统的一个关键部分。处理大量的数据,提取结论,并将这些数据可视化为可读的方式。 &nbsp;&nbsp;&nbsp;&nbsp;聚合可以分成两组:度量聚合和桶聚合。 date_histogram&nbsp;&nbsp;&nbsp;&nbsp;时间区间的柱形图，Date histogram的用法与histogram差不多，只不过区间上支持了日期的表达式。 date_histogram属性介绍{ &quot;aggs&quot;:{ &quot;articles_over_time&quot;:{ &quot;date_histogram&quot;:{ &quot;field&quot;:&quot;date&quot;, &quot;interval&quot;:&quot;month&quot; } } } } interval字段支持多种关键字：year, quarter, month, week, day, hour, minute, second 当然也支持对这些关键字进行扩展使用，比如一个半小时可以定义成如下: { &quot;aggs&quot;:{ &quot;articles_over_time&quot;:{ &quot;date_histogram&quot;:{ &quot;field&quot;:&quot;date&quot;, &quot;interval&quot;:&quot;1.5h&quot; } } } } format返回的结果可以通过设置format进行格式化: { &quot;aggs&quot;:{ &quot;articles_over_time&quot;:{ &quot;date_histogram&quot;:{ &quot;field&quot;:&quot;date&quot;, &quot;interval&quot;:&quot;1M&quot;, &quot;format&quot;:&quot;yyyy-MM-dd&quot; } } } } 得到的结果如下： { &quot;aggregations&quot;:{ &quot;articles_over_time&quot;:{ &quot;buckets&quot;:[{ &quot;key_as_string&quot;:&quot;2013-02-02&quot;, &quot;key&quot;:1328140800000, &quot;doc_count&quot;:1 },{ &quot;key_as_string&quot;:&quot;2013-03-02&quot;, &quot;key&quot;:1330646400000, &quot;doc_count&quot;:2 }, ... ]} } } 其中key_as_string是格式化后的日期，key显示了是日期时间戳 time_zone时区的用法在es中日期支持时区的表示方法，这样就相当于东八区的时间。 { &quot;aggs&quot;:{ &quot;by_day&quot;:{ &quot;date_histogram&quot;:{ &quot;field&quot;:&quot;date&quot;, &quot;interval&quot;:&quot;day&quot;, &quot;time_zone&quot;:&quot;+08:00&quot; } } } } offsetoffset 使用偏移值，改变时间区间默认情况是从凌晨0点到午夜24:00，如果想改变时间区间，可以通过下面的方式，设置偏移值： {&quot;aggs&quot;:{ &quot;by_day&quot;:{ &quot;date_histogram&quot;:{ &quot;field&quot;:&quot;date&quot;, &quot;interval&quot;:&quot;day&quot;, &quot;offset&quot;:&quot;+6h&quot; } } } } 那么桶的区间就改变为： &quot;aggregations&quot;:{ &quot;by_day&quot;:{ &quot;buckets&quot;:[{ &quot;key_as_string&quot;:&quot;2015-09-30T06:00:00.000Z&quot;, &quot;key&quot;:1443592800000, &quot;doc_count&quot;:1 },{ &quot;key_as_string&quot;:&quot;2015-10-01T06:00:00.000Z&quot;, &quot;key&quot;:1443679200000, &quot;doc_count&quot;:1 }] } } missing valueMissing Value缺省字段当遇到没有值的字段，就会按照缺省字段missing value来计算： { &quot;aggs&quot;:{ &quot;publish_date&quot;:{ &quot;date_histogram&quot;:{ &quot;field&quot;:&quot;publish_date&quot;, &quot;interval&quot;:&quot;year&quot;, &quot;missing&quot;:&quot;2000-01-01&quot; } } } } 产品相关统计应用数据准备curl -XPOST http://study0:9200/cars/transactions/_bulk -d &apos; { &quot;index&quot;: {}} { &quot;price&quot; : 10000, &quot;color&quot; : &quot;red&quot;, &quot;make&quot; : &quot;honda&quot;, &quot;sold&quot; : &quot;2014-10-28&quot; } { &quot;index&quot;: {}} { &quot;price&quot; : 20000, &quot;color&quot; : &quot;red&quot;, &quot;make&quot; : &quot;honda&quot;, &quot;sold&quot; : &quot;2014-11-05&quot; } { &quot;index&quot;: {}} { &quot;price&quot; : 30000, &quot;color&quot; : &quot;green&quot;, &quot;make&quot; : &quot;ford&quot;, &quot;sold&quot; : &quot;2014-05-18&quot; } { &quot;index&quot;: {}} { &quot;price&quot; : 15000, &quot;color&quot; : &quot;blue&quot;, &quot;make&quot; : &quot;toyota&quot;, &quot;sold&quot; : &quot;2014-07-02&quot; } { &quot;index&quot;: {}} { &quot;price&quot; : 12000, &quot;color&quot; : &quot;green&quot;, &quot;make&quot; : &quot;toyota&quot;, &quot;sold&quot; : &quot;2014-08-19&quot; } { &quot;index&quot;: {}} { &quot;price&quot; : 20000, &quot;color&quot; : &quot;red&quot;, &quot;make&quot; : &quot;honda&quot;, &quot;sold&quot; : &quot;2014-11-05&quot; } { &quot;index&quot;: {}} { &quot;price&quot; : 80000, &quot;color&quot; : &quot;red&quot;, &quot;make&quot; : &quot;bmw&quot;, &quot;sold&quot; : &quot;2014-01-01&quot; } { &quot;index&quot;: {}} { &quot;price&quot; : 25000, &quot;color&quot; : &quot;blue&quot;, &quot;make&quot; : &quot;ford&quot;, &quot;sold&quot; : &quot;2014-02-12&quot; } 备注：我们会建立一个也许对汽车交易商有所用处的聚合。数据是关于汽车交易的：汽车型号，制造商，销售价格，销售时间以及一些其他的相关数据 统计每个月文档数 按时间统计，每个月的文档数 GET /cars/transactions/_search { &quot;aggs&quot;: { &quot;doc_count&quot;: { &quot;date_histogram&quot;: { &quot;field&quot;: &quot;sold&quot;, &quot;interval&quot;: &quot;month&quot; } } } } 返回结果： &quot;aggregations&quot; : { &quot;articles_over_time&quot; : { &quot;buckets&quot; : [ { &quot;key_as_string&quot; : &quot;2014-01-01T00:00:00.000Z&quot;, &quot;key&quot; : 1388534400000, &quot;doc_count&quot; : 1 }, { &quot;key_as_string&quot; : &quot;2014-02-01T00:00:00.000Z&quot;, &quot;key&quot; : 1391212800000, &quot;doc_count&quot; : 1 }, histogram统计价格区间柱形图（Histogram Aggregation） Histogram做等间距划分，统计区间的price值，看他落在那个区间，数据间隔是5000 GET /cars/transactions/_search { &quot;size&quot;: 0, &quot;aggs&quot; : { &quot;prices&quot; : { &quot;histogram&quot; : { &quot;field&quot; : &quot;price&quot;, &quot;interval&quot; : 5000 } } } } 返回结果 &quot;aggregations&quot; : { &quot;prices&quot; : { &quot;buckets&quot; : [ { &quot;key&quot; : 10000.0, &quot;doc_count&quot; : 2 }, { &quot;key&quot; : 15000.0, &quot;doc_count&quot; : 1 }, 非数值类型的文档数统计 统计非数值类型的字段,类似sql中的select count(*) from table group by field 如查看每种颜色的销量 GET /cars/transactions/_search { &quot;size&quot;: 0, &quot;aggs&quot; : { &quot;genres&quot; : { &quot;terms&quot; : { &quot;field&quot; : &quot;color&quot; } } } } 说明:genres表示的是统计结果名，可以是任意合法字符串 注意:会报如下错： “reason” : “Fielddata is disabled on text fields by default. Set fielddata=true on [color] in order to load fielddata in memory by uninverting the inverted index. Note that this can however use significant memory.” 提示我们数据类型不对，我们修改一下mapping映射： GET /cars/_mapping/transactions { &quot;properties&quot;: { &quot;color&quot;: { &quot;type&quot;: &quot;text&quot;, &quot;fielddata&quot;: true } } } {&quot;acknowledged&quot;:true} 统计结果 &quot;buckets&quot; : [ { &quot;key&quot; : &quot;red&quot;, &quot;doc_count&quot; : 4 }, { &quot;key&quot; : &quot;blue&quot;, &quot;doc_count&quot; : 2 }, { &quot;key&quot; : &quot;green&quot;, &quot;doc_count&quot; : 2 } Metric添加一个指标(Metric),相当于sql中的select count(*),avg(vi),max(vi)…from table group by field GET /cars/transactions/_search { &quot;size&quot;: 0, &quot;aggs&quot; : { &quot;genres&quot; : { &quot;terms&quot; : { &quot;field&quot; : &quot;color&quot; }, &quot;aggs&quot;: { &quot;avg_price&quot;: { &quot;avg&quot;: { &quot;field&quot;: &quot;price&quot; } } } } } } 注意:avg可以换成max,min,sum等。用stats就表示所有。 用stats找出Metric的所有值。 GET /cars/transactions/_search { &quot;size&quot;: 0, &quot;aggs&quot; : { &quot;genres&quot; : { &quot;terms&quot; : { &quot;field&quot; : &quot;color&quot; } , &quot;aggs&quot;: { &quot;avg_price&quot;: { &quot;stats&quot;: { &quot;field&quot;: &quot;price&quot; } } } } } } 返回结果 &quot;buckets&quot; : [ { &quot;key&quot; : &quot;red&quot;, &quot;doc_count&quot; : 4, &quot;avg_price&quot; : { &quot;count&quot; : 4, &quot;min&quot; : 10000.0, &quot;max&quot; : 80000.0, &quot;avg&quot; : 32500.0, &quot;sum&quot; : 130000.0 } }","tags":[{"name":"elasticsearch","slug":"elasticsearch","permalink":"http://dennis.pathto.top/tags/elasticsearch/"},{"name":"elk","slug":"elk","permalink":"http://dennis.pathto.top/tags/elk/"}]},{"title":"11.elasticsearch-几种聚合查询","date":"2017-09-10T13:35:29.000Z","path":"2017/09/10/elasticsearch-11-severral-aggs/","text":"计算emp每个sex下的数量将文本field的fielddata属性设置为truePUT /company/_mapping/emp { &quot;properties&quot;: { &quot;sex&quot;: { &quot;type&quot;: &quot;text&quot;, &quot;fielddata&quot;: true } } } 执行结果 { &quot;acknowledged&quot;: true } 统计男女人数一般统计方式GET /company/emp/_search { &quot;aggs&quot;: { &quot;group_by_tags&quot;: { &quot;terms&quot;: { &quot;field&quot;: &quot;sex&quot; } } } } 添加size=0，优化统计结果GET /company/emp/_search { &quot;size&quot;: 0, &quot;aggs&quot;: { &quot;all_tags&quot;: { &quot;terms&quot;: { &quot;field&quot;: &quot;sex&quot; } } } } 执行结果 { &quot;took&quot;: 21, &quot;timed_out&quot;: false, &quot;_shards&quot;: { &quot;total&quot;: 5, &quot;successful&quot;: 5, &quot;failed&quot;: 0 }, &quot;hits&quot;: { &quot;total&quot;: 9, &quot;max_score&quot;: 0, &quot;hits&quot;: [] }, &quot;aggregations&quot;: { &quot;all_tags&quot;: { &quot;doc_count_error_upper_bound&quot;: 0, &quot;sum_other_doc_count&quot;: 0, &quot;buckets&quot;: [ { &quot;key&quot;: &quot;man&quot;, &quot;doc_count&quot;: 5 }, { &quot;key&quot;: &quot;woman&quot;, &quot;doc_count&quot;: 4 } ] } } } 对hobby中包含trivel的emp，计算每个sex下的数量GET /company/emp/_search { &quot;size&quot;: 0, &quot;query&quot;: { &quot;match&quot;: { &quot;hobby&quot;: &quot;trivel&quot; } }, &quot;aggs&quot;: { &quot;all_tags&quot;: { &quot;terms&quot;: { &quot;field&quot;: &quot;sex&quot; } } } } 执行结果 { &quot;took&quot;: 33, &quot;timed_out&quot;: false, &quot;_shards&quot;: { &quot;total&quot;: 5, &quot;successful&quot;: 5, &quot;failed&quot;: 0 }, &quot;hits&quot;: { &quot;total&quot;: 3, &quot;max_score&quot;: 0, &quot;hits&quot;: [] }, &quot;aggregations&quot;: { &quot;all_tags&quot;: { &quot;doc_count_error_upper_bound&quot;: 0, &quot;sum_other_doc_count&quot;: 0, &quot;buckets&quot;: [ { &quot;key&quot;: &quot;man&quot;, &quot;doc_count&quot;: 2 }, { &quot;key&quot;: &quot;woman&quot;, &quot;doc_count&quot;: 1 } ] } } } 先按sex分组，算出每组的数量，再计算每个sex下的商品的平均年龄GET /company/emp/_search { &quot;size&quot;: 0, &quot;aggs&quot; : { &quot;group_by_tags&quot; : { &quot;terms&quot; : { &quot;field&quot; : &quot;sex&quot; }, &quot;aggs&quot; : { &quot;avg_age&quot; : { &quot;avg&quot; : { &quot;field&quot; : &quot;age&quot; } } } } } } 执行结果 { &quot;took&quot;: 13, &quot;timed_out&quot;: false, &quot;_shards&quot;: { &quot;total&quot;: 5, &quot;successful&quot;: 5, &quot;failed&quot;: 0 }, &quot;hits&quot;: { &quot;total&quot;: 9, &quot;max_score&quot;: 0, &quot;hits&quot;: [] }, &quot;aggregations&quot;: { &quot;group_by_tags&quot;: { &quot;doc_count_error_upper_bound&quot;: 0, &quot;sum_other_doc_count&quot;: 0, &quot;buckets&quot;: [ { &quot;key&quot;: &quot;man&quot;, &quot;doc_count&quot;: 5, &quot;avg_age&quot;: { &quot;value&quot;: 24.2 } }, { &quot;key&quot;: &quot;woman&quot;, &quot;doc_count&quot;: 4, &quot;avg_age&quot;: { &quot;value&quot;: 22 } } ] } } } 计算每个sex下的平均年龄，并且按照平均年龄降序排序GET /company/emp/_search { &quot;size&quot;: 0, &quot;aggs&quot; : { &quot;all_tags&quot; : { &quot;terms&quot; : { &quot;field&quot; : &quot;sex&quot;, &quot;order&quot;: { &quot;avg_age&quot;: &quot;desc&quot; } }, &quot;aggs&quot; : { &quot;avg_age&quot; : { &quot;avg&quot; : { &quot;field&quot; : &quot;age&quot; } } } } } } 执行结果 { &quot;took&quot;: 7, &quot;timed_out&quot;: false, &quot;_shards&quot;: { &quot;total&quot;: 5, &quot;successful&quot;: 5, &quot;failed&quot;: 0 }, &quot;hits&quot;: { &quot;total&quot;: 9, &quot;max_score&quot;: 0, &quot;hits&quot;: [] }, &quot;aggregations&quot;: { &quot;all_tags&quot;: { &quot;doc_count_error_upper_bound&quot;: 0, &quot;sum_other_doc_count&quot;: 0, &quot;buckets&quot;: [ { &quot;key&quot;: &quot;man&quot;, &quot;doc_count&quot;: 5, &quot;avg_age&quot;: { &quot;value&quot;: 24.2 } }, { &quot;key&quot;: &quot;woman&quot;, &quot;doc_count&quot;: 4, &quot;avg_age&quot;: { &quot;value&quot;: 22 } } ] } } } 按照指定的年龄范围区间进行分组，然后在每组内再按照sex进行分组，最后再计算每组的平均年龄GET /company/emp/_search { &quot;size&quot;: 0, &quot;aggs&quot;: { &quot;group_by_age&quot;: { &quot;range&quot;: { &quot;field&quot;: &quot;age&quot;, &quot;ranges&quot;: [ { &quot;from&quot;: 0, &quot;to&quot;: 10 }, { &quot;from&quot;: 10, &quot;to&quot;: 20 }, { &quot;from&quot;: 20, &quot;to&quot;: 30 }, { &quot;from&quot;: 30, &quot;to&quot;: 100 } ] }, &quot;aggs&quot;: { &quot;group_by_sex&quot;: { &quot;terms&quot;: { &quot;field&quot;: &quot;sex&quot; }, &quot;aggs&quot;: { &quot;average_age&quot;: { &quot;avg&quot;: { &quot;field&quot;: &quot;age&quot; } } } } } } } } 执行结果 { &quot;took&quot;: 16, &quot;timed_out&quot;: false, &quot;_shards&quot;: { &quot;total&quot;: 5, &quot;successful&quot;: 5, &quot;failed&quot;: 0 }, &quot;hits&quot;: { &quot;total&quot;: 9, &quot;max_score&quot;: 0, &quot;hits&quot;: [] }, &quot;aggregations&quot;: { &quot;group_by_age&quot;: { &quot;buckets&quot;: [ { &quot;key&quot;: &quot;0.0-10.0&quot;, &quot;from&quot;: 0, &quot;to&quot;: 10, &quot;doc_count&quot;: 0, &quot;group_by_sex&quot;: { &quot;doc_count_error_upper_bound&quot;: 0, &quot;sum_other_doc_count&quot;: 0, &quot;buckets&quot;: [] } }, { &quot;key&quot;: &quot;10.0-20.0&quot;, &quot;from&quot;: 10, &quot;to&quot;: 20, &quot;doc_count&quot;: 2, &quot;group_by_sex&quot;: { &quot;doc_count_error_upper_bound&quot;: 0, &quot;sum_other_doc_count&quot;: 0, &quot;buckets&quot;: [ { &quot;key&quot;: &quot;man&quot;, &quot;doc_count&quot;: 1, &quot;average_age&quot;: { &quot;value&quot;: 17 } }, { &quot;key&quot;: &quot;woman&quot;, &quot;doc_count&quot;: 1, &quot;average_age&quot;: { &quot;value&quot;: 18 } } ] } }, { &quot;key&quot;: &quot;20.0-30.0&quot;, &quot;from&quot;: 20, &quot;to&quot;: 30, &quot;doc_count&quot;: 5, &quot;group_by_sex&quot;: { &quot;doc_count_error_upper_bound&quot;: 0, &quot;sum_other_doc_count&quot;: 0, &quot;buckets&quot;: [ { &quot;key&quot;: &quot;woman&quot;, &quot;doc_count&quot;: 3, &quot;average_age&quot;: { &quot;value&quot;: 23.333333333333332 } }, { &quot;key&quot;: &quot;man&quot;, &quot;doc_count&quot;: 2, &quot;average_age&quot;: { &quot;value&quot;: 21 } } ] } }, { &quot;key&quot;: &quot;30.0-100.0&quot;, &quot;from&quot;: 30, &quot;to&quot;: 100, &quot;doc_count&quot;: 2, &quot;group_by_sex&quot;: { &quot;doc_count_error_upper_bound&quot;: 0, &quot;sum_other_doc_count&quot;: 0, &quot;buckets&quot;: [ { &quot;key&quot;: &quot;man&quot;, &quot;doc_count&quot;: 2, &quot;average_age&quot;: { &quot;value&quot;: 31 } } ] } } ] } } }","tags":[{"name":"elasticsearch","slug":"elasticsearch","permalink":"http://dennis.pathto.top/tags/elasticsearch/"},{"name":"elk","slug":"elk","permalink":"http://dennis.pathto.top/tags/elk/"}]},{"title":"9.elasticsearch-查询demo","date":"2017-09-10T13:25:29.000Z","path":"2017/09/10/elasticsearch-normal-api/","text":"初始化数据创建一个company索引,在company索引下面建立一个emp类型,并且批量保存几个文档 curl -XPOST &apos;study0:9200/company/emp/_bulk&apos; -d &apos; { &quot;index&quot;: { &quot;_id&quot;: 1 }} { &quot;name&quot; : &quot;zhangshan&quot;, &quot;age&quot; : 21 , &quot;sex&quot;: &quot;man&quot;, &quot;birthday&quot;: &quot;1996-01-02&quot; , &quot;hobby&quot;: &quot;i like sport&quot; } { &quot;index&quot;: { &quot;_id&quot;: 2 }} { &quot;name&quot; : &quot;lisi&quot;, &quot;age&quot; : 21 , &quot;sex&quot;: &quot;man&quot;, &quot;birthday&quot;: &quot;1995-01-02&quot; , &quot;hobby&quot;: &quot;i like compute&quot; } { &quot;index&quot;: { &quot;_id&quot;: 3 }} { &quot;name&quot; : &quot;wangwu&quot;, &quot;age&quot; : 17 , &quot;sex&quot;: &quot;man&quot;, &quot;birthday&quot;: &quot;1998-01-02&quot; , &quot;hobby&quot;: &quot;i like trivel&quot; } { &quot;index&quot;: { &quot;_id&quot;: 4 }} { &quot;name&quot; : &quot;wangba&quot;, &quot;age&quot; : 25 , &quot;sex&quot;: &quot;woman&quot;, &quot;birthday&quot;: &quot;1996-01-02&quot; , &quot;hobby&quot;: &quot;i like trivel&quot; } { &quot;index&quot;: { &quot;_id&quot;: 5 }} { &quot;name&quot; : &quot;xiaoming&quot;, &quot;age&quot; : 25 , &quot;sex&quot;: &quot;woman&quot;, &quot;birthday&quot;: &quot;1991-01-02&quot; , &quot;hobby&quot;: &quot;i like song&quot; } { &quot;index&quot;: { &quot;_id&quot;: 6 }} { &quot;name&quot; : &quot;xiaohong&quot;, &quot;age&quot; : 31 , &quot;sex&quot;: &quot;man&quot;, &quot;birthday&quot;: &quot;1988-01-02&quot; , &quot;hobby&quot;: &quot;i like piano&quot; } { &quot;index&quot;: { &quot;_id&quot;: 7 }} { &quot;name&quot; : &quot;zhaowu&quot;, &quot;age&quot; : 31 , &quot;sex&quot;: &quot;man&quot;, &quot;birthday&quot;: &quot;1997-01-02&quot; , &quot;hobby&quot;: &quot;i like trivel and music&quot; } { &quot;index&quot;: { &quot;_id&quot;: 8 }} { &quot;name&quot; : &quot;zhaoliu&quot;, &quot;age&quot; : 18 , &quot;sex&quot;: &quot;woman&quot;, &quot;birthday&quot;: &quot;1998-01-02&quot; , &quot;hobby&quot;: &quot;i like compute game&quot; } { &quot;index&quot;: { &quot;_id&quot;: 9 }} { &quot;name&quot; : &quot;zhaoqi&quot;, &quot;age&quot; : 20 , &quot;sex&quot;: &quot;woman&quot;, &quot;birthday&quot;: &quot;1996-01-02&quot; , &quot;hobby&quot;: &quot;i like compute game&quot; } &apos; match类似sql中的like,但是比like查询更加强大 match_allmatch_all 表示要获取全部文档 curl -XPOST &apos;study0:9200/company/emp/_search&apos; -d &apos; { &quot;query&quot;: { &quot;match_all&quot;: {} } }&apos; 查询结果: {&quot;took&quot;:10,&quot;timed_out&quot;:false,&quot;_shards&quot;:{&quot;total&quot;:5,&quot;successful&quot;:5,&quot;failed&quot;:0},&quot;hits&quot;:{&quot;total&quot;:9,&quot;max_score&quot;:1.0,&quot;hits&quot;:[{&quot;_index&quot;:&quot;company&quot;,&quot;_type&quot;:&quot;emp&quot;,&quot;_id&quot;:&quot;5&quot;,&quot;_score&quot;:1.0,&quot;_source&quot;:{ &quot;name&quot; : &quot;xiaoming&quot;, &quot;age&quot; : 25 , &quot;sex&quot;: &quot;woman&quot;, &quot;birthday&quot;: &quot;1991-01-02&quot; , &quot;hobby&quot;: &quot;i like song&quot; }},{&quot;_index&quot;:&quot;company&quot;,&quot;_type&quot;:&quot;emp&quot;,&quot;_id&quot;:&quot;8&quot;,&quot;_score&quot;:1.0,&quot;_source&quot;:{ &quot;name&quot; : &quot;zhaoliu&quot;, &quot;age&quot; : 18 , &quot;sex&quot;: &quot;woman&quot;, &quot;birthday&quot;: &quot;1998-01-02&quot; , &quot;hobby&quot;: &quot;i like compute game&quot; }},{&quot;_index&quot;:&quot;company&quot;,&quot;_type&quot;:&quot;emp&quot;,&quot;_id&quot;:&quot;9&quot;,&quot;_score&quot;:1.0,&quot;_source&quot;:{ &quot;name&quot; : &quot;zhaoqi&quot;, &quot;age&quot; : 20 , &quot;sex&quot;: &quot;woman&quot;, &quot;birthday&quot;: &quot;1996-01-02&quot; , &quot;hobby&quot;: &quot;i like compute game&quot; }},{&quot;_index&quot;:&quot;company&quot;,&quot;_type&quot;:&quot;emp&quot;,&quot;_id&quot;:&quot;2&quot;,&quot;_score&quot;:1.0,&quot;_source&quot;:{ &quot;name&quot; : &quot;lisi&quot;, &quot;age&quot; : 21 , &quot;sex&quot;: &quot;man&quot;, &quot;birthday&quot;: &quot;1995-01-02&quot; , &quot;hobby&quot;: &quot;i like compute&quot; }},{&quot;_index&quot;:&quot;company&quot;,&quot;_type&quot;:&quot;emp&quot;,&quot;_id&quot;:&quot;4&quot;,&quot;_score&quot;:1.0,&quot;_source&quot;:{ &quot;name&quot; : &quot;wangba&quot;, &quot;age&quot; : 25 , &quot;sex&quot;: &quot;woman&quot;, &quot;birthday&quot;: &quot;1996-01-02&quot; , &quot;hobby&quot;: &quot;i like trivel&quot; }},{&quot;_index&quot;:&quot;company&quot;,&quot;_type&quot;:&quot;emp&quot;,&quot;_id&quot;:&quot;6&quot;,&quot;_score&quot;:1.0,&quot;_source&quot;:{ &quot;name&quot; : &quot;xiaohong&quot;, &quot;age&quot; : 31 , &quot;sex&quot;: &quot;man&quot;, &quot;birthday&quot;: &quot;1988-01-02&quot; , &quot;hobby&quot;: &quot;i like piano&quot; }},{&quot;_index&quot;:&quot;company&quot;,&quot;_type&quot;:&quot;emp&quot;,&quot;_id&quot;:&quot;1&quot;,&quot;_score&quot;:1.0,&quot;_source&quot;:{ &quot;name&quot; : &quot;zhangshan&quot;, &quot;age&quot; : 21 , &quot;sex&quot;: &quot;man&quot;, &quot;birthday&quot;: &quot;1996-01-02&quot; , &quot;hobby&quot;: &quot;i like sport&quot; }},{&quot;_index&quot;:&quot;company&quot;,&quot;_type&quot;:&quot;emp&quot;,&quot;_id&quot;:&quot;7&quot;,&quot;_score&quot;:1.0,&quot;_source&quot;:{ &quot;name&quot; : &quot;zhaowu&quot;, &quot;age&quot; : 31 , &quot;sex&quot;: &quot;man&quot;, &quot;birthday&quot;: &quot;1997-01-02&quot; , &quot;hobby&quot;: &quot;i like trivel and music&quot; }},{&quot;_index&quot;:&quot;company&quot;,&quot;_type&quot;:&quot;emp&quot;,&quot;_id&quot;:&quot;3&quot;,&quot;_score&quot;:1.0,&quot;_source&quot;:{ &quot;name&quot; : &quot;wangwu&quot;, &quot;age&quot; : 17 , &quot;sex&quot;: &quot;man&quot;, &quot;birthday&quot;: &quot;1998-01-02&quot; , &quot;hobby&quot;: &quot;i like trivel&quot; }}]}} pretty在查询url后面添加pretty,可以格式化查询结果，使阅读更加友好 curl -XPOST &apos;study0:9200/company/emp/_search?pretty&apos; -d &apos; { &quot;query&quot;: { &quot;match_all&quot;: {} } }&apos; 查询结果: { &quot;took&quot; : 8, &quot;timed_out&quot; : false, &quot;_shards&quot; : { &quot;total&quot; : 5, &quot;successful&quot; : 5, &quot;failed&quot; : 0 }, &quot;hits&quot; : { &quot;total&quot; : 9, &quot;max_score&quot; : 1.0, &quot;hits&quot; : [ { &quot;_index&quot; : &quot;company&quot;, &quot;_type&quot; : &quot;emp&quot;, &quot;_id&quot; : &quot;5&quot;, &quot;_score&quot; : 1.0, &quot;_source&quot; : { &quot;name&quot; : &quot;xiaoming&quot;, &quot;age&quot; : 25, &quot;sex&quot; : &quot;woman&quot;, &quot;birthday&quot; : &quot;1991-01-02&quot;, &quot;hobby&quot; : &quot;i like song&quot; } }, { &quot;_index&quot; : &quot;company&quot;, &quot;_type&quot; : &quot;emp&quot;, &quot;_id&quot; : &quot;8&quot;, &quot;_score&quot; : 1.0, &quot;_source&quot; : { &quot;name&quot; : &quot;zhaoliu&quot;, &quot;age&quot; : 18, &quot;sex&quot; : &quot;woman&quot;, &quot;birthday&quot; : &quot;1998-01-02&quot;, &quot;hobby&quot; : &quot;i like compute game&quot; } }, { &quot;_index&quot; : &quot;company&quot;, &quot;_type&quot; : &quot;emp&quot;, &quot;_id&quot; : &quot;9&quot;, &quot;_score&quot; : 1.0, &quot;_source&quot; : { &quot;name&quot; : &quot;zhaoqi&quot;, &quot;age&quot; : 20, &quot;sex&quot; : &quot;woman&quot;, &quot;birthday&quot; : &quot;1996-01-02&quot;, &quot;hobby&quot; : &quot;i like compute game&quot; } }, { &quot;_index&quot; : &quot;company&quot;, &quot;_type&quot; : &quot;emp&quot;, &quot;_id&quot; : &quot;2&quot;, &quot;_score&quot; : 1.0, &quot;_source&quot; : { &quot;name&quot; : &quot;lisi&quot;, &quot;age&quot; : 21, &quot;sex&quot; : &quot;man&quot;, &quot;birthday&quot; : &quot;1995-01-02&quot;, &quot;hobby&quot; : &quot;i like compute&quot; } }, { &quot;_index&quot; : &quot;company&quot;, &quot;_type&quot; : &quot;emp&quot;, &quot;_id&quot; : &quot;4&quot;, &quot;_score&quot; : 1.0, &quot;_source&quot; : { &quot;name&quot; : &quot;wangba&quot;, &quot;age&quot; : 25, &quot;sex&quot; : &quot;woman&quot;, &quot;birthday&quot; : &quot;1996-01-02&quot;, &quot;hobby&quot; : &quot;i like trivel&quot; } }, { &quot;_index&quot; : &quot;company&quot;, &quot;_type&quot; : &quot;emp&quot;, &quot;_id&quot; : &quot;6&quot;, &quot;_score&quot; : 1.0, &quot;_source&quot; : { &quot;name&quot; : &quot;xiaohong&quot;, &quot;age&quot; : 31, &quot;sex&quot; : &quot;man&quot;, &quot;birthday&quot; : &quot;1988-01-02&quot;, &quot;hobby&quot; : &quot;i like piano&quot; } }, { &quot;_index&quot; : &quot;company&quot;, &quot;_type&quot; : &quot;emp&quot;, &quot;_id&quot; : &quot;1&quot;, &quot;_score&quot; : 1.0, &quot;_source&quot; : { &quot;name&quot; : &quot;zhangshan&quot;, &quot;age&quot; : 21, &quot;sex&quot; : &quot;man&quot;, &quot;birthday&quot; : &quot;1996-01-02&quot;, &quot;hobby&quot; : &quot;i like sport&quot; } }, { &quot;_index&quot; : &quot;company&quot;, &quot;_type&quot; : &quot;emp&quot;, &quot;_id&quot; : &quot;7&quot;, &quot;_score&quot; : 1.0, &quot;_source&quot; : { &quot;name&quot; : &quot;zhaowu&quot;, &quot;age&quot; : 31, &quot;sex&quot; : &quot;man&quot;, &quot;birthday&quot; : &quot;1997-01-02&quot;, &quot;hobby&quot; : &quot;i like trivel and music&quot; } }, { &quot;_index&quot; : &quot;company&quot;, &quot;_type&quot; : &quot;emp&quot;, &quot;_id&quot; : &quot;3&quot;, &quot;_score&quot; : 1.0, &quot;_source&quot; : { &quot;name&quot; : &quot;wangwu&quot;, &quot;age&quot; : 17, &quot;sex&quot; : &quot;man&quot;, &quot;birthday&quot; : &quot;1998-01-02&quot;, &quot;hobby&quot; : &quot;i like trivel&quot; } } ] } } match查询hobby字段，喜欢trivel的人 curl -XPOST &apos;study0:9200/company/emp/_search?pretty&apos; -d &apos; { &quot;query&quot;: { &quot;match&quot;: {&quot;hobby&quot;: &quot;trivel&quot;} } }&apos; 查询结果 { &quot;took&quot; : 20, &quot;timed_out&quot; : false, &quot;_shards&quot; : { &quot;total&quot; : 5, &quot;successful&quot; : 5, &quot;failed&quot; : 0 }, &quot;hits&quot; : { &quot;total&quot; : 3, &quot;max_score&quot; : 0.86312973, &quot;hits&quot; : [ { &quot;_index&quot; : &quot;company&quot;, &quot;_type&quot; : &quot;emp&quot;, &quot;_id&quot; : &quot;4&quot;, &quot;_score&quot; : 0.86312973, &quot;_source&quot; : { &quot;name&quot; : &quot;wangba&quot;, &quot;age&quot; : 25, &quot;sex&quot; : &quot;woman&quot;, &quot;birthday&quot; : &quot;1996-01-02&quot;, &quot;hobby&quot; : &quot;i like trivel&quot; } }, { &quot;_index&quot; : &quot;company&quot;, &quot;_type&quot; : &quot;emp&quot;, &quot;_id&quot; : &quot;7&quot;, &quot;_score&quot; : 0.6160039, &quot;_source&quot; : { &quot;name&quot; : &quot;zhaowu&quot;, &quot;age&quot; : 31, &quot;sex&quot; : &quot;man&quot;, &quot;birthday&quot; : &quot;1997-01-02&quot;, &quot;hobby&quot; : &quot;i like trivel and music&quot; } }, { &quot;_index&quot; : &quot;company&quot;, &quot;_type&quot; : &quot;emp&quot;, &quot;_id&quot; : &quot;3&quot;, &quot;_score&quot; : 0.25316024, &quot;_source&quot; : { &quot;name&quot; : &quot;wangwu&quot;, &quot;age&quot; : 17, &quot;sex&quot; : &quot;man&quot;, &quot;birthday&quot; : &quot;1998-01-02&quot;, &quot;hobby&quot; : &quot;i like trivel&quot; } } ] } } 多条件查询多条件查询的时候，可以用bool对象。Bool包含的字段有：must，must_not，should must和must_not查找hobby是compute，并且sex字段不是”man”的文档 curl -XPOST &apos;study0:9200/company/emp/_search?pretty&apos; -d &apos; { &quot;query&quot;: { &quot;bool&quot;: { &quot;must&quot;: { &quot;match&quot;: {&quot;hobby&quot;: &quot;compute&quot;}}, &quot;must_not&quot;: {&quot;match&quot;: {&quot;sex&quot;: &quot;man&quot;}} } } }&apos; 查询结果: { &quot;took&quot; : 10, &quot;timed_out&quot; : false, &quot;_shards&quot; : { &quot;total&quot; : 5, &quot;successful&quot; : 5, &quot;failed&quot; : 0 }, &quot;hits&quot; : { &quot;total&quot; : 2, &quot;max_score&quot; : 0.45315093, &quot;hits&quot; : [ { &quot;_index&quot; : &quot;company&quot;, &quot;_type&quot; : &quot;emp&quot;, &quot;_id&quot; : &quot;8&quot;, &quot;_score&quot; : 0.45315093, &quot;_source&quot; : { &quot;name&quot; : &quot;zhaoliu&quot;, &quot;age&quot; : 18, &quot;sex&quot; : &quot;woman&quot;, &quot;birthday&quot; : &quot;1998-01-02&quot;, &quot;hobby&quot; : &quot;i like compute game&quot; } }, { &quot;_index&quot; : &quot;company&quot;, &quot;_type&quot; : &quot;emp&quot;, &quot;_id&quot; : &quot;9&quot;, &quot;_score&quot; : 0.45315093, &quot;_source&quot; : { &quot;name&quot; : &quot;zhaoqi&quot;, &quot;age&quot; : 20, &quot;sex&quot; : &quot;woman&quot;, &quot;birthday&quot; : &quot;1996-01-02&quot;, &quot;hobby&quot; : &quot;i like compute game&quot; } } ] } } should查询hobby是trivel或者性别是man的文档 这种查询和sql中的or很类似 curl -XPOST &apos;study0:9200/company/emp/_search?pretty&apos; -d &apos; { &quot;query&quot;: { &quot;bool&quot;: { &quot;must&quot;: { &quot;match&quot;: {&quot;hobby&quot;: &quot;trivel&quot;}}, &quot;should&quot;: {&quot;match&quot;: {&quot;sex&quot;: &quot;man&quot;}} } } }&apos; 查询结果: { &quot;took&quot; : 8, &quot;timed_out&quot; : false, &quot;_shards&quot; : { &quot;total&quot; : 5, &quot;successful&quot; : 5, &quot;failed&quot; : 0 }, &quot;hits&quot; : { &quot;total&quot; : 3, &quot;max_score&quot; : 0.86312973, &quot;hits&quot; : [ { &quot;_index&quot; : &quot;company&quot;, &quot;_type&quot; : &quot;emp&quot;, &quot;_id&quot; : &quot;4&quot;, &quot;_score&quot; : 0.86312973, &quot;_source&quot; : { &quot;name&quot; : &quot;wangba&quot;, &quot;age&quot; : 25, &quot;sex&quot; : &quot;woman&quot;, &quot;birthday&quot; : &quot;1996-01-02&quot;, &quot;hobby&quot; : &quot;i like trivel&quot; } }, { &quot;_index&quot; : &quot;company&quot;, &quot;_type&quot; : &quot;emp&quot;, &quot;_id&quot; : &quot;7&quot;, &quot;_score&quot; : 0.7983254, &quot;_source&quot; : { &quot;name&quot; : &quot;zhaowu&quot;, &quot;age&quot; : 31, &quot;sex&quot; : &quot;man&quot;, &quot;birthday&quot; : &quot;1997-01-02&quot;, &quot;hobby&quot; : &quot;i like trivel and music&quot; } }, { &quot;_index&quot; : &quot;company&quot;, &quot;_type&quot; : &quot;emp&quot;, &quot;_id&quot; : &quot;3&quot;, &quot;_score&quot; : 0.5408423, &quot;_source&quot; : { &quot;name&quot; : &quot;wangwu&quot;, &quot;age&quot; : 17, &quot;sex&quot; : &quot;man&quot;, &quot;birthday&quot; : &quot;1998-01-02&quot;, &quot;hobby&quot; : &quot;i like trivel&quot; } } ] } } Term过滤term主要用于精确匹配值，比如数字，日期，布尔值或 not_analyzed的字符串(未经分析的文本数据类型) { &quot;term&quot;: { &quot;age&quot;: 26 }} { &quot;term&quot;: { &quot;date&quot;: &quot;2017-06-09&quot; }} { &quot;term&quot;: { &quot;sex&quot;: true }} 用term过滤替换matchcurl -XPOST &apos;study0:9200/company/emp/_search?pretty&apos; -d &apos; { &quot;query&quot;: { &quot;bool&quot;: { &quot;must&quot;: { &quot;term&quot;: {&quot;hobby&quot;: &quot;trivel&quot;}}, &quot;should&quot;: {&quot;term&quot;: {&quot;sex&quot;: &quot;man&quot;}} }} }&apos; 查询结果 { &quot;took&quot; : 7, &quot;timed_out&quot; : false, &quot;_shards&quot; : { &quot;total&quot; : 5, &quot;successful&quot; : 5, &quot;failed&quot; : 0 }, &quot;hits&quot; : { &quot;total&quot; : 3, &quot;max_score&quot; : 0.86312973, &quot;hits&quot; : [ { &quot;_index&quot; : &quot;company&quot;, &quot;_type&quot; : &quot;emp&quot;, &quot;_id&quot; : &quot;4&quot;, &quot;_score&quot; : 0.86312973, &quot;_source&quot; : { &quot;name&quot; : &quot;wangba&quot;, &quot;age&quot; : 25, &quot;sex&quot; : &quot;woman&quot;, &quot;birthday&quot; : &quot;1996-01-02&quot;, &quot;hobby&quot; : &quot;i like trivel&quot; } }, { &quot;_index&quot; : &quot;company&quot;, &quot;_type&quot; : &quot;emp&quot;, &quot;_id&quot; : &quot;7&quot;, &quot;_score&quot; : 0.7983254, &quot;_source&quot; : { &quot;name&quot; : &quot;zhaowu&quot;, &quot;age&quot; : 31, &quot;sex&quot; : &quot;man&quot;, &quot;birthday&quot; : &quot;1997-01-02&quot;, &quot;hobby&quot; : &quot;i like trivel and music&quot; } }, { &quot;_index&quot; : &quot;company&quot;, &quot;_type&quot; : &quot;emp&quot;, &quot;_id&quot; : &quot;3&quot;, &quot;_score&quot; : 0.5408423, &quot;_source&quot; : { &quot;name&quot; : &quot;wangwu&quot;, &quot;age&quot; : 17, &quot;sex&quot; : &quot;man&quot;, &quot;birthday&quot; : &quot;1998-01-02&quot;, &quot;hobby&quot; : &quot;i like trivel&quot; } } ] } } terms可以用来匹配多个值curl -XPOST &apos;study0:9200/company/emp/_search?pretty&apos; -d &apos; { &quot;query&quot;: { &quot;bool&quot;: { &quot;must&quot;: { &quot;terms&quot;: {&quot;hobby&quot;: [&quot;trivel&quot;,&quot;music&quot;]}} } } }&apos; 查询结果，可以匹配到语句里面包含，trivel,或者music的单词。 { &quot;took&quot; : 16, &quot;timed_out&quot; : false, &quot;_shards&quot; : { &quot;total&quot; : 5, &quot;successful&quot; : 5, &quot;failed&quot; : 0 }, &quot;hits&quot; : { &quot;total&quot; : 3, &quot;max_score&quot; : 1.2320077, &quot;hits&quot; : [ { &quot;_index&quot; : &quot;company&quot;, &quot;_type&quot; : &quot;emp&quot;, &quot;_id&quot; : &quot;7&quot;, &quot;_score&quot; : 1.2320077, &quot;_source&quot; : { &quot;name&quot; : &quot;zhaowu&quot;, &quot;age&quot; : 31, &quot;sex&quot; : &quot;man&quot;, &quot;birthday&quot; : &quot;1997-01-02&quot;, &quot;hobby&quot; : &quot;i like trivel and music&quot; } }, { &quot;_index&quot; : &quot;company&quot;, &quot;_type&quot; : &quot;emp&quot;, &quot;_id&quot; : &quot;4&quot;, &quot;_score&quot; : 0.86312973, &quot;_source&quot; : { &quot;name&quot; : &quot;wangba&quot;, &quot;age&quot; : 25, &quot;sex&quot; : &quot;woman&quot;, &quot;birthday&quot; : &quot;1996-01-02&quot;, &quot;hobby&quot; : &quot;i like trivel&quot; } }, { &quot;_index&quot; : &quot;company&quot;, &quot;_type&quot; : &quot;emp&quot;, &quot;_id&quot; : &quot;3&quot;, &quot;_score&quot; : 0.25316024, &quot;_source&quot; : { &quot;name&quot; : &quot;wangwu&quot;, &quot;age&quot; : 17, &quot;sex&quot; : &quot;man&quot;, &quot;birthday&quot; : &quot;1998-01-02&quot;, &quot;hobby&quot; : &quot;i like trivel&quot; } } ] } } 关于match和term比较的例子 term主要是用于精确的过滤，代表完全匹配，即不进行分词器分析，文档中必须包含整个搜索的词汇，比如说,要匹配”我爱中国”,只能匹配到包含”我爱中国”的文本 match会根据你给定的字段提供合适的分析器,比如需要匹配”我爱中国”，会先分词，我、爱、中国、我爱等，然后在匹配 matchcurl -XPOST &apos;study0:9200/company/emp/_search?pretty&apos; -d &apos; { &quot;query&quot;: { &quot;bool&quot;: { &quot;must&quot;: { &quot;match&quot;: {&quot;hobby&quot;: &quot;trivel and&quot;}} } } }&apos; 查询结果 { &quot;took&quot; : 13, &quot;timed_out&quot; : false, &quot;_shards&quot; : { &quot;total&quot; : 5, &quot;successful&quot; : 5, &quot;failed&quot; : 0 }, &quot;hits&quot; : { &quot;total&quot; : 3, &quot;max_score&quot; : 1.2320077, &quot;hits&quot; : [ { &quot;_index&quot; : &quot;company&quot;, &quot;_type&quot; : &quot;emp&quot;, &quot;_id&quot; : &quot;7&quot;, &quot;_score&quot; : 1.2320077, &quot;_source&quot; : { &quot;name&quot; : &quot;zhaowu&quot;, &quot;age&quot; : 31, &quot;sex&quot; : &quot;man&quot;, &quot;birthday&quot; : &quot;1997-01-02&quot;, &quot;hobby&quot; : &quot;i like trivel and music&quot; } }, { &quot;_index&quot; : &quot;company&quot;, &quot;_type&quot; : &quot;emp&quot;, &quot;_id&quot; : &quot;4&quot;, &quot;_score&quot; : 0.86312973, &quot;_source&quot; : { &quot;name&quot; : &quot;wangba&quot;, &quot;age&quot; : 25, &quot;sex&quot; : &quot;woman&quot;, &quot;birthday&quot; : &quot;1996-01-02&quot;, &quot;hobby&quot; : &quot;i like trivel&quot; } }, { &quot;_index&quot; : &quot;company&quot;, &quot;_type&quot; : &quot;emp&quot;, &quot;_id&quot; : &quot;3&quot;, &quot;_score&quot; : 0.25316024, &quot;_source&quot; : { &quot;name&quot; : &quot;wangwu&quot;, &quot;age&quot; : 17, &quot;sex&quot; : &quot;man&quot;, &quot;birthday&quot; : &quot;1998-01-02&quot;, &quot;hobby&quot; : &quot;i like trivel&quot; } } ] } } 上面的，返回包含trivel 或者 and 或者 trivel and 都包含的索引。 termcurl -XPOST &apos;study0:9200/company/emp/_search?pretty&apos; -d &apos; { &quot;query&quot;: { &quot;bool&quot;: { &quot;must&quot;: { &quot;term&quot;: {&quot;hobby&quot;: &quot;trivel and&quot;}} } } }&apos; 查询结果 { &quot;took&quot; : 7, &quot;timed_out&quot; : false, &quot;_shards&quot; : { &quot;total&quot; : 5, &quot;successful&quot; : 5, &quot;failed&quot; : 0 }, &quot;hits&quot; : { &quot;total&quot; : 0, &quot;max_score&quot; : null, &quot;hits&quot; : [ ] } } 但是可以看到使用terms是没有返回结果的。就说明terms是精准匹配词组。 Range过滤Range过滤允许我们按照指定的范围查找一些数据：操作范围：gt(大于)，gae(大于等于),lt(小于)，lte(小于等于)： range之gt和lt查找出大于20岁，小于25岁的emp curl -XPOST &apos;study0:9200/company/emp/_search?pretty&apos; -d &apos; { &quot;query&quot;: { &quot;range&quot;: { &quot;age&quot;: {&quot;gt&quot;:20,&quot;lt&quot;:30} } } } }&apos; 查询结果 { &quot;took&quot; : 19, &quot;timed_out&quot; : false, &quot;_shards&quot; : { &quot;total&quot; : 5, &quot;successful&quot; : 5, &quot;failed&quot; : 0 }, &quot;hits&quot; : { &quot;total&quot; : 4, &quot;max_score&quot; : 1.0, &quot;hits&quot; : [ { &quot;_index&quot; : &quot;company&quot;, &quot;_type&quot; : &quot;emp&quot;, &quot;_id&quot; : &quot;5&quot;, &quot;_score&quot; : 1.0, &quot;_source&quot; : { &quot;name&quot; : &quot;xiaoming&quot;, &quot;age&quot; : 25, &quot;sex&quot; : &quot;woman&quot;, &quot;birthday&quot; : &quot;1991-01-02&quot;, &quot;hobby&quot; : &quot;i like song&quot; } }, { &quot;_index&quot; : &quot;company&quot;, &quot;_type&quot; : &quot;emp&quot;, &quot;_id&quot; : &quot;2&quot;, &quot;_score&quot; : 1.0, &quot;_source&quot; : { &quot;name&quot; : &quot;lisi&quot;, &quot;age&quot; : 21, &quot;sex&quot; : &quot;man&quot;, &quot;birthday&quot; : &quot;1995-01-02&quot;, &quot;hobby&quot; : &quot;i like compute&quot; } }, { &quot;_index&quot; : &quot;company&quot;, &quot;_type&quot; : &quot;emp&quot;, &quot;_id&quot; : &quot;4&quot;, &quot;_score&quot; : 1.0, &quot;_source&quot; : { &quot;name&quot; : &quot;wangba&quot;, &quot;age&quot; : 25, &quot;sex&quot; : &quot;woman&quot;, &quot;birthday&quot; : &quot;1996-01-02&quot;, &quot;hobby&quot; : &quot;i like trivel&quot; } }, { &quot;_index&quot; : &quot;company&quot;, &quot;_type&quot; : &quot;emp&quot;, &quot;_id&quot; : &quot;1&quot;, &quot;_score&quot; : 1.0, &quot;_source&quot; : { &quot;name&quot; : &quot;zhangshan&quot;, &quot;age&quot; : 21, &quot;sex&quot; : &quot;man&quot;, &quot;birthday&quot; : &quot;1996-01-02&quot;, &quot;hobby&quot; : &quot;i like sport&quot; } } ] } } exists和 missing过滤Exists表示包含某个字段，missing表示没有某个字段的文档 exists匹配有age字段的文档 curl -XPOST &apos;study0:9200/company/emp/_search&apos; -d &apos; { &quot;query&quot;: { &quot;exists&quot;: { &quot;field&quot;: &quot;age&quot; } } } }&apos; 查询结果 {&quot;took&quot;:3,&quot;timed_out&quot;:false,&quot;_shards&quot;:{&quot;total&quot;:5,&quot;successful&quot;:5,&quot;failed&quot;:0},&quot;hits&quot;:{&quot;total&quot;:9,&quot;max_score&quot;:1.0,&quot;hits&quot;:[{&quot;_index&quot;:&quot;company&quot;,&quot;_type&quot;:&quot;emp&quot;,&quot;_id&quot;:&quot;5&quot;,&quot;_score&quot;:1.0,&quot;_source&quot;:{ &quot;name&quot; : &quot;xiaoming&quot;, &quot;age&quot; : 25 , &quot;sex&quot;: &quot;woman&quot;, &quot;birthday&quot;: &quot;1991-01-02&quot; , &quot;hobby&quot;: &quot;i like song&quot; }},{&quot;_index&quot;:&quot;company&quot;,&quot;_type&quot;:&quot;emp&quot;,&quot;_id&quot;:&quot;8&quot;,&quot;_score&quot;:1.0,&quot;_source&quot;:{ &quot;name&quot; : &quot;zhaoliu&quot;, &quot;age&quot; : 18 , &quot;sex&quot;: &quot;woman&quot;, &quot;birthday&quot;: &quot;1998-01-02&quot; , &quot;hobby&quot;: &quot;i like compute game&quot; }},{&quot;_index&quot;:&quot;company&quot;,&quot;_type&quot;:&quot;emp&quot;,&quot;_id&quot;:&quot;9&quot;,&quot;_score&quot;:1.0,&quot;_source&quot;:{ &quot;name&quot; : &quot;zhaoqi&quot;, &quot;age&quot; : 20 , &quot;sex&quot;: &quot;woman&quot;, &quot;birthday&quot;: &quot;1996-01-02&quot; , &quot;hobby&quot;: &quot;i like compute game&quot; }},{&quot;_index&quot;:&quot;company&quot;,&quot;_type&quot;:&quot;emp&quot;,&quot;_id&quot;:&quot;2&quot;,&quot;_score&quot;:1.0,&quot;_source&quot;:{ &quot;name&quot; : &quot;lisi&quot;, &quot;age&quot; : 21 , &quot;sex&quot;: &quot;man&quot;, &quot;birthday&quot;: &quot;1995-01-02&quot; , &quot;hobby&quot;: &quot;i like compute&quot; }},{&quot;_index&quot;:&quot;company&quot;,&quot;_type&quot;:&quot;emp&quot;,&quot;_id&quot;:&quot;4&quot;,&quot;_score&quot;:1.0,&quot;_source&quot;:{ &quot;name&quot; : &quot;wangba&quot;, &quot;age&quot; : 25 , &quot;sex&quot;: &quot;woman&quot;, &quot;birthday&quot;: &quot;1996-01-02&quot; , &quot;hobby&quot;: &quot;i like trivel&quot; }},{&quot;_index&quot;:&quot;company&quot;,&quot;_type&quot;:&quot;emp&quot;,&quot;_id&quot;:&quot;6&quot;,&quot;_score&quot;:1.0,&quot;_source&quot;:{ &quot;name&quot; : &quot;xiaohong&quot;, &quot;age&quot; : 31 , &quot;sex&quot;: &quot;man&quot;, &quot;birthday&quot;: &quot;1988-01-02&quot; , &quot;hobby&quot;: &quot;i like piano&quot; }},{&quot;_index&quot;:&quot;company&quot;,&quot;_type&quot;:&quot;emp&quot;,&quot;_id&quot;:&quot;1&quot;,&quot;_score&quot;:1.0,&quot;_source&quot;:{ &quot;name&quot; : &quot;zhangshan&quot;, &quot;age&quot; : 21 , &quot;sex&quot;: &quot;man&quot;, &quot;birthday&quot;: &quot;1996-01-02&quot; , &quot;hobby&quot;: &quot;i like sport&quot; }},{&quot;_index&quot;:&quot;company&quot;,&quot;_type&quot;:&quot;emp&quot;,&quot;_id&quot;:&quot;7&quot;,&quot;_score&quot;:1.0,&quot;_source&quot;:{ &quot;name&quot; : &quot;zhaowu&quot;, &quot;age&quot; : 31 , &quot;sex&quot;: &quot;man&quot;, &quot;birthday&quot;: &quot;1997-01-02&quot; , &quot;hobby&quot;: &quot;i like trivel and music&quot; }},{&quot;_index&quot;:&quot;company&quot;,&quot;_type&quot;:&quot;emp&quot;,&quot;_id&quot;:&quot;3&quot;,&quot;_score&quot;:1.0,&quot;_source&quot;:{ &quot;name&quot; : &quot;wangwu&quot;, &quot;age&quot; : 17 , &quot;sex&quot;: &quot;man&quot;, &quot;birthday&quot;: &quot;1998-01-02&quot; , &quot;hobby&quot;: &quot;i like trivel&quot; }}]}} 注意:上面全部结果都查询出来了 bool用bool可以进行多行条件查询 must: 多个查询条件的完全匹配,相当于 and 。 must_not:多个查询条件的相反匹配，相当于 not 。 should:至少有一个查询条件匹配, 相当于 or 。 执行下面的查询 curl -XGET ‘study0:9200/company/emp/_search?pretty’ -d ‘{“query”: { “bool”: { “must”: { “match”: {“hobby”: “trivel”}}, “must_not”: {“match”: {“sex”: “man”}} } }}’ 查询结果 { &quot;took&quot; : 7, &quot;timed_out&quot; : false, &quot;_shards&quot; : { &quot;total&quot; : 5, &quot;successful&quot; : 5, &quot;failed&quot; : 0 }, &quot;hits&quot; : { &quot;total&quot; : 1, &quot;max_score&quot; : 1.8631297, &quot;hits&quot; : [ { &quot;_index&quot; : &quot;company&quot;, &quot;_type&quot; : &quot;emp&quot;, &quot;_id&quot; : &quot;4&quot;, &quot;_score&quot; : 1.8631297, &quot;_source&quot; : { &quot;name&quot; : &quot;wangba&quot;, &quot;age&quot; : 25, &quot;sex&quot; : &quot;woman&quot;, &quot;birthday&quot; : &quot;1996-01-02&quot;, &quot;hobby&quot; : &quot;i like trivel&quot; } } ] } } 普通查询与过滤条件合并curl -XPOST &apos;study0:9200/company/emp/_search?pretty&apos; -d &apos; { &quot;query&quot;: { &quot;bool&quot;: { &quot;must&quot;: {&quot;match&quot;: {&quot;hobby&quot;: &quot;compute&quot;}}, &quot;filter&quot;: [{&quot;term&quot;:{&quot;age&quot;: 20}}] } } }&apos; 查询结果 { &quot;took&quot; : 4, &quot;timed_out&quot; : false, &quot;_shards&quot; : { &quot;total&quot; : 5, &quot;successful&quot; : 5, &quot;failed&quot; : 0 }, &quot;hits&quot; : { &quot;total&quot; : 1, &quot;max_score&quot; : 0.45315093, &quot;hits&quot; : [ { &quot;_index&quot; : &quot;company&quot;, &quot;_type&quot; : &quot;emp&quot;, &quot;_id&quot; : &quot;9&quot;, &quot;_score&quot; : 0.45315093, &quot;_source&quot; : { &quot;name&quot; : &quot;zhaoqi&quot;, &quot;age&quot; : 20, &quot;sex&quot; : &quot;woman&quot;, &quot;birthday&quot; : &quot;1996-01-02&quot;, &quot;hobby&quot; : &quot;i like compute game&quot; } } ] } } 条件过滤curl -XPOST &apos;study0:9200/company/emp/_search?pretty&apos; -d &apos; { &quot;query&quot;: { &quot;bool&quot;: { &quot;filter&quot;: [{&quot;term&quot;:{&quot;age&quot;: 20}}] } } }&apos; 查询结果 { &quot;took&quot; : 9, &quot;timed_out&quot; : false, &quot;_shards&quot; : { &quot;total&quot; : 5, &quot;successful&quot; : 5, &quot;failed&quot; : 0 }, &quot;hits&quot; : { &quot;total&quot; : 1, &quot;max_score&quot; : 0.0, &quot;hits&quot; : [ { &quot;_index&quot; : &quot;company&quot;, &quot;_type&quot; : &quot;emp&quot;, &quot;_id&quot; : &quot;9&quot;, &quot;_score&quot; : 0.0, &quot;_source&quot; : { &quot;name&quot; : &quot;zhaoqi&quot;, &quot;age&quot; : 20, &quot;sex&quot; : &quot;woman&quot;, &quot;birthday&quot; : &quot;1996-01-02&quot;, &quot;hobby&quot; : &quot;i like compute game&quot; } } ] } }","tags":[{"name":"elasticsearch","slug":"elasticsearch","permalink":"http://dennis.pathto.top/tags/elasticsearch/"},{"name":"elk","slug":"elk","permalink":"http://dennis.pathto.top/tags/elk/"}]},{"title":"10.elasticsearch中的match查询和bool查询的关系，提升查询子句","date":"2017-09-10T13:25:29.000Z","path":"2017/09/10/elasticsearch-10-match-bool/","text":"match和bool查询等价的例子现在，你也许意识到了使用了match查询的多词查询只是简单地将生成的term查询包含在了一个bool查询中。通过默认的or操作符，每个term查询都以一个语句被添加，所以至少一个should语句需要被匹配。以下两个查询是等价的： { &quot;match&quot;: { &quot;title&quot;: &quot;brown fox&quot;} } { &quot;bool&quot;: { &quot;should&quot;: [ { &quot;term&quot;: { &quot;title&quot;: &quot;brown&quot; }}, { &quot;term&quot;: { &quot;title&quot;: &quot;fox&quot; }} ] } } 使用and操作符时，所有的term查询都以must语句被添加，因此所有的查询都需要匹配。以下两个查询是等价的： { &quot;match&quot;: { &quot;title&quot;: { &quot;query&quot;:&quot;brown fox&quot;, &quot;operator&quot;: &quot;and&quot; } } } { &quot;bool&quot;: { &quot;must&quot;: [ { &quot;term&quot;: { &quot;title&quot;: &quot;brown&quot; }}, { &quot;term&quot;: { &quot;title&quot;: &quot;fox&quot; }} ] } } 如果指定了minimum_should_match参数，它会直接被传入到bool查询中，因此下面两个查询是等价的： { &quot;match&quot;: { &quot;title&quot;: { &quot;query&quot;:&quot;quick brown fox&quot;, &quot;minimum_should_match&quot;: &quot;75%&quot; } } } { &quot;bool&quot;: { &quot;should&quot;: [ { &quot;term&quot;: { &quot;title&quot;: &quot;brown&quot; }}, { &quot;term&quot;: { &quot;title&quot;: &quot;fox&quot; }}, { &quot;term&quot;: { &quot;title&quot;: &quot;quick&quot; }} ], &quot;minimum_should_match&quot;: 2 } } 因为只有3个查询语句，minimum_should_match的值75%会被向下舍入到2。即至少两个should语句需要匹配。 当然，我们可以通过match查询来编写这类查询，但是理解match查询的内部工作原理能够让你根据需要来控制该过程。有些行为无法通过一个match查询完成，比如对部分查询词条给予更多的权重。在下一节中我们会看到一个例子。 提升查询子句(Boosting Query Clause)当然，bool查询并不是只能合并简单的单词(One-word)match查询。它能够合并任何其它的查询，包括其它的bool查询。它通常被用来通过合并数个单独的查询的分值来调优每份文档的相关度_score。 假设我们需要搜索和”full-text search”相关的文档，但是我们想要给予那些提到了”Elasticsearch”或者”Lucene”的文档更多权重。更多权重的意思是，对于提到了”Elasticsearch”或者”Lucene”的文档，它们的相关度_score会更高，即它们会出现在结果列表的前面。 一个简单的bool查询能够让我们表达较为复杂的逻辑： GET /_search { &quot;query&quot;: { &quot;bool&quot;: { &quot;must&quot;: { &quot;match&quot;: { &quot;content&quot;: { &quot;query&quot;:&quot;full text search&quot;, &quot;operator&quot;: &quot;and&quot; } } }, &quot;should&quot;: [ { &quot;match&quot;: { &quot;content&quot;: &quot;Elasticsearch&quot; }}, { &quot;match&quot;: { &quot;content&quot;: &quot;Lucene&quot;}} ] } } } content字段必须含有full，text和search这三个词条 如果content字段也含有了词条Elasticsearch或者Lucene，那么该文档会有一个较高的_score should查询子句的匹配数量越多，那么文档的相关度就越高。目前为止还不错。 但是如果我们想给含有Lucene的文档多一些权重，同时给含有Elasticsearch的文档更多一些权重呢？ 我们可以通过指定一个boost值来控制每个查询子句的相对权重，该值默认为1。一个大于1的boost会增加该查询子句的相对权重。因此我们可以将上述查询重写如下： GET /_search { &quot;query&quot;: { &quot;bool&quot;: { &quot;must&quot;: { &quot;match&quot;: { &quot;content&quot;: { &quot;query&quot;:&quot;full text search&quot;, &quot;operator&quot;: &quot;and&quot; } } }, &quot;should&quot;: [ { &quot;match&quot;: { &quot;content&quot;: { &quot;query&quot;: &quot;Elasticsearch&quot;, &quot;boost&quot;: 3 } }}, { &quot;match&quot;: { &quot;content&quot;: { &quot;query&quot;: &quot;Lucene&quot;, &quot;boost&quot;: 2 } }} ] } } } boost参数被用来增加一个子句的相对权重(当boost大于1时)，或者减小相对权重(当boost介于0到1时)，但是增加或者减小不是线性的。换言之，boost设为2并不会让最终的_score加倍。 相反，新的_score会在适用了boost后被归一化(Normalized)。每种查询都有自己的归一化算法(Normalization Algorithm)。但是能够说一个高的boost值会产生一个高的_score。 如果你在实现你自己的不基于TF/IDF的相关度分值模型并且你需要对提升过程拥有更多的控制，你可以使用function_score查询，它不通过归一化步骤对文档的boost进行操作。","tags":[{"name":"elasticsearch","slug":"elasticsearch","permalink":"http://dennis.pathto.top/tags/elasticsearch/"},{"name":"elk","slug":"elk","permalink":"http://dennis.pathto.top/tags/elk/"}]},{"title":"8.elasticsearch几种查询","date":"2017-09-09T13:25:29.000Z","path":"2017/09/09/elasticsearch-8-several-query/","text":"数据准备 image query string search搜索全部商品GET /company/emp/_search 序号 属性 描述 1 took 耗费了几毫秒 2 timed_out 是否超时，这里是没有 3 _shards 数据拆成了5个分片，所以对于搜索请求，会打到所有的primary shard（或者是它的某个replica shard也可以） 4 hits.total 查询结果的数量，9个document 5 hits.max_score score的含义，就是document对于一个search的相关度的匹配分数，越相关，就越匹配，分数也高 6 hits.hits 包含了匹配搜索的document的详细数据 { &quot;took&quot;: 41, &quot;timed_out&quot;: false, &quot;_shards&quot;: { &quot;total&quot;: 5, &quot;successful&quot;: 5, &quot;failed&quot;: 0 }, &quot;hits&quot;: { &quot;total&quot;: 9, &quot;max_score&quot;: 1, &quot;hits&quot;: [ { &quot;_index&quot;: &quot;company&quot;, &quot;_type&quot;: &quot;emp&quot;, &quot;_id&quot;: &quot;5&quot;, &quot;_score&quot;: 1, &quot;_source&quot;: { &quot;name&quot;: &quot;xiaoming&quot;, &quot;age&quot;: 25, &quot;sex&quot;: &quot;woman&quot;, &quot;birthday&quot;: &quot;1991-01-02&quot;, &quot;hobby&quot;: &quot;i like song&quot; } }, { &quot;_index&quot;: &quot;company&quot;, &quot;_type&quot;: &quot;emp&quot;, &quot;_id&quot;: &quot;8&quot;, &quot;_score&quot;: 1, &quot;_source&quot;: { &quot;name&quot;: &quot;zhaoliu&quot;, &quot;age&quot;: 18, &quot;sex&quot;: &quot;woman&quot;, &quot;birthday&quot;: &quot;1998-01-02&quot;, &quot;hobby&quot;: &quot;i like compute game&quot; } ...... } } ] } } query string search搜索company中包含trivel的人员，而且按照年龄降序排序 GET /company/_search?q=hobby:trivel&amp;sort=age:desc 注意:适用于临时的在命令行使用一些工具，比如curl，快速的发出请求，来检索想要的信息；但是如果查询请求很复杂，是很难去构建的在生产环境中，几乎很少使用query string search query DSLa.查询所有的company所有员工 GET /company/_search { &quot;query&quot;: { &quot;match_all&quot;: {} } } b.查询hobby包含trivel的商品，同时按照age降序排序 GET /company/_search { &quot;query&quot; : { &quot;match&quot; : { &quot;hobby&quot; : &quot;trivel&quot; } }, &quot;sort&quot;: [ { &quot;age&quot;: &quot;desc&quot; } ] } c.分页查询company，总共9条记录，假设每页就显示1条，现在显示第2页，所以就查出来第2个记录 GET company/_search { &quot;query&quot;: { &quot;match_all&quot;: {} }, &quot;from&quot;: 1, &quot;size&quot;: 1 } d.指定要查询出来记录的name和hobby就可以 GET company/_search { &quot;query&quot;: { &quot;match_all&quot;: {} }, &quot;_source&quot;: [&quot;name&quot;, &quot;hobby&quot;] } query filter搜索hobby包含trivel，而且age大于23元的记录 GET /company/_search { &quot;query&quot; : { &quot;bool&quot; : { &quot;must&quot; : { &quot;match&quot; : { &quot;hobby&quot; : &quot;trivel&quot; } }, &quot;filter&quot; : { &quot;range&quot; : { &quot;age&quot; : { &quot;gt&quot; : 23 } } } } } } full-text search（全文检索）GET /company/_search { &quot;query&quot; : { &quot;match&quot; : { &quot;hobby&quot; : &quot;trivel&quot; } } } phrase search跟全文检索相对应，相反，全文检索会将输入的搜索串拆解开来，去倒排索引里面去一一匹配，只要能匹配上任意一个拆解后的单词，就可以作为结果返回phrase search（短语搜索），要求输入的搜索串，必须在指定的字段文本中，完全包含一模一样的，才可以算匹配，才能作为结果返回 GET /company/_search { &quot;query&quot; : { &quot;match_phrase&quot; : { &quot;hobby&quot; : &quot;and music&quot; } } } 查询结果 { &quot;took&quot;: 35, &quot;timed_out&quot;: false, &quot;_shards&quot;: { &quot;total&quot;: 5, &quot;successful&quot;: 5, &quot;failed&quot;: 0 }, &quot;hits&quot;: { &quot;total&quot;: 1, &quot;max_score&quot;: 1.2320077, &quot;hits&quot;: [ { &quot;_index&quot;: &quot;company&quot;, &quot;_type&quot;: &quot;emp&quot;, &quot;_id&quot;: &quot;7&quot;, &quot;_score&quot;: 1.2320077, &quot;_source&quot;: { &quot;name&quot;: &quot;zhaowu&quot;, &quot;age&quot;: 31, &quot;sex&quot;: &quot;man&quot;, &quot;birthday&quot;: &quot;1997-01-02&quot;, &quot;hobby&quot;: &quot;i like trivel and music&quot; } } ] } } highlight search（高亮搜索结果）GET /company/_search { &quot;query&quot; : { &quot;match&quot; : { &quot;hobby&quot; : &quot;trivel&quot; } }, &quot;highlight&quot;: { &quot;fields&quot; : { &quot;hobby&quot; : {} } } } 查询结果 { &quot;took&quot;: 187, &quot;timed_out&quot;: false, &quot;_shards&quot;: { &quot;total&quot;: 5, &quot;successful&quot;: 5, &quot;failed&quot;: 0 }, &quot;hits&quot;: { &quot;total&quot;: 3, &quot;max_score&quot;: 0.86312973, &quot;hits&quot;: [ { &quot;_index&quot;: &quot;company&quot;, &quot;_type&quot;: &quot;emp&quot;, &quot;_id&quot;: &quot;4&quot;, &quot;_score&quot;: 0.86312973, &quot;_source&quot;: { &quot;name&quot;: &quot;wangba&quot;, &quot;age&quot;: 25, &quot;sex&quot;: &quot;woman&quot;, &quot;birthday&quot;: &quot;1996-01-02&quot;, &quot;hobby&quot;: &quot;i like trivel&quot; }, &quot;highlight&quot;: { &quot;hobby&quot;: [ &quot;i like &lt;em&gt;trivel&lt;/em&gt;&quot; ] } }, { &quot;_index&quot;: &quot;company&quot;, &quot;_type&quot;: &quot;emp&quot;, &quot;_id&quot;: &quot;7&quot;, &quot;_score&quot;: 0.6160039, &quot;_source&quot;: { &quot;name&quot;: &quot;zhaowu&quot;, &quot;age&quot;: 31, &quot;sex&quot;: &quot;man&quot;, &quot;birthday&quot;: &quot;1997-01-02&quot;, &quot;hobby&quot;: &quot;i like trivel and music&quot; }, &quot;highlight&quot;: { &quot;hobby&quot;: [ &quot;i like &lt;em&gt;trivel&lt;/em&gt; and music&quot; ] } }, { &quot;_index&quot;: &quot;company&quot;, &quot;_type&quot;: &quot;emp&quot;, &quot;_id&quot;: &quot;3&quot;, &quot;_score&quot;: 0.25316024, &quot;_source&quot;: { &quot;name&quot;: &quot;wangwu&quot;, &quot;age&quot;: 17, &quot;sex&quot;: &quot;man&quot;, &quot;birthday&quot;: &quot;1998-01-02&quot;, &quot;hobby&quot;: &quot;i like trivel&quot; }, &quot;highlight&quot;: { &quot;hobby&quot;: [ &quot;i like &lt;em&gt;trivel&lt;/em&gt;&quot; ] } } ] } }","tags":[{"name":"elasticsearch","slug":"elasticsearch","permalink":"http://dennis.pathto.top/tags/elasticsearch/"},{"name":"elk","slug":"elk","permalink":"http://dennis.pathto.top/tags/elk/"}]},{"title":"7.elasticsearch-简单集群管理","date":"2017-09-08T13:25:29.000Z","path":"2017/09/08/elasticsearch-7-cluster-management/","text":"简单的集群管理快速检查集群的健康状况GET /_cat/health?v { &quot;cluster_name&quot;: &quot;es-log&quot;, &quot;status&quot;: &quot;green&quot;, &quot;timed_out&quot;: false, &quot;number_of_nodes&quot;: 2, &quot;number_of_data_nodes&quot;: 2, &quot;active_primary_shards&quot;: 66, &quot;active_shards&quot;: 132, &quot;relocating_shards&quot;: 0, &quot;initializing_shards&quot;: 0, &quot;unassigned_shards&quot;: 0, &quot;delayed_unassigned_shards&quot;: 0, &quot;number_of_pending_tasks&quot;: 0, &quot;number_of_in_flight_fetch&quot;: 0, &quot;task_max_waiting_in_queue_millis&quot;: 0, &quot;active_shards_percent_as_number&quot;: 100 } 集群的健康状况集群的健康状况使用green、yellow、red 3种颜色表示 green：每个索引的primary shard和replica shard都是active状态的 yellow：每个索引的primary shard都是active状态的，但是部分replica shard不是active状态，处于不可用的状态 red：不是所有索引的primary shard都是active状态的，部分索引有数据丢失了 索引管理查看集群中有哪些索引GET /_cat/indices?v health status index uuid pri rep docs.count docs.deleted store.size pri.store.size green open .monitoring-es-2-2017.08.04 3ge5x25mTb2__tr6Sleqhg 1 1 85733 798 86.1mb 43mb green open .monitoring-es-2-2017.07.31 pYmUsT8rT7WK-yyBbLiWiA 1 1 32352 146 27.1mb 13.5mb green open .monitoring-es-2-2017.07.28 oCq3rTWbSU-b8C7vuI3vaA 1 1 16473 273 14.9mb 7.4mb green open .monitoring-kibana-2-2017.07.28 eJnF7v1bQJmRAcSg6ve6OA 1 1 195 0 281.1kb 140.5kb green open .monitoring-kibana-2-2017.08.06 7DJqZ7i6TXqN8gU8xbuR0A 1 1 721 0 387.1kb 193.5kb green open .kibana K3oCOVvAQS-7HItGeSN98w 1 1 99 67 456.6kb 228.3kb green open .security ss49jo3ZTOux7-PFK68tjw 1 1 5 0 32.5kb 16.2kb 创建索引PUT /test_index?pretty health status index uuid pri rep docs.count docs.deleted store.size pri.store.size green open test_index e8eqND3STmG-fzr1H_hnbQ 5 1 0 0 780b 260b green open .monitoring-es-2-2017.08.04 3ge5x25mTb2__tr6Sleqhg 1 1 85733 798 86.1mb 43mb 删除索引DELETE /test_index?pretty health status index uuid pri rep docs.count docs.deleted store.size pri.store.size green open .monitoring-es-2-2017.08.04 3ge5x25mTb2__tr6Sleqhg 1 1 85733 798 86.1mb 43mb","tags":[{"name":"elasticsearch","slug":"elasticsearch","permalink":"http://dennis.pathto.top/tags/elasticsearch/"}]},{"title":"6.elasticsearch-x-pack和klibana安装","date":"2017-09-07T13:25:29.000Z","path":"2017/09/07/elasticsearch-6-xpack-kibana/","text":"安装x-pack:在线安装方法bin/elasticsearch-plugin install x-pack 但是上面的安装方法可能网络的原因，会很卡，可以直接下载，上传zip包。 直接用下载包安装bin/kibana-plugin install file:///usr/local/es/x-pack-5.2.0.zip 修改es配置文件添加：xpack.security.enabled: false #关闭 x-pack默认会启用：xpack.security.enabled，xpack.monitoring.enabled，xpack.graph.enabled，xpack.watcher.enabled，xpack.reporting.enabled.在配置文件里面设置false即可，开始使用head插件的话需要停掉security服务，但是停掉security服务的话对我们的权限管理也受到很大的影响。 启动es[study@study0 elasticsearch-5.2.0]$ bin/elasticsearch 安装kibana修改kibana配置文件cd /usr/local/es/kibana-5.2.0-linux-x86_64/config vim kibana.yml server.host: &quot;study0&quot; elasticsearch.url: http://study0:9200 elasticsearch.username: &quot;elastic&quot; elasticsearch.password: &quot;changeme&quot; ##x-pack默认超级用户的登录密码(es和kibana两个的超级管理员账号密码都一样) 修改elastic的密码curl XPUT -u elastic:changeme &apos;study0:9200/_xpack/security/user/elastic/_password&apos; -d &apos;{ &quot;password&quot; : &quot;123456&quot; }&apos; 现在elastic的密码已经变成了123456 再改一下kibana的登录密码curl -XPUT -u elastic:123456 &apos;192.168.63.246:9200/_xpack/security/user/kibana/_password&apos; -d &apos;{ &quot;password&quot; : &quot;123456&quot; }&apos; 最后启动kibana[study@study0 kibana-5.2.0-linux-x86_64]$ bin/kibana image","tags":[{"name":"elasticsearch","slug":"elasticsearch","permalink":"http://dennis.pathto.top/tags/elasticsearch/"}]},{"title":"5.elasticsearch-IK分词器安装","date":"2017-09-05T13:25:29.000Z","path":"2017/09/05/elasticsearch-5-ik/","text":"安装ik分词插件git clone https://github.com/medcl/elasticsearch-analysis-ik git checkout tags/v5.2.0 #切换到对应的版本 mvn package 建立相应的ik分词插件目录mkdir /usr/local/es/elasticsearch-5.2.0/plugins/ik 复制压缩包到目录下cp target/releases/elasticsearch-analysis-ik-5.2.0.zip /usr/local/es/elasticsearch-5.2.0/plugins/ik unzip elasticsearch-analysis-ik-5.2.0.zip 解压重启即可","tags":[{"name":"elasticsearch","slug":"elasticsearch","permalink":"http://dennis.pathto.top/tags/elasticsearch/"}]},{"title":"3.elasticsearch运行系统参数优化","date":"2017-09-03T13:25:29.000Z","path":"2017/09/03/elasticsearch-3-installation-problem/","text":"在centos6.5系统中，不能直接运行elasticsearch,必须对系统参数进行优化如果没有优化，会出现如下面的问题 下面我们来进行系统优化吧~~ 启动 elasticsearch 如出现异常 can not run elasticsearch as root解决方法：创建ES 账户，修改文件夹 文件 所属用户 组 启动异常：ERROR: bootstrap checks failedsystem call filters failed to install; check the logs and fix your configuration or disable system call filters at your own risk 问题原因：因为Centos6不支持SecComp，而ES5.2.1默认bootstrap.system_call_filter为true进行检测，所以导致检测失败，失败后直接导致ES不能启动。详见 ：https://github.com/elastic/elasticsearch/issues/22899 解决方法：在elasticsearch.yml中配置bootstrap.system_call_filter为false，注意要在Memory下面: bootstrap.memory_lock: false bootstrap.system_call_filter: false 启动后，如果只有本地可以访问，尝试修改配置文件 elasticsearch.yml中network.host(注意配置文件格式不是以 # 开头的要空一格， ： 后要空一格)为 network.host: 0.0.0.0 默认端口是 9200 注意：关闭防火墙 或者开放9200端口 ERROR: bootstrap checks failedmax file descriptors [4096] for elasticsearch process likely too low, increase to at least [65536]max number of threads [1024] for user [lishang] likely too low, increase to at least [2048]解决方法：切换到root用户，编辑limits.conf 添加类似如下内容 vi /etc/security/limits.conf 添加如下内容: * soft nofile 65536 * hard nofile 131072 * soft nproc 2048 * hard nproc 4096 max number of threads [1024] for user [lish] likely too low, increase to at least [2048]解决：切换到root用户，进入limits.d目录下修改配置文件。 vi /etc/security/limits.d/90-nproc.conf 修改如下内容： * soft nproc 1024 #修改为 * soft nproc 2048 max virtual memory areas vm.max_map_count [65530] likely too low, increase to at least [262144]解决：切换到root用户修改配置sysctl.conf vi /etc/sysctl.conf 添加下面配置： vm.max_map_count=655360 并执行命令： sysctl -p 然后，重新启动elasticsearch，即可启动成功。 ping超时问题错误的详细信息09-09T16:08:16,479][WARN ][o.e.d.z.ZenDiscovery ] [log-1] master left (reason = failed to ping, tried [3] times, each with maximum [30s] timeout), current nodes: nodes: {log-0}{awifQlJfRcKNggd2II3LQQ}{FpEt0t3cRy6eBxiKtPYfRw}{study0}{192.168.137.150:9300}, master {log-1}{gTsJJfRoRF6hX1vP_TfUiA}{l84qWHqzTdm2wNBGxdpzIg}{study1}{192.168.137.151:9300}, local [2017-09-09T16:08:19,637][INFO ][o.e.c.s.ClusterService ] [log-1] detected_master {log-0}{awifQlJfRcKNggd2II3LQQ}{FpEt0t3cRy6eBxiKtPYfRw}{study0}{192.168.137.150:9300}, reason: zen-disco-receive(from master [master {log-0}{awifQlJfRcKNggd2II3LQQ}{FpEt0t3cRy6eBxiKtPYfRw}{study0}{192.168.137.150:9300} committed version [141]]) [2017-09-09T16:08:20,647][INFO ][o.e.d.z.ZenDiscovery ] [log-1] master_left [{log-0}{awifQlJfRcKNggd2II3LQQ}{FpEt0t3cRy6eBxiKtPYfRw}{study0}{192.168.137.150:9300}], reason [failed to ping, tried [3] times, each with maximum [30s] timeout] [2017-09-09T16:08:20,648][WARN ][o.e.d.z.ZenDiscovery ] [log-1] master left (reason = failed to ping, tried [3] times, each with maximum [30s] timeout), current nodes: nodes: {log-0}{awifQlJfRcKNggd2II3LQQ}{FpEt0t3cRy6eBxiKtPYfRw}{study0}{192.168.137.150:9300}, master {log-1}{gTsJJfRoRF6hX1vP_TfUiA}{l84qWHqzTdm2wNBGxdpzIg}{study1}{192.168.137.151:9300}, local 解决办法每一个节点上，elasticsearch.yml 都添加xpack.security.enabled: false 分词器问题错误日志[2017-09-10T20:01:22,848][WARN ][o.e.i.c.IndicesClusterStateService] [log-1] [[iktest][4]] marking and sending shard failed due to [failed to create index] java.lang.IllegalArgumentException: Custom Analyzer [ik] failed to find tokenizer under name [ik_max_word] at org.elasticsearch.index.analysis.CustomAnalyzerProvider.build(CustomAnalyzerProvider.java:56) ~[elasticsearch-5.2.0.jar:5.2.0] at org.elasticsearch.index.analysis.AnalysisRegistry.processAnalyzerFactory(AnalysisRegistry.java:560) ~[elasticsearch-5.2.0.jar:5.2.0] at org.elasticsearch.index.analysis.AnalysisRegistry.build(AnalysisRegistry.java:490) ~[elasticsearch-5.2.0.jar:5.2.0] at org.elasticsearch.index.analysis.AnalysisRegistry.build(AnalysisRegistry.java:158) ~[elasticsearch-5.2.0.jar:5.2.0] at org.elasticsearch.index.IndexService.&lt;init&gt;(IndexService.java:146) ~[elasticsearch-5.2.0.jar:5.2.0] at org.elasticsearch.index.IndexModule.newIndexService(IndexModule.java:363) ~[elasticsearch-5.2.0.jar:5.2.0] at org.elasticsearch.indices.IndicesService.createIndexService(IndicesService.java:425) ~[elasticsearch-5.2.0.jar:5.2.0] at org.elasticsearch.indices.IndicesService.createIndex(IndicesService.java:390) ~[elasticsearch-5.2.0.jar:5.2.0] at org.elasticsearch.indices.IndicesService.createIndex(IndicesService.java:146) ~[elasticsearch-5.2.0.jar:5.2.0] at org.elasticsearch.indices.cluster.IndicesClusterStateService.createIndices(IndicesClusterStateService.java:444) [elasticsearch-5.2.0.jar:5.2.0] at org.elasticsearch.indices.cluster.IndicesClusterStateService.applyClusterState(IndicesClusterStateService.java:202) [elasticsearch-5.2.0.jar:5.2.0] at org.elasticsearch.cluster.service.ClusterService.callClusterStateAppliers(ClusterService.java:856) [elasticsearch-5.2.0.jar:5.2.0] at org.elasticsearch.cluster.service.ClusterService.publishAndApplyChanges(ClusterService.java:810) [elasticsearch-5.2.0.jar:5.2.0] at org.elasticsearch.cluster.service.ClusterService.runTasks(ClusterService.java:628) [elasticsearch-5.2.0.jar:5.2.0] at org.elasticsearch.cluster.service.ClusterService$UpdateTask.run(ClusterService.java:1112) [elasticsearch-5.2.0.jar:5.2.0] at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:527) [elasticsearch-5.2.0.jar:5.2.0] at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:238) [elasticsearch-5.2.0.jar:5.2.0] at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:201) [elasticsearch-5.2.0.jar:5.2.0] at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [?:1.8.0_141] at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [?:1.8.0_141] at java.lang.Thread.run(Thread.java:748) [?:1.8.0_141] 解决办法scp -r ik study@study1:/usr/local/es/elasticsearch-5.2.0/plugins 每一个节点都安装一下分词器插件","tags":[{"name":"elasticsearch","slug":"elasticsearch","permalink":"http://dennis.pathto.top/tags/elasticsearch/"}]},{"title":"2.elasticsearch安装","date":"2017-09-02T13:25:29.000Z","path":"2017/09/02/elasticsearch-2-installation/","text":"软件版本 名称 版本 os CentOS release 6.5 (Final) ES elasticsearch-5.2.0 集群节点 主机 ip study0 192.168.137.150 study1 192.168.137.151 部署elasticsearch集群：安装jdk[root@study0 elasticsearch-5.2.0]# java -version java version &quot;1.8.0_141&quot; Java(TM) SE Runtime Environment (build 1.8.0_141-b15) Java HotSpot(TM) 64-Bit Server VM (build 25.141-b15, mixed mode) [root@study0 elasticsearch-5.2.0]# 解压安装[root@study0 es]# unzip elasticsearch-5.2.0.zip 具体配置cd config/ vim elasticsearch.yml cluster.name: es-log node.name: log-0 #node.attr.rack: r1 path.data: /usr/local/es/elasticsearch-5.2.0/data path.logs: /usr/local/es/elasticsearch-5.2.0/logs bootstrap.memory_lock: false bootstrap.system_call_filter: false network.host: study0 http.port: 9200 discovery.zen.ping.unicast.hosts: [&quot;study0&quot;, &quot;study1&quot;] discovery.zen.minimum_master_nodes: 1 #gateway.recover_after_nodes: 3 #action.destructive_requires_name: true #action.auto_create_index: .security,.monitoring*,.watches,.triggered_watches,.watcher-history* xpack.security.enabled: false xpack.notification.email.account: work: profile: standard email_defaults: from: dennis52o1314@163.com smtp: auth: true host: smtp.163.com port: 25 user: dennis52o1314@163.com password: 1111111111 http.cors.enabled: true http.cors.allow-origin: &quot;*&quot; 配置解释集群名称cluster.name: es-log 节点node.name: log-1 ##节点保持唯一性。 数据和日志存放目录path.data: /path/to/data path.logs: /path/to/logs ##默认当前目录下，可以修改 是否使用swapbootstrap.memory_lock:true bootstrap.memory_lock: false bootstrap.system_call_filter: false 广播配置discovery.zen.ping.unicast.hosts: [&quot;study0&quot;, &quot;study1&quot;] discovery.zen.minimum_master_nodes: 1 其他系统设置vim /etc/sysctl.conf vm.max_map_count= 262144 sysctl –p 系统打开文件数配置vim /etc/security/limits.conf * hard nofile 65536 * soft nofile 65536 修改用户线程数vim /etc/security/limits.d/90-nproc.conf * soft nproc 2048 切换普通用户启动su – study ./elasticsearch 要是提示，报一些没有目录的错误，直接创建即可，但是想写入日志和数据必须是普通用户有写入权限 测试安装效果curl -XGET &apos;study0:9200&apos; { &quot;name&quot; : &quot;log-1&quot;, &quot;cluster_name&quot; : &quot;es-log&quot;, &quot;cluster_uuid&quot; : &quot;_na_&quot;, &quot;version&quot; : { &quot;number&quot; : &quot;5.0.0&quot;, &quot;build_hash&quot; : &quot;253032b&quot;, &quot;build_date&quot; : &quot;2016-10-26T04:37:51.531Z&quot;, &quot;build_snapshot&quot; : false, &quot;lucene_version&quot; : &quot;6.2.0&quot; }, &quot;tagline&quot; : &quot;You Know, for Search&quot; } 集群启动设置只加入一个节点，那么es就当做自己是一个集群。一个节点(node)就是一个Elasticsearch实例，而一个集群(cluster)由一个或多个节点组成，它们具有相同的cluster.name，它们协同工作，分享数据和负载。当加入新的节点或者删除一个节点时，集群就会感知到并平衡数据。 study0创建一条索引，查看单集群的状态[root@study0 elasticsearch-5.2.0]# curl -XPOST &apos;study0:9200/test/name/1&apos; -d &apos; { &quot;name&quot;: &quot;dennis&quot; }&apos; ####创建一条test的索引，type为name,id=1 查看集群当前的状态：[root@study0 elasticsearch-5.2.0]#curl -XGET &apos;study0:9200/_cluster/health?pretty&apos; { &quot;cluster_name&quot; : &quot;es-log&quot;, &quot;status&quot; : &quot;yellow&quot;, } 集群的几个状态： 颜色 说明 green 所有主要分片和复制分片都可用 yellow 所有主要分片可用，但不是所有复制分片都可用 red 不是所有的主要分片都可用 可以看到显示为：yellow的，因为只有主分片，而没有复制分片的。 现在启动配置好study1这个节点： # ---------------------------------- Cluster ----------------------------------- # # Use a descriptive name for your cluster: # cluster.name: es-log # # ------------------------------------ Node ------------------------------------ # # Use a descriptive name for the node: # node.name: log-1 # # Add custom attributes to the node: # #node.attr.rack: r1 # # ----------------------------------- Paths ------------------------------------ # # Path to directory where to store the data (separate multiple locations by comma): # path.data: /usr/local/es/elasticsearch-5.2.0/data # # Path to log files: # path.logs: /usr/local/es/elasticsearch-5.2.0/logs # # ----------------------------------- Memory ----------------------------------- # # Lock the memory on startup: # bootstrap.memory_lock: false bootstrap.system_call_filter: false # # Make sure that the heap size is set to about half the memory available # on the system and that the owner of the process is allowed to use this # limit. # # Elasticsearch performs poorly when the system is swapping the memory. # # ---------------------------------- Network ----------------------------------- # # Set the bind address to a specific IP (IPv4 or IPv6): # network.host: study1 # # Set a custom port for HTTP: # http.port: 9200 # # For more information, consult the network module documentation. # # --------------------------------- Discovery ---------------------------------- # # Pass an initial list of hosts to perform discovery when new node is started: # The default list of hosts is [&quot;127.0.0.1&quot;, &quot;[::1]&quot;] # discovery.zen.ping.unicast.hosts: [&quot;study0&quot;, &quot;study1&quot;] # # Prevent the &quot;split brain&quot; by configuring the majority of nodes (total number of master-eligible nodes / 2 + 1): # discovery.zen.minimum_master_nodes: 1 # # For more information, consult the zen discovery module documentation. # # ---------------------------------- Gateway ----------------------------------- # # Block initial recovery after a full cluster restart until N nodes are started: # #gateway.recover_after_nodes: 3 # # For more information, consult the gateway module documentation. # # ---------------------------------- Various ----------------------------------- # # Require explicit names when deleting indices: # #action.destructive_requires_name: true 集群的相关状态： [root@study0 elasticsearch-5.2.0]# curl -XGET &apos;study0:9200/_cluster/health?pretty&apos; { &quot;cluster_name&quot; : &quot;es-log&quot;, &quot;status&quot; : &quot;green&quot;, } 可以看到集群已经变成绿色，说明我们复制分片是已经可以使用了的，我们在study1上面查看一下我们刚刚创建的数据看： [root@study1 elasticsearch-5.2.0]# curl -XGET &apos;study1:9200/test/name/1?pretty&apos; { &quot;_index&quot; : &quot;test&quot;, &quot;_type&quot; : &quot;name&quot;, &quot;_id&quot; : &quot;1&quot;, &quot;_version&quot; : 1, &quot;found&quot; : true, &quot;_source&quot; : { &quot;name&quot; : &quot;dennis&quot; } } 可以看到数据已经被复制到study1上面了。 成功之后，集群的配置要稍作修改： discovery.zen.minimum_master_nodes: 2 ###开始设置成1是为了一台测试，推荐大于1台。","tags":[{"name":"elasticsearch","slug":"elasticsearch","permalink":"http://dennis.pathto.top/tags/elasticsearch/"}]},{"title":"1.elasticsearch介绍","date":"2017-09-01T13:25:29.000Z","path":"2017/09/01/elasticsearch-1-instroduce/","text":"lucene全文检索与数据库查询的区别性能上数据库:比如我要查找某个商品，根据商品名，比如: select * from product where doctname like %keywords% 这样查询的话对于数据量少是可以的，可是一旦你的数据量巨大几万几十万的时候，你的性能将会极大的减弱。 lucene(全文检索):建立一个索引库，一次建立多次使用。在索引库里面会把所有的商品名根据分词器建立索引，就好比新华字典，索引对应document，比如输入衬衫，那么就会根据索引迅速的翻到衬衫对应的商品名，时间迅速，性能很好。 相关度排序数据库：数据库要实现该功能也是可以的，可是需要改变表的结构，添加一个字段，然后该字段用于排名，最后查询的时候order by 一下. lucene:查询出来的document都有一个算法（得分），根据算法可以计算得分，得分越高的排名越靠前，比如百度搜索一个东西，一般排名靠前的得分越高，得分通过算法，可以人工控制，比如百度推广，企业给的钱多得分自然高，因此排名靠前 准确性数据库： select * from product where doctname like %ant% 搜索出来的可以是plant,aplant,planting等等，准确性不高 lucene：它是通过索引查询的，就好像你查字典一样，准确性比数据库的模糊查询高许多 lucene和elasticsearch的关系elasticsearch是基于lucene实现的分布式全文检索系统，解决了lucene存储可伸缩问题，高可用问题，读写负载均衡问.提供了更多高级功能如：复杂的搜索功能，聚合分析功能，基于地理位置搜索，rest api,多种语言客户端开发的api等 Elasticsearch的特点（1）可以作为一个大型分布式集群（数百台服务器）技术，处理PB级数据，服务大公司；也可以运行在单机上，服务小公司 （2）Elasticsearch是将全文检索、数据分析以及分布式技术，合并在了一起，才形成数据分析软件，分布式数据库 （3）elasticsearch，基于lucene，隐藏复杂性，提供简单易用的restful api接口、java api接口,对用户而言，简单易用，数据量不大，操作不是太复杂 （4）Elasticsearch作为传统数据库的一个补充，提供了数据库所不不能提供的很多功能,如全文检索，同义词处理，相关度排名，复杂数据分析，支持PB级数据,海量数据的近实时处理； 相关概念（1）Near Realtime（NRT）：近实时，从写入数据到数据可以被搜索到有一个小延迟（大概1秒）；基于es执行搜索和分析可以达到秒级 （2）Cluster：集群，包含多个节点，每个节点属于哪个集群是通过一个配置（集群名称，默认是elasticsearch）来决定的,也可以只有一个节点 （3）Node：节点，集群中的一个节点，节点也有一个名称,默认是随机分配的，在执行运维管理操作的时候，节点名称很重要，默认节点会去加入一个名称为“elasticsearch”的集群，如果直接启动一堆节点，那么它们会自动组成一个elasticsearch集群，一个节点也可以组成一个elasticsearch集群 （4）Document和field：文档，es中的最小数据单元，一个document相当于数据库的一行数据，用JSON数据结构表示;每个index下的type中，都可以去存储多个document。一个document里面有多个field，每个field就是一个数据字段。 （5）Index：相当于数据库中的数据库实例。 （6）Type：类型，相当于数据库中的表。 （7）shard：单台机器无法存储大量数据，es可以将一个索引中的数据切分为多个分片shard，分布在多台服务器上存储。有了shard就可以横向扩展，存储更多数据，让搜索和分析等操作分布到多台服务器上去执行，提升读写性能。每个shard都是一个lucene index。 （8）replica：任何一个服务器随时可能故障或宕机，此时shard可能就会丢失，因此可以为每个shard创建多个replica副本。replica可以在shard故障时提供备用服务，保证数据不丢失，多个replica还可以提升搜索操作的吞吐量和性能。默认每个索引10个shard，5个primary shard，5个replica shard，最小的高可用配置，是2台服务器。 3、elasticsearch核心概念 vs. 数据库核心概念 Elasticsearch 数据库 Document 行 Type 表 Index 库","tags":[{"name":"elasticsearch","slug":"elasticsearch","permalink":"http://dennis.pathto.top/tags/elasticsearch/"}]},{"title":"14.spring-cloud-zuul配置","date":"2017-08-24T13:13:40.000Z","path":"2017/08/24/spring-cloud-zuul-configuration-14/","text":"微服务重命名zuul可以给微服务重命名,重命名非常简单，只需要在application配置文件中添加下面配置项即可 zuul: ignored-services: &apos;*&apos; routes: spring-cloud-provider: /provider/** 这个配置把spring-cloud-provider的一组微服务名称命名为provider了 浏览器打开http://192.168.88.101:9004/provider/user/get?id=1 即可访问spring-cloud-provider的微服务 image 浏览器打开原来微服务 http://192.168.88.101:9004/spring-cloud-provider/user/get?id=1 ，发现已经不能被访问了 image 如果把ignored-services: &#39;*&#39;删除了，新旧的微服务名称都可以通过网关代理访问，并且，任何被注册到eureka上面的微服务，都可以被zuul代理网关访问 其他重命名方式abcd和efgh对重命名的微服务进行分组管理，名称可以是任意的有效字符 zuul: #ignored-services: &apos;*&apos; routes: spring-cloud-provider: /provider/** abcd: path: /consumer/** serviceId: spring-cloud-consumer efgh: path: /provider-test/** url: http://localhost:8082 当eureka被禁用的情况下，可以使用下面的方式重命名 zuul: routes: abcd: path: /direct/** serviceId: spring-cloud-provider-test-direct ribbon: eureka: enabled: false spring-cloud-provider-test-direct: ribbon: listOfServers: http://localhost:8085,http://localhost:8086 该配置把http://localhost:8085,http://localhost:8086定义为一组微服务spring-cloud-provider-test-direct 然后zuul对这组微服务提供重命名为direct 文件上传文件上传超时，需要合理的配置下面的属性 hystrix.command.default.execution.isolation.thread.timeoutInMilliseconds: 10000 ribbon: ConnectTimeout: 2000 ReadTimeout: 30000","tags":[{"name":"java","slug":"java","permalink":"http://dennis.pathto.top/tags/java/"},{"name":"spring","slug":"spring","permalink":"http://dennis.pathto.top/tags/spring/"},{"name":"spring-boot","slug":"spring-boot","permalink":"http://dennis.pathto.top/tags/spring-boot/"},{"name":"spring-cloud","slug":"spring-cloud","permalink":"http://dennis.pathto.top/tags/spring-cloud/"}]},{"title":"13.spring-cloud-zuul入门","date":"2017-08-24T13:13:37.000Z","path":"2017/08/24/spring-cloud-zuul-13/","text":"zuul介绍Zuul是Netflix的基于JVM的路由器和服务器端负载均衡器,提供了API网关的功能。 API网关是一个服务器，也可以是进入系统的唯一节点。这与面向对象设计的门面模式很像。API网关封装内部系统的架构。并且提供API给各个客户端，它还可能具备授权，监控，负载均衡，缓存，请求分片，管理，静态响应处理等功能。 API网关具有有点，也具有缺点 优点API网关的最大有点就是分装了应用程序内部结构。客户端需要和网关交互，不必和特定的服务交互。API网关为每一类客户端提供了特定的API。减少了客户端和应用程序的交互次数，简化了客户端的代码。 缺点它增加了部署，维护的工作量。API网关变成了瓶颈，API网关的存在，需要走网络，也会有一点的性能损耗。 入门实例pom.xml&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt; &lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.example&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-zuul&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;name&gt;spring-cloud-zuul&lt;/name&gt; &lt;description&gt;Demo project for Spring Boot&lt;/description&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;1.4.7.RELEASE&lt;/version&gt; &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt; &lt;/parent&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;spring-cloud.version&gt;Camden.SR7&lt;/spring-cloud.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-eureka&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-zuul&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;${spring-cloud.version}&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/dependencyManagement&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; &lt;/project&gt; application.ymlserver: port: 9004 spring: application: name: spring-cloud-zuul eureka: client: serviceUrl: defaultZone: http://localhost:8761/eureka instance: prefer-ip-address: true SpringCloudZuulApplication.javapackage com.example.demo; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; import org.springframework.cloud.netflix.zuul.EnableZuulProxy; @EnableZuulProxy @SpringBootApplication public class SpringCloudZuulApplication { public static void main(String[] args) { SpringApplication.run(SpringCloudZuulApplication.class, args); } } 验证浏览器打开http://192.168.88.101:9004/spring-cloud-provider/user/get?id=1 spring-cloud-provider是微服务的application.name 反复刷新页面，浏览器会交替显示下面的内容: {&quot;id&quot;:&quot;1&quot;,&quot;userName&quot;:&quot;xiaoming1&quot;,&quot;age&quot;:30,&quot;birthday&quot;:null} {&quot;id&quot;:&quot;1&quot;,&quot;userName&quot;:&quot;xiaoming&quot;,&quot;age&quot;:30,&quot;birthday&quot;:null}","tags":[{"name":"java","slug":"java","permalink":"http://dennis.pathto.top/tags/java/"},{"name":"spring","slug":"spring","permalink":"http://dennis.pathto.top/tags/spring/"},{"name":"spring-boot","slug":"spring-boot","permalink":"http://dennis.pathto.top/tags/spring-boot/"},{"name":"spring-cloud","slug":"spring-cloud","permalink":"http://dennis.pathto.top/tags/spring-cloud/"}]},{"title":"12.spring-cloud-turbine监控微服务","date":"2017-08-24T13:13:35.000Z","path":"2017/08/24/spring-cloud-hystrix-turbine-monitor-12/","text":"turbine是聚合服务器发送事件流数据的一个工具，hystrix的监控中，只能监控单个节点，实际生产中都为集群，因此可以通过turbine来监控集群下hystrix的metrics情况，通过eureka来发现hystrix服务。 下面把turbine整合到spring-cloud项目中 pom.xml &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-turbine&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-eureka&lt;/artifactId&gt; &lt;/dependency&gt; application.yaml server: port: 9003 spring: application: name: hystrix-turbine eureka: client: serviceUrl: defaultZone: http://localhost:8761/eureka instance: prefer-ip-address: true turbine: aggregator: clusterConfig: SPRING-CLOUD-CONSUMER appConfig: spring-cloud-consumer SpringCloudHystrixTurbineApplication.java package com.example.demo; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; import org.springframework.cloud.netflix.turbine.EnableTurbine; @SpringBootApplication @EnableTurbine public class SpringCloudHystrixTurbineApplication { public static void main(String[] args) { SpringApplication.run(SpringCloudHystrixTurbineApplication.class, args); } } 验证 浏览器打开http://localhost:9000/user/list和http://192.168.88.101:9003/turbine.stream?cluster=SPRING-CLOUD-CONSUMER,可以监控到SPRING-CLOUD-CONSUMER的微服务 image image 在hystrix dashboard中图形化监控 image image","tags":[{"name":"java","slug":"java","permalink":"http://dennis.pathto.top/tags/java/"},{"name":"spring","slug":"spring","permalink":"http://dennis.pathto.top/tags/spring/"},{"name":"spring-boot","slug":"spring-boot","permalink":"http://dennis.pathto.top/tags/spring-boot/"},{"name":"spring-cloud","slug":"spring-cloud","permalink":"http://dennis.pathto.top/tags/spring-cloud/"}]},{"title":"11.spring-cloud-hystrix监控微服务","date":"2017-08-24T13:13:32.000Z","path":"2017/08/24/spring-cloud-hystrix-monitor-11/","text":"hystrix监控功能 1.添加maven依赖 &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-hystrix&lt;/artifactId&gt; &lt;/dependency&gt; 2.添加注解 @EnableCircuitBreaker 3.添加@HystrixCommand @ResponseBody @GetMapping(&quot;/list&quot;) @HystrixCommand(fallbackMethod=&quot;listFallBack&quot;) public User[] list(){ System.out.println(&quot;list--&gt;&quot;+Thread.currentThread().getId()); User[] list = restTemplate.getForObject(&quot;http://spring-cloud-provider/user/list&quot;, User[].class); return list; } public User[] listFallBack(){ System.out.println(&quot;listFallBack--&gt;&quot;+Thread.currentThread().getId()); return new User[]{}; } 4.验证 先从浏览器打开http://localhost:9000/user/list 注意：一定先浏览一下http://localhost:9000/user/list，否则没法打开http://localhost:9000/hystrix.stream 在打开监控页面 http://localhost:9000/hystrix.stream image 浏览器打开Hystrix dashboard http://localhost:9001/hystrix/ image image","tags":[{"name":"java","slug":"java","permalink":"http://dennis.pathto.top/tags/java/"},{"name":"spring","slug":"spring","permalink":"http://dennis.pathto.top/tags/spring/"},{"name":"spring-boot","slug":"spring-boot","permalink":"http://dennis.pathto.top/tags/spring-boot/"},{"name":"spring-cloud","slug":"spring-cloud","permalink":"http://dennis.pathto.top/tags/spring-cloud/"}]},{"title":"10.spring-cloud-指定某些feignClient无需Hystrix的支持","date":"2017-08-24T13:13:29.000Z","path":"2017/08/24/spring-cloud-feign-without-hystrix-10/","text":"定义一个不需要Hystrix支持的FeignClient UserFeignClientWithoutHystrix.java package com.example.demo.feign; @FeignClient(name=&quot;spring-cloud-provider&quot;,fallback=UserFeignClientFallback.class,configuration=FeignClientWithoutHystrixConfig.class) public interface UserFeignClientWithoutHystrix { @RequestMapping(value=&quot;/user/get?id={id}&quot;,method=RequestMethod.GET) public User get(@PathVariable(&quot;id&quot;) String id); @RequestMapping(value=&quot;/user/list&quot;,method=RequestMethod.GET) public List&lt;User&gt; list(); } FeignClientWithoutHystrixConfig.java package com.example.config; @Configuration public class FeignClientWithoutHystrixConfig { /** * 禁止某个api支持hystrix fallback * @return */ @Bean @Scope(&quot;prototype&quot;) public Feign.Builder feignBuilder() { return Feign.builder(); } } 验证 当服务提供端启动的时候，UserFeignClientWithoutHystrix可以被正常调用。当服务提供端关闭之后UserFeignClientWithoutHystrix调用失败，但是不会调用Hystrix的回调(UserFeignClientFallback)","tags":[{"name":"java","slug":"java","permalink":"http://dennis.pathto.top/tags/java/"},{"name":"spring","slug":"spring","permalink":"http://dennis.pathto.top/tags/spring/"},{"name":"spring-boot","slug":"spring-boot","permalink":"http://dennis.pathto.top/tags/spring-boot/"},{"name":"spring-cloud","slug":"spring-cloud","permalink":"http://dennis.pathto.top/tags/spring-cloud/"}]},{"title":"9.spring-cloud-hystrix和feign整合","date":"2017-08-24T13:13:27.000Z","path":"2017/08/24/spring-cloud-feign-hystrix-feign-9/","text":"上一章中完成了Ribbon和hytrix的整合，本章整合Hystrix和Feign 要实现Hystrix和Feign的整合，需要在消费端完成以下几个步骤: 1.添加Hystrix和Feign的maven依赖 &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-feign&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-hystrix&lt;/artifactId&gt; &lt;/dependency&gt; 2.在启动类中添加注解 @EnableFeignClients @EnableCircuitBreaker 3.添加FeignClient接口 package com.example.demo.feign; @FeignClient(name=&quot;spring-cloud-provider&quot;,fallback=UserFeignClientFallback.class) public interface UserFeignClient { @RequestMapping(value=&quot;/user/get?id={id}&quot;,method=RequestMethod.GET) public User get(@PathVariable(&quot;id&quot;) String id); @RequestMapping(value=&quot;/user/list&quot;,method=RequestMethod.GET) public List&lt;User&gt; list(); } 4.添加Fallback的实现了，Fallback实现了FeignClient接口 package com.example.demo.fallback; @Component public class UserFeignClientFallback implements UserFeignClient{ @Override public User get(String id) { // TODO Auto-generated method stub return new User(); } @Override public List&lt;User&gt; list() { // TODO Auto-generated method stub return new ArrayList&lt;User&gt;(); } } 5.使用FeignClient实现对微服务的调用 //只需要在使用的SpringBean中注入Feignclient即可 @Autowired private UserFeignClient userFeignClient; 使用fallbackFactory实现Hystrix和Feign的整合，并且捕获异常 UserFeignClient.java 把@FeignClient的fallback属性给删除了,并且添加fallbackFactory=UserFeignClientFactory.class package com.example.demo.feign; @FeignClient(name=&quot;spring-cloud-provider&quot;/*,fallback=UserFeignClientFallback.class*/,fallbackFactory=UserFeignClientFactory.class) public interface UserFeignClient { @RequestMapping(value=&quot;/user/get?id={id}&quot;,method=RequestMethod.GET) public User get(@PathVariable(&quot;id&quot;) String id); @RequestMapping(value=&quot;/user/list&quot;,method=RequestMethod.GET) public List&lt;User&gt; list(); } UserFeignClientFactory.java package com.example.demo.fallback; @Component public class UserFeignClientFactory implements FallbackFactory&lt;UserFeignClient&gt;{ @Override public UserFeignClient create(Throwable arg0) { //返回一个匿名内部类,这个匿名内部类实现了FeignClient接口 return new UserFeignClient(){ @Override public User get(String id) { // TODO Auto-generated method stub return new User(&quot;-1&quot;, &quot;error&quot;, -1, new Date()); } @Override public List&lt;User&gt; list() { // TODO Auto-generated method stub return new ArrayList&lt;User&gt;(); }}; } } 验证 关闭微服务，浏览器打开http://192.168.88.101:9000/user/feign_get?id=1，在消费端被浏览器调用的时候 浏览器显示如下内容: {&quot;id&quot;:&quot;-1&quot;,&quot;userName&quot;:&quot;error&quot;,&quot;age&quot;:-1,&quot;birthday&quot;:1503539977737} 系统抛出下面的异常 java.lang.RuntimeException: com.netflix.client.ClientException: Load balancer does not have available server for client: spring-cloud-provider at org.springframework.cloud.netflix.feign.ribbon.LoadBalancerFeignClient.execute(LoadBalancerFeignClient.java:71) at feign.SynchronousMethodHandler.executeAndDecode(SynchronousMethodHandler.java:97) at feign.SynchronousMethodHandler.invoke(SynchronousMethodHandler.java:76) at feign.hystrix.HystrixInvocationHandler$1.run(HystrixInvocationHandler.java:108)","tags":[{"name":"java","slug":"java","permalink":"http://dennis.pathto.top/tags/java/"},{"name":"spring","slug":"spring","permalink":"http://dennis.pathto.top/tags/spring/"},{"name":"spring-boot","slug":"spring-boot","permalink":"http://dennis.pathto.top/tags/spring-boot/"},{"name":"spring-cloud","slug":"spring-cloud","permalink":"http://dennis.pathto.top/tags/spring-cloud/"}]},{"title":"8.spring-cloud-hystrix入门","date":"2017-08-24T13:13:24.000Z","path":"2017/08/24/spring-cloud-feign-hystrix-8/","text":"介绍使用微服务架构实现大型项目的过程中，经常会对一个大而全的系统拆分成多个较小的服务单元，各个服务单元之间通过注册和订阅的方式，了解对方的状态，相互依赖。每一个服务单元运行在一个单独的进程中。各个服务单元在相互调用的过程中，会出现各种各样的不可用情况，如网络不可用，服务单元的进程挂掉了，服务单元内部的实现性能有问题等等。如果高并发高并发的情况下，挂起的服务单元一直占用系统资源不及时释放，就会导致系统资源耗尽，从而导致整个系统出现问题。hystrix的出现，就是为了解决这种问题的，它提供了故障监控。如果出现故障，Hystrix可以帮助系统快速调用一个异常处理模块，快速失败，快速释放系统资源，避免了故障的蔓延，从而避免的系统雪崩的危害。 如何让自己的功能得到Hystrix的支持? 需要完成下面的步骤: 1).添加Hytrix的maven依赖 &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-hystrix&lt;/artifactId&gt; &lt;/dependency&gt; 2).在启动类中添加注解 启动类中需要添加@EnableCircuitBreaker 3).在需要高可用的模块中添加相应的注解和回调函数 @ResponseBody @GetMapping(&quot;/list&quot;) @HystrixCommand(fallbackMethod=&quot;listFallBack&quot;) public User[] list(){ System.out.println(&quot;list--&gt;&quot;+Thread.currentThread().getId()); User[] list = restTemplate.getForObject(&quot;http://spring-cloud-provider/user/list&quot;, User[].class); return list; } public User[] listFallBack(){ System.out.println(&quot;listFallBack--&gt;&quot;+Thread.currentThread().getId()); return new User[]{}; } 当list函数出现性能问题，执行速度太慢，响应太慢的时候就会直接调用listFallBack函数","tags":[{"name":"java","slug":"java","permalink":"http://dennis.pathto.top/tags/java/"},{"name":"spring","slug":"spring","permalink":"http://dennis.pathto.top/tags/spring/"},{"name":"spring-boot","slug":"spring-boot","permalink":"http://dennis.pathto.top/tags/spring-boot/"},{"name":"spring-cloud","slug":"spring-cloud","permalink":"http://dennis.pathto.top/tags/spring-cloud/"}]},{"title":"7.spring-cloud-ribbon和feign返回集合类型","date":"2017-08-24T13:13:21.000Z","path":"2017/08/24/spring-cloud-ribbon-feign-collection-7/","text":"ribbon中如果要调用服务端的接口，需要使用到restTemplate，使用restTemplate提供的api返回多个元素是一个数组了下的。 feign中提供的接口如果要返回集合类型的数据，数据类型和服务端的返回的数据类型一致即可 消费端 UserConstroller.java Ribbon调用微服务的方法 @ResponseBody @GetMapping(&quot;/list&quot;) public User[] list(){ //http://spring-cloud-provider/user/list返回List&lt;User&gt;的数据类型 User[] list = restTemplate.getForObject(&quot;http://spring-cloud-provider/user/list&quot;, User[].class); return list; } Feign调用微服务的方法 @ResponseBody @GetMapping(&quot;/feign_list&quot;) public List&lt;User&gt; feign_list(){ List&lt;User&gt; list = userFeignClient.list(); return list; } UserFeignClient.java @RequestMapping(value=&quot;/user/list&quot;,method=RequestMethod.GET) public List&lt;User&gt; list(); 服务提供端 UserController.java package com.example.demo.controller; import java.util.ArrayList; import java.util.HashMap; import java.util.List; import java.util.Map; import java.util.Map.Entry; import org.springframework.web.bind.annotation.GetMapping; import org.springframework.web.bind.annotation.RequestMapping; import org.springframework.web.bind.annotation.ResponseBody; import org.springframework.web.bind.annotation.RestController; import com.example.demo.model.User; @RestController @RequestMapping(value=&quot;/user&quot;) public class UserController { private Map&lt;String, User&gt; umap = new HashMap(); public UserController(){ umap.put(&quot;1&quot;, new User(&quot;1&quot;, &quot;xiaoming1&quot;, 30)); umap.put(&quot;2&quot;, new User(&quot;2&quot;, &quot;xiaohong1&quot;, 20)); umap.put(&quot;3&quot;, new User(&quot;3&quot;, &quot;zhangsan1&quot;, 80)); umap.put(&quot;4&quot;, new User(&quot;4&quot;, &quot;lisi1&quot;, 10)); umap.put(&quot;5&quot;, new User(&quot;5&quot;, &quot;wangwu1&quot;, 22)); } @RequestMapping(value=&quot;/get&quot;) @ResponseBody public List&lt;User&gt; list(){ List&lt;User&gt; list = new ArrayList&lt;User&gt;(); for(Entry&lt;String, User&gt;e:umap.entrySet()){ list.add(e.getValue()); } return list; } @RequestMapping(value=&quot;/list&quot;) @ResponseBody public User get(String id){ return umap.get(id); } }","tags":[{"name":"java","slug":"java","permalink":"http://dennis.pathto.top/tags/java/"},{"name":"spring","slug":"spring","permalink":"http://dennis.pathto.top/tags/spring/"},{"name":"spring-boot","slug":"spring-boot","permalink":"http://dennis.pathto.top/tags/spring-boot/"},{"name":"spring-cloud","slug":"spring-cloud","permalink":"http://dennis.pathto.top/tags/spring-cloud/"}]},{"title":"6.spring-cloud-feign入门","date":"2017-08-24T13:13:18.000Z","path":"2017/08/24/spring-cloud-feign-6/","text":"feign介绍feign整合了ribbon和hystrix。除了整合两者的强大功能外，还提供了一种声明式的web服务客户端定义方式。feign简化了ribbon中template的开发，提供更高层次的接口.feign自身也提供了一下可插拔的组件，如编码器和解码器。等等 快速入门spring-cloud-consumer-01步骤: 添加feign的依赖 在pom.xml中添加下面的maven配置 &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-feign&lt;/artifactId&gt; &lt;/dependency&gt; 启动类中添加@EnableFeignClients注解 开发FeignClient程序 详细代码实现SpringCloudConsumer01Application.javapackage com.example.demo; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; import org.springframework.cloud.netflix.eureka.EnableEurekaClient; import org.springframework.cloud.netflix.feign.EnableFeignClients; import org.springframework.cloud.netflix.ribbon.RibbonClient; import com.example.config.LoadBarentConfig; @EnableEurekaClient @SpringBootApplication @EnableFeignClients public class SpringCloudConsumer01Application { public static void main(String[] args) { SpringApplication.run(SpringCloudConsumer01Application.class, args); } } UserFeignClient.javapackage com.example.demo.feign; import org.springframework.cloud.netflix.feign.FeignClient; import org.springframework.web.bind.annotation.GetMapping; import org.springframework.web.bind.annotation.PathVariable; import org.springframework.web.bind.annotation.RequestBody; import org.springframework.web.bind.annotation.RequestMapping; import org.springframework.web.bind.annotation.RequestMethod; import com.example.demo.model.User; import feign.Param; @FeignClient(&quot;spring-cloud-provider&quot;) public interface UserFeignClient { @RequestMapping(value=&quot;/user/get?id={id}&quot;,method=RequestMethod.GET) public User get(@PathVariable(&quot;id&quot;) String id); } UserConstroller.javapackage com.example.demo.controller; @RestController @RequestMapping(value=&quot;/user&quot;) public class UserConstroller { @Autowired private UserFeignClient userFeignClient; @ResponseBody @GetMapping(&quot;/feign_get&quot;) public User feign(String id){ User u = userFeignClient.get(id); return u; } } 服务提供端spring-cloud-provider-01和spring-cloud-provider-02 这两个微服务注册到eureka中 spring-cloud-provider-01 package com.example.demo.controller; import java.util.HashMap; import java.util.Map; import org.springframework.web.bind.annotation.GetMapping; import org.springframework.web.bind.annotation.RequestMapping; import org.springframework.web.bind.annotation.ResponseBody; import org.springframework.web.bind.annotation.RestController; import com.example.demo.model.User; @RestController @RequestMapping(value=&quot;/user&quot;) public class UserController { private Map&lt;String, User&gt; umap = new HashMap(); public UserController(){ umap.put(&quot;1&quot;, new User(&quot;1&quot;, &quot;xiaoming1&quot;, 30)); umap.put(&quot;2&quot;, new User(&quot;2&quot;, &quot;xiaohong1&quot;, 20)); umap.put(&quot;3&quot;, new User(&quot;3&quot;, &quot;zhangsan1&quot;, 80)); umap.put(&quot;4&quot;, new User(&quot;4&quot;, &quot;lisi1&quot;, 10)); umap.put(&quot;5&quot;, new User(&quot;5&quot;, &quot;wangwu1&quot;, 22)); } @RequestMapping(value=&quot;/get&quot;) @ResponseBody public User get(String id){ return umap.get(id); } } spring-cloud-provider-02 package com.example.demo.controller; import java.util.HashMap; import java.util.Map; import org.springframework.web.bind.annotation.GetMapping; import org.springframework.web.bind.annotation.RequestMapping; import org.springframework.web.bind.annotation.ResponseBody; import org.springframework.web.bind.annotation.RestController; import com.example.demo.model.User; @RestController @RequestMapping(value=&quot;/user&quot;) public class UserController { private Map&lt;String, User&gt; umap = new HashMap(); public UserController(){ umap.put(&quot;1&quot;, new User(&quot;1&quot;, &quot;xiaoming&quot;, 30)); umap.put(&quot;2&quot;, new User(&quot;2&quot;, &quot;xiaohong&quot;, 20)); umap.put(&quot;3&quot;, new User(&quot;3&quot;, &quot;zhangsan&quot;, 80)); umap.put(&quot;4&quot;, new User(&quot;4&quot;, &quot;lisi&quot;, 10)); umap.put(&quot;5&quot;, new User(&quot;5&quot;, &quot;wangwu&quot;, 22)); } @RequestMapping(value=&quot;/get&quot;) @ResponseBody public User get(String id){ return umap.get(id); } } 验证 在浏览器中打开:http://192.168.88.101:9000/user/feign_get?id=1 反复刷新浏览器会交替显示下面的json数据 {&quot;id&quot;:&quot;1&quot;,&quot;userName&quot;:&quot;xiaoming1&quot;,&quot;age&quot;:30,&quot;birthday&quot;:null} {&quot;id&quot;:&quot;1&quot;,&quot;userName&quot;:&quot;xiaoming&quot;,&quot;age&quot;:30,&quot;birthday&quot;:null} 问题 在调试feign程序的过程中，经常会出现timeout的问题，可以使用下面的3中方法之一来解决: hystrix.command.default.execution.isolation.thread.timeoutInMilliseconds: 5000 hystrix.command.default.execution.timeout.enabled: false feign.hystrix.enabled: false ## 索性禁用feign的hystrix支持","tags":[{"name":"java","slug":"java","permalink":"http://dennis.pathto.top/tags/java/"},{"name":"spring","slug":"spring","permalink":"http://dennis.pathto.top/tags/spring/"},{"name":"spring-boot","slug":"spring-boot","permalink":"http://dennis.pathto.top/tags/spring-boot/"},{"name":"spring-cloud","slug":"spring-cloud","permalink":"http://dennis.pathto.top/tags/spring-cloud/"}]},{"title":"5.spring-cloud-Ribbon-直接调用微服务","date":"2017-08-24T13:13:15.000Z","path":"2017/08/24/spring-cloud-direct-invoke-micro-service-5/","text":"禁止使用eureka来发现微服务，直接调用微服务 ribbon: eureka: enabled: false spring-cloud-provider-test-direct: ribbon: listOfServers: localhost:8085,localhost:8086","tags":[{"name":"java","slug":"java","permalink":"http://dennis.pathto.top/tags/java/"},{"name":"spring","slug":"spring","permalink":"http://dennis.pathto.top/tags/spring/"},{"name":"spring-boot","slug":"spring-boot","permalink":"http://dennis.pathto.top/tags/spring-boot/"},{"name":"spring-cloud","slug":"spring-cloud","permalink":"http://dennis.pathto.top/tags/spring-cloud/"}]},{"title":"4.spring-cloud-Ribbon其他负载均衡算法","date":"2017-08-24T13:13:12.000Z","path":"2017/08/24/spring-cloud-other-load-balance-4/","text":"Ribbon支持多种客户端负载均衡算法，如轮询，最小响应时间，随机等等. 这里简单使用一下随机的Ribbon客户端负载均衡算法 使用上一章的项目，在spring-cloud-consumer-01项目中添加一个配置类，在里面构建一个随机负载均衡的bean 配置类的方式配置父子均衡算法spring-cloud-consumer-01消费端添加了对随机负载均衡的支持 LoadBarentConfig.javapackage com.example.config; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; import com.netflix.client.config.IClientConfig; import com.netflix.loadbalancer.IRule; import com.netflix.loadbalancer.RandomRule; @Configuration public class LoadBarentConfig { /** * 随机规则 * @param config * @return */ @Bean public IRule iRuleBean(){ return new RandomRule(); } } 特别注意 LoadBarentConfig不能被spring扫描器扫描到 所以LoadBarentConfig.java不能和SpringCloudConsumer01Application.java文件在同一级别或者下一级子目录中 SpringCloudConsumer01Application.javapackage com.example.demo; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; import org.springframework.cloud.netflix.eureka.EnableEurekaClient; import org.springframework.cloud.netflix.ribbon.RibbonClient; import com.example.config.LoadBarentConfig; @EnableEurekaClient @SpringBootApplication @RibbonClient(name=&quot;spring-cloud-provider-test&quot;,configuration={LoadBarentConfig.class}) public class SpringCloudConsumer01Application { public static void main(String[] args) { SpringApplication.run(SpringCloudConsumer01Application.class, args); } } UserConstroller.javapackage com.example.demo.controller; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.web.bind.annotation.GetMapping; import org.springframework.web.bind.annotation.RequestMapping; import org.springframework.web.bind.annotation.ResponseBody; import org.springframework.web.bind.annotation.RestController; import org.springframework.web.client.RestTemplate; import com.example.demo.model.User; @RestController @RequestMapping(value=&quot;/user&quot;) public class UserConstroller { @Autowired private RestTemplate restTemplate; @ResponseBody @GetMapping(&quot;/get&quot;) public User get(String uid){ return restTemplate.getForObject(&quot;http://spring-cloud-provider/user/get?id=&quot;+uid, User.class); } @ResponseBody @GetMapping(&quot;/random_get&quot;) public User randomGet(String uid){ return restTemplate.getForObject(&quot;http://spring-cloud-provider-test/user/get?id=&quot;+uid, User.class); } } spring-cloud-provider这个服务包含spring-cloud-provider-01和spring-cloud-provider-02项目,这一组微服务提供的接口和前一节相同 spring-cloud-provider-test这个服务包含spring-cloud-provider-03和spring-cloud-provider-04项目 spring-cloud-provider-03package com.example.demo.controller; import java.util.HashMap; import java.util.Map; import org.springframework.web.bind.annotation.GetMapping; import org.springframework.web.bind.annotation.RequestMapping; import org.springframework.web.bind.annotation.ResponseBody; import org.springframework.web.bind.annotation.RestController; import com.example.demo.model.User; @RestController @RequestMapping(value=&quot;/user&quot;) public class UserController { private Map&lt;String, User&gt; umap = new HashMap(); public UserController(){ umap.put(&quot;1&quot;, new User(&quot;1&quot;, &quot;xiaoming3&quot;, 30)); umap.put(&quot;2&quot;, new User(&quot;2&quot;, &quot;xiaohong3&quot;, 20)); umap.put(&quot;3&quot;, new User(&quot;3&quot;, &quot;zhangsan3&quot;, 80)); umap.put(&quot;4&quot;, new User(&quot;4&quot;, &quot;lisi3&quot;, 10)); umap.put(&quot;5&quot;, new User(&quot;5&quot;, &quot;wangwu3&quot;, 22)); } @GetMapping(value=&quot;/get&quot;) @ResponseBody public User get(String id){ return umap.get(id); } } spring-cloud-provider-04package com.example.demo.controller; import java.util.HashMap; import java.util.Map; import org.springframework.web.bind.annotation.GetMapping; import org.springframework.web.bind.annotation.RequestMapping; import org.springframework.web.bind.annotation.ResponseBody; import org.springframework.web.bind.annotation.RestController; import com.example.demo.model.User; @RestController @RequestMapping(value=&quot;/user&quot;) public class UserController { private Map&lt;String, User&gt; umap = new HashMap(); public UserController(){ umap.put(&quot;1&quot;, new User(&quot;1&quot;, &quot;xiaoming4&quot;, 30)); umap.put(&quot;2&quot;, new User(&quot;2&quot;, &quot;xiaohong4&quot;, 20)); umap.put(&quot;3&quot;, new User(&quot;3&quot;, &quot;zhangsan4&quot;, 80)); umap.put(&quot;4&quot;, new User(&quot;4&quot;, &quot;lisi4&quot;, 10)); umap.put(&quot;5&quot;, new User(&quot;5&quot;, &quot;wangwu4&quot;, 22)); } @GetMapping(value=&quot;/get&quot;) @ResponseBody public User get(String id){ return umap.get(id); } } 验证浏览器多次刷新http://192.168.88.101:9000/user/random_get?uid=1 内容随机显示 {&quot;id&quot;:&quot;1&quot;,&quot;userName&quot;:&quot;xiaoming4&quot;,&quot;age&quot;:30,&quot;birthday&quot;:null} {&quot;id&quot;:&quot;1&quot;,&quot;userName&quot;:&quot;xiaoming3&quot;,&quot;age&quot;:30,&quot;birthday&quot;:null} 浏览器多次刷新http://192.168.88.101:9000/user/get?uid=1 内容轮询显示 {&quot;id&quot;:&quot;1&quot;,&quot;userName&quot;:&quot;xiaoming&quot;,&quot;age&quot;:30,&quot;birthday&quot;:null} {&quot;id&quot;:&quot;1&quot;,&quot;userName&quot;:&quot;xiaoming1&quot;,&quot;age&quot;:30,&quot;birthday&quot;:null} 配置文件配置客户端负载均衡 推荐使用这种方式配置负载均衡 application.yamlspring-cloud-provider-test: ribbon: NFLoadBalancerRuleClassName: com.netflix.loadbalancer.RandomRule","tags":[{"name":"java","slug":"java","permalink":"http://dennis.pathto.top/tags/java/"},{"name":"spring","slug":"spring","permalink":"http://dennis.pathto.top/tags/spring/"},{"name":"spring-boot","slug":"spring-boot","permalink":"http://dennis.pathto.top/tags/spring-boot/"},{"name":"spring-cloud","slug":"spring-cloud","permalink":"http://dennis.pathto.top/tags/spring-cloud/"}]},{"title":"3.spring-cloud-Ribbon负载均衡和故障转移","date":"2017-08-24T13:13:10.000Z","path":"2017/08/24/spring-cloud-ribbon-load-balance-failover3/","text":"Ribbon可以实现客户端的负载均衡和故障转移，默认情况下，Ribbon使用到的负载均衡算法是轮询算法 下面是Ribbon实现客户端负载均衡的列子 使用到的项目有spring-cloud-eureka,spring-cloud-provider-01,spring-cloud-provider-02,spring-cloud-consumer-01 服务提供端spring-cloud-provider-01pom.xml&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt; &lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.example&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-provider-01&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;name&gt;spring-cloud-provider-01&lt;/name&gt; &lt;description&gt;Demo project for Spring Boot&lt;/description&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;1.4.7.RELEASE&lt;/version&gt; &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt; &lt;/parent&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;spring-cloud.version&gt;Camden.SR7&lt;/spring-cloud.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-eureka&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;${spring-cloud.version}&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/dependencyManagement&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; &lt;/project&gt; application.yamlserver: port: 8080 spring: application: name: spring-cloud-provider eureka: client: service-url: defaultZone: http://localhost:8761/eureka instance: prefer-ip-address: true User.javapackage com.example.demo.model; import java.util.Date; public class User { private String id; private String userName; private int age; private Date birthday; public String getId() { return id; } public void setId(String id) { this.id = id; } public String getUserName() { return userName; } public void setUserName(String userName) { this.userName = userName; } public int getAge() { return age; } public void setAge(int age) { this.age = age; } public Date getBirthday() { return birthday; } public void setBirthday(Date birthday) { this.birthday = birthday; } public User(String id, String userName, int age, Date birthday) { super(); this.id = id; this.userName = userName; this.age = age; this.birthday = birthday; } public User(String id, String userName, int age) { super(); this.id = id; this.userName = userName; this.age = age; } } UserController.javapackage com.example.demo.controller; import java.util.HashMap; import java.util.Map; import org.springframework.web.bind.annotation.GetMapping; import org.springframework.web.bind.annotation.RequestMapping; import org.springframework.web.bind.annotation.ResponseBody; import org.springframework.web.bind.annotation.RestController; import com.example.demo.model.User; @RestController @RequestMapping(value=&quot;/user&quot;) public class UserController { private Map&lt;String, User&gt; umap = new HashMap(); public UserController(){ umap.put(&quot;1&quot;, new User(&quot;1&quot;, &quot;xiaoming1&quot;, 30)); umap.put(&quot;2&quot;, new User(&quot;2&quot;, &quot;xiaohong1&quot;, 20)); umap.put(&quot;3&quot;, new User(&quot;3&quot;, &quot;zhangsan1&quot;, 80)); umap.put(&quot;4&quot;, new User(&quot;4&quot;, &quot;lisi1&quot;, 10)); umap.put(&quot;5&quot;, new User(&quot;5&quot;, &quot;wangwu1&quot;, 22)); } @GetMapping(value=&quot;/get&quot;) @ResponseBody public User get(String id){ return umap.get(id); } } spring-cloud-provider-02spring-cloud-provider-01和spring-cloud-provider-02不同的地方是UserController其他地方都是一样 UserController.javapackage com.example.demo.controller; import java.util.HashMap; import java.util.Map; import org.springframework.web.bind.annotation.GetMapping; import org.springframework.web.bind.annotation.RequestMapping; import org.springframework.web.bind.annotation.ResponseBody; import org.springframework.web.bind.annotation.RestController; import com.example.demo.model.User; @RestController @RequestMapping(value=&quot;/user&quot;) public class UserController { private Map&lt;String, User&gt; umap = new HashMap(); public UserController(){ umap.put(&quot;1&quot;, new User(&quot;1&quot;, &quot;xiaoming&quot;, 30)); umap.put(&quot;2&quot;, new User(&quot;2&quot;, &quot;xiaohong&quot;, 20)); umap.put(&quot;3&quot;, new User(&quot;3&quot;, &quot;zhangsan&quot;, 80)); umap.put(&quot;4&quot;, new User(&quot;4&quot;, &quot;lisi&quot;, 10)); umap.put(&quot;5&quot;, new User(&quot;5&quot;, &quot;wangwu&quot;, 22)); } @GetMapping(value=&quot;/get&quot;) @ResponseBody public User get(String id){ return umap.get(id); } } 服务消费端spring-cloud-consumer-01pom.xml&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt; &lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.example&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-consumer-01&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;name&gt;spring-cloud-consumer-01&lt;/name&gt; &lt;description&gt;Demo project for Spring Boot&lt;/description&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;1.4.7.RELEASE&lt;/version&gt; &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt; &lt;/parent&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;spring-cloud.version&gt;Camden.SR7&lt;/spring-cloud.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-eureka&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-ribbon&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;${spring-cloud.version}&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/dependencyManagement&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; &lt;/project&gt; application.yamlserver: port: 8082 spring: application: name: spring-cloud-consumer eureka: client: service-url: defaultZone: http://localhost:8761/eureka instance: prefer-ip-address: true SpringCloudConsumer01Application.javapackage com.example.demo; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; import org.springframework.cloud.netflix.eureka.EnableEurekaClient; @EnableEurekaClient @SpringBootApplication public class SpringCloudConsumer01Application { public static void main(String[] args) { SpringApplication.run(SpringCloudConsumer01Application.class, args); } } CoreConfiguration.javapackage com.example.demo.config; import org.springframework.cloud.client.loadbalancer.LoadBalanced; import org.springframework.context.annotation.Bean; import org.springframework.stereotype.Controller; import org.springframework.web.client.RestTemplate; @Controller public class CoreConfiguration { @LoadBalanced @Bean public RestTemplate restTemplateBean(){ return new RestTemplate(); } } UserConstroller.javapackage com.example.demo.controller; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.web.bind.annotation.GetMapping; import org.springframework.web.bind.annotation.RequestMapping; import org.springframework.web.bind.annotation.ResponseBody; import org.springframework.web.bind.annotation.RestController; import org.springframework.web.client.RestTemplate; import com.example.demo.model.User; @RestController @RequestMapping(value=&quot;/user&quot;) public class UserConstroller { @Autowired private RestTemplate restTemplate; @ResponseBody @GetMapping(&quot;/get&quot;) public User get(String uid){ return restTemplate.getForObject(&quot;http://spring-cloud-provider/user/get?id=&quot;+uid, User.class); } } User.javapackage com.example.demo.model; import java.util.Date; public class User { private String id; private String userName; private int age; private Date birthday; public String getId() { return id; } public void setId(String id) { this.id = id; } public String getUserName() { return userName; } public void setUserName(String userName) { this.userName = userName; } public int getAge() { return age; } public void setAge(int age) { this.age = age; } public Date getBirthday() { return birthday; } public void setBirthday(Date birthday) { this.birthday = birthday; } public User(String id, String userName, int age, Date birthday) { super(); this.id = id; this.userName = userName; this.age = age; this.birthday = birthday; } public User(String id, String userName, int age) { super(); this.id = id; this.userName = userName; this.age = age; } public User(){} } 验证消费端 http://192.168.88.101:8082/user/get?uid=1 在浏览器中打开http://192.168.88.101:8082/user/get?uid=1，并且不停的刷新，页面中轮回显示下面的内容： {&quot;id&quot;:&quot;1&quot;,&quot;userName&quot;:&quot;xiaoming1&quot;,&quot;age&quot;:30,&quot;birthday&quot;:null} {&quot;id&quot;:&quot;1&quot;,&quot;userName&quot;:&quot;xiaoming&quot;,&quot;age&quot;:30,&quot;birthday&quot;:null} 当服务提供端挂了一个的时候，可以实现故障转移","tags":[{"name":"java","slug":"java","permalink":"http://dennis.pathto.top/tags/java/"},{"name":"spring","slug":"spring","permalink":"http://dennis.pathto.top/tags/spring/"},{"name":"spring-boot","slug":"spring-boot","permalink":"http://dennis.pathto.top/tags/spring-boot/"},{"name":"spring-cloud","slug":"spring-cloud","permalink":"http://dennis.pathto.top/tags/spring-cloud/"}]},{"title":"2.spring-cloud-eureka客户端的使用","date":"2017-08-24T13:13:07.000Z","path":"2017/08/24/spring-cloud-eureka-client-2/","text":"本章主要试验:eureka客户端注册 ，监控,eureka客户端信息 spring-cloud-provider-01pom.xml&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt; &lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.example&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-provider-01&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;name&gt;spring-cloud-provider-01&lt;/name&gt; &lt;description&gt;Demo project for Spring Boot&lt;/description&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;1.4.7.RELEASE&lt;/version&gt; &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt; &lt;/parent&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;spring-cloud.version&gt;Camden.SR7&lt;/spring-cloud.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-eureka&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;${spring-cloud.version}&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/dependencyManagement&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; &lt;/project&gt; application.yamlspring: application: name: spring-cloud-provider eureka: client: service-url: defaultZone: http://localhost:8761/eureka instance: prefer-ip-address: true SpringCloudProvider01Application.javapackage com.example.demo; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; import org.springframework.cloud.client.discovery.EnableDiscoveryClient; import org.springframework.cloud.netflix.eureka.EnableEurekaClient; @EnableEurekaClient //@EnableDiscoveryClient @SpringBootApplication public class SpringCloudProvider01Application { public static void main(String[] args) { SpringApplication.run(SpringCloudProvider01Application.class, args); } } spring-cloud-provider-02spring-cloud-provider-02项目和spring-cloud-provider-01除了yaml之外，其他都是一样的 application.yamlserver: port: 8081 spring: application: name: spring-cloud-provider eureka: client: service-url: defaultZone: http://localhost:8761/eureka instance: prefer-ip-address: true 结果验证 image 监控模块spring-boot-starter-actuator模块具有监控的功能 添加maven依赖&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; 浏览器验证http://192.168.88.102:8080/health {&quot;description&quot;:&quot;Spring Cloud Eureka Discovery Client&quot;,&quot;status&quot;:&quot;UP&quot;,&quot;discoveryComposite&quot;:{&quot;description&quot;:&quot;Spring Cloud Eureka Discovery Client&quot;,&quot;status&quot;:&quot;UP&quot;,&quot;discoveryClient&quot;:{&quot;description&quot;:&quot;Spring Cloud Eureka Discovery Client&quot;,&quot;status&quot;:&quot;UP&quot;,&quot;services&quot;:[&quot;spring-cloud-provider&quot;]},&quot;eureka&quot;:{&quot;description&quot;:&quot;Remote status from Eureka server&quot;,&quot;status&quot;:&quot;UNKNOWN&quot;,&quot;applications&quot;:{&quot;SPRING-CLOUD-PROVIDER&quot;:1}}},&quot;diskSpace&quot;:{&quot;status&quot;:&quot;UP&quot;,&quot;total&quot;:311385124864,&quot;free&quot;:246084595712,&quot;threshold&quot;:10485760},&quot;refreshScope&quot;:{&quot;status&quot;:&quot;UP&quot;},&quot;hystrix&quot;:{&quot;status&quot;:&quot;UP&quot;}} eureka客户端相关信息spring-cloud-provider-01和spring-cloud-provider-02 MicroServiceInfoController.javapackage com.example.demo.controller; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.cloud.client.ServiceInstance; import org.springframework.cloud.client.discovery.DiscoveryClient; import org.springframework.stereotype.Controller; import org.springframework.web.bind.annotation.GetMapping; import org.springframework.web.bind.annotation.RequestMapping; import org.springframework.web.bind.annotation.ResponseBody; import com.netflix.discovery.EurekaClient; @Controller @RequestMapping(value=&quot;/micro_server&quot;) public class MicroServiceInfoController { @Autowired private EurekaClient eurekaClient; @Autowired private DiscoveryClient discoveryClient; @ResponseBody @GetMapping(value=&quot;url&quot;) public String url(){ return eurekaClient.getNextServerFromEureka(&quot;SPRING-CLOUD-PROVIDER&quot;, false).getHomePageUrl(); } @ResponseBody @GetMapping(value=&quot;info&quot;) public ServiceInstance info(){ return discoveryClient.getLocalServiceInstance(); } } http://192.168.88.102:8081/micro_server/url 浏览器显示:http://192.168.88.102:8081/ http://192.168.88.102:8081/micro_server/info 浏览器显示 {“host”:”192.168.88.102”,”port”:8081,”metadata”:{},”uri”:”http://192.168.88.102:8081&quot;,&quot;secure&quot;:false,&quot;serviceId&quot;:&quot;spring-cloud-provider&quot;}","tags":[{"name":"java","slug":"java","permalink":"http://dennis.pathto.top/tags/java/"},{"name":"spring","slug":"spring","permalink":"http://dennis.pathto.top/tags/spring/"},{"name":"spring-boot","slug":"spring-boot","permalink":"http://dennis.pathto.top/tags/spring-boot/"},{"name":"spring-cloud","slug":"spring-cloud","permalink":"http://dennis.pathto.top/tags/spring-cloud/"}]},{"title":"1.spring-cloud-Eureka","date":"2017-08-24T13:13:04.000Z","path":"2017/08/24/spring-cloude-ureka-1/","text":"在Spring Cloud实现一个Eureka Server是一件非常简单的事情。下面我们来写一个Eureka Server DEMO。 (1) 首先创建一个Maven工程，添加内容如下： &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt; &lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.example&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-eureka&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;name&gt;spring-cloud-eureka&lt;/name&gt; &lt;description&gt;Demo project for Spring Boot&lt;/description&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;1.4.7.RELEASE&lt;/version&gt; &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt; &lt;/parent&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;spring-cloud.version&gt;Camden.SR7&lt;/spring-cloud.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-eureka-server&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;${spring-cloud.version}&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/dependencyManagement&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; &lt;/project&gt; (2) 编写启动类，在启动类上添加@EnableEurekaServer 注解。 package com.example.demo; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; import org.springframework.cloud.netflix.eureka.server.EnableEurekaServer; @EnableEurekaServer @SpringBootApplication public class SpringCloudEurekaApplication { public static void main(String[] args) { SpringApplication.run(SpringCloudEurekaApplication.class, args); } } (3) 编写配置文件application.yaml server: port: 8761 eureka: client: registerWithEureka: false fetchRegistry: false serviceUrl: defaultZone: http://localhost:8761/eureka/ 这样就完成了一个简单的Eureka Server。简要说明一下application.yml中的配置项： eureka.client.registerWithEureka ：表示是否将自己注册到Eureka Server，默认为true。由于当前这个应用就是Eureka Server，故而设为false。eureka.client.fetchRegistry ：表示是否从Eureka Server获取注册信息，默认为true。因为这是一个单点的Eureka Server，不需要同步其他的Eureka Server节点的数据，故而设为false。eureka.client.serviceUrl.defaultZone ：设置与Eureka Server交互的地址，查询服务和注册服务都需要依赖这个地址。默认是http://localhost:8761/eureka ；多个地址可使用 , 分隔。 Eureka的配置类所在类： org.springframework.cloud.netflix.eureka.EurekaInstanceConfigBean org.springframework.cloud.netflix.eureka.EurekaClientConfigBean org.springframework.cloud.netflix.eureka.server.EurekaServerConfigBean 测试 启动工程后，访问：http://localhost:8761/ 。我们会发现此时还没有服务注册到Eureka上面，如下图： image 该页面展示了Eureka的系统状态、当前注册到Eureka Server上的服务实例、一般信息、实例信息等。我们可以看到，当前还没有任何服务被注册到Eureka Server上。","tags":[{"name":"java","slug":"java","permalink":"http://dennis.pathto.top/tags/java/"},{"name":"spring","slug":"spring","permalink":"http://dennis.pathto.top/tags/spring/"},{"name":"spring-boot","slug":"spring-boot","permalink":"http://dennis.pathto.top/tags/spring-boot/"},{"name":"spring-cloud","slug":"spring-cloud","permalink":"http://dennis.pathto.top/tags/spring-cloud/"}]},{"title":"2.nginx-根据查询参数实现后端流量分发","date":"2017-08-17T12:36:55.000Z","path":"2017/08/17/nginx-Traffic-distribution-2/","text":"nginx应用层安装按照《1.安装nginx+openrestry》在study1和study2节点上安装nginx 配置study1和study2的lua页面http://study1/lua 1.study1 [root@study1 hello]# cat lua/hello.lua ngx.say(&quot;hello,study1&quot;) 2.study2 [root@study2 hello]# cat lua/hello.lua ngx.say(&quot;hello,study2&quot;) 配置流量分发层nginx (study0节点) [root@study0 lua]# cat hello.lua --ngx.say(&quot;hello,lua project&quot;) local uri_args = ngx.req.get_uri_args() local userId = uri_args[&quot;userId&quot;] local host = {&quot;192.168.137.151&quot;, &quot;192.168.137.152&quot;} local hash = ngx.crc32_long(userId) hash = (hash % 2) + 1 backend = &quot;http://&quot;..host[hash] local method = uri_args[&quot;method&quot;] local requestBody = &quot;/&quot;..method..&quot;?userId=&quot;..userId local http = require(&quot;resty.http&quot;) local httpc = http.new() local resp, err = httpc:request_uri(backend, { method = &quot;GET&quot;, path = requestBody }) if not resp then ngx.say(&quot;request error :&quot;, err) return end ngx.say(resp.body) httpc:close() 重启study0,study1,study2的节点的nginx/usr/servers/nginx/sbin/nginx -s reload 验证 浏览器打开:http://study0/lua?userId=1&amp;method=lua hello,study2 浏览器打开:http://study0/lua?userId=4&amp;method=lua hello,study1","tags":[{"name":"nginx","slug":"nginx","permalink":"http://dennis.pathto.top/tags/nginx/"},{"name":"openrestry","slug":"openrestry","permalink":"http://dennis.pathto.top/tags/openrestry/"}]},{"title":"1.安装nginx+openrestry","date":"2017-08-17T12:35:45.000Z","path":"2017/08/17/nginx-openrestry-install-1/","text":"部署nginx+openresty+lua，作为应用层nginx 安装nginx+openresty创建安装目录mkdir -p /usr/servers cd /usr/servers/ 安装依赖yum install -y readline-devel pcre-devel openssl-devel gcc wget http://openresty.org/download/openresty-1.11.2.4.tar.gz tar -zxvf openresty-1.11.2.4.tar.gz cd /usr/servers/openresty-1.11.2.4 cd bundle/LuaJIT-2.1-20170405/ make clean &amp;&amp; make &amp;&amp; make install ln -sf luajit-2.1.0-beta2 /usr/local/bin/luajit 安装bundlecd /usr/servers/openresty-1.11.2.4/bundle wget https://github.com/FRiCKLE/ngx_cache_purge/archive/2.3.tar.gz tar -xvf 2.3 wget https://github.com/yaoweibin/nginx_upstream_check_module/archive/v0.3.0.tar.gz tar -xvf v0.3.0 安装openrestycd /usr/servers/openresty-1.11.2.4 ./configure --prefix=/usr/servers --with-http_realip_module --with-pcre --with-luajit --add-module=./bundle/ngx_cache_purge-2.3/ --add-module=./bundle/nginx_upstream_check_module-0.3.0/ -j2 gmake &amp;&amp; gmake install 查看安装文件cd /usr/servers/ ll total 4304 drwxr-xr-x. 2 root root 4096 Aug 17 17:14 bin drwxr-xr-x. 6 root root 4096 Aug 17 17:14 luajit drwxr-xr-x. 6 root root 4096 Aug 17 17:14 lualib drwxr-xr-x. 11 root root 4096 Aug 17 17:16 nginx drwxrwxr-x. 6 1000 1000 4096 Aug 17 17:12 openresty-1.11.2.4 -rw-r--r--. 1 root root 4158984 Jul 12 01:44 openresty-1.11.2.4.tar.gz drwxr-xr-x. 43 root root 4096 Aug 17 17:14 pod -rw-r--r--. 1 root root 214511 Aug 17 17:14 resty.index drwxr-xr-x. 5 root root 4096 Aug 17 17:14 site 启动nginx/usr/servers/nginx/sbin/nginx nginx+lua开发的hello world配置nginx.confvi /usr/servers/nginx/conf/nginx.conf 在http部分添加： lua_package_path &quot;/usr/servers/lualib/?.lua;;&quot;; lua_package_cpath &quot;/usr/servers/lualib/?.so;;&quot;; include lua.conf; 添加lua.conf在/usr/servers/nginx/conf下，创建一个lua.conf,内容如下: server { listen 80; server_name _; } 验证配置文件/usr/servers/nginx/sbin/nginx -t nginx: the configuration file /usr/servers/nginx/conf/nginx.conf syntax is ok nginx: configuration file /usr/servers/nginx/conf/nginx.conf test is successful 在lua.conf的server部分添加lua脚本location /lua { default_type &apos;text/html&apos;; content_by_lua &apos;ngx.say(&quot;hello world&quot;)&apos;; } 测试配置是否有问题/usr/servers/nginx/sbin/nginx -t 重新nginx加载配置/usr/servers/nginx/sbin/nginx -s reload 访问http: http://study0/lua 单独编写lua脚本模块vi /usr/servers/nginx/conf/lua/test.lua ngx.say(&quot;hello lua&quot;); 修改lua.conflocation /lua { default_type &apos;text/html&apos;; content_by_lua_file conf/lua/test.lua; } 如果发现异常,查看异常日志tail -f /usr/servers/nginx/logs/error.log 工程化的nginx+lua项目结构项目工程结构 hello hello.conf lua hello.lua lualib *.lua *.so 创建hello项目mkdir /usr/hello cd /usr/hello cp -r /usr/servers/lualib/ . 修改nginx.confvi /usr/servers/nginx/conf/nginx.conf 在http模块添加 lua_package_path &quot;/usr/hello/lualib/?.lua;;&quot;; lua_package_cpath &quot;/usr/hello/lualib/?.so;;&quot;; include /usr/hello/hello.conf; 添加hello.confvi /usr/hello/hello.conf server { listen 80; server_name _; location /lua { default_type &apos;text/html&apos;; content_by_lua_file /usr/hello/lua/hello.lua; } } 添加/usr/hello/lua/hello.luamkdir /usr/hello/lua/ vi /usr/hello/lua/hello.lua ngx.say(&quot;hello,lua project&quot;) 重启nginx/usr/servers/nginx/sbin/nginx -s reload","tags":[{"name":"nginx","slug":"nginx","permalink":"http://dennis.pathto.top/tags/nginx/"},{"name":"openrestry","slug":"openrestry","permalink":"http://dennis.pathto.top/tags/openrestry/"}]},{"title":"这样的公司绝对不能去面试","date":"2017-08-15T23:57:22.000Z","path":"2017/08/16/interview-garbage-company/","text":"首先，真正的高级人才是不用找工作的，因为只有被工作找的份。 当你开始厌倦了旧的工作环境，或者遇到天花板，没有了发展空间，或者遇到新老板上任后排除异己来提拔自己的亲信等等……这些都会促使你动跳槽的念头。如果你真打算自己去找工作，那么至少需注意以下几点： 有些公司常年在招聘同一个职位。网上求职尤其需注意那些一天到晚在网上打招聘广告的公司。这类公司通常分成两类： 一类是垃圾公司，如一些别有用心的保险公司、中介公司等。这类公司以获取你的个人资源和个人信息为目的。 二类是某些小有名气的公司，但由于用人条件苛刻并且薪资待遇与他们的苛刻要求不匹配，所以一年到头在招人，却总也招不到让他们满意的人。还有一些著名公司，以打广告为目的，招人为幌子，一个破烂职位能放在网上招一两年。 当心猎头公司泄露你的隐私。他们更象是猎狗公司，他们嗅觉灵敏，对打探个人隐私有着狂热而又执着的癖好，往往是工作没给你找成功，却把你现在工作的公司，以前工作的公司闹得沸沸扬扬。如果你不想丢掉现在的工作，不想让你以前的同事议论非非，那么，请慎重选择猎头公司，慎重透露你的隐私给猎头公司。切记切记。 通知你去面试却连电话都不舍得打一个的公司不要去。只给你发邮件乃至短信而不打电话叫你去面试的公司，你可以不予理睬。通常这是一些垃圾公司，没有能力满足你的基本要求。他们自己也没把握雇得起你，所以连电话费也免了。 第一次电话就让你于某月某日几点钟去某地面试的公司，必须立刻回绝。因为你到时候到那里一看，一堆刚毕业2、3年的年轻后生正爬在桌子上填写简历。你跟这些人竞争的结果就是你的工资最多只有他们的1倍高，5、6千顶天了。那么应该怎么回答呢?告诉人事经理，我没空，我只有莫月某日下午几点钟才有空，若不然，就不用去了，浪费时间，肯定是低级职位。 第一次面试就让你带好学历学位证书去面试的公司，千万别去。不用问，那些肯定是低级职位，多是面向刚毕业的大学生的。 去公司面试前必须问清楚是谁面试你，如果你得知不是经理级别的来面试你的，劝你立刻回绝这个职位。因为如果面试你的是个的基层领导，那么你的职位肯定也高不到哪儿去。总之，打扮得笔挺结果给猪看了，即花钱又浪费时间。 一进门就让你填一堆表格的公司，必须立马走人。因为这是招聘中低等员工的惯用伎俩，特别是对那些喜欢出一些类似智力测试题的试卷的公司，千万不要和他们浪费时间。 不要去人才市场找工作，高端职位不是放在菜市场上卖的。如果公司所在城市需要你搭乘火车乃至飞机前往的，一定要问明公司是否不报销路费。如果不报销，或者说如果录取就报销的公司，建议不要冒险去试。即使十个面试者中最后被你淘汰了九个，你还是会发现该公司的福利待遇极差极差。惨痛教训，切记勿再试。 要知道一个公司的整体面貌和素质如何，那就请留意人事部职员的面貌，尤其是人事经理的素质往往是一个公司整体素质的缩影。如果接待你的人事经理较热心较礼貌周到，那么该公司的工作氛围一般较好，如果人事经理较冷漠或不很礼貌，那么该公司同事关系往往较残酷较冷漠。（完）","tags":[{"name":"interview","slug":"interview","permalink":"http://dennis.pathto.top/tags/interview/"},{"name":"work","slug":"work","permalink":"http://dennis.pathto.top/tags/work/"}]},{"title":"9.spring-boot-跨域服务开发","date":"2017-08-15T15:16:22.000Z","path":"2017/08/15/spring-boot-cors-9/","text":"CORS介绍跨域资源共享 (CORS)是一个被绝大部分浏览器实现的W3C标准，CORS允许你灵活的指定跨域请求是否授权而不是使用一些不安全脆弱的方法，例如IFRAME或者JSONP。 CORS实现方法一MyConfiguration.javapackage com.example.demo.config; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; import org.springframework.web.servlet.config.annotation.CorsRegistry; import org.springframework.web.servlet.config.annotation.WebMvcConfigurer; import org.springframework.web.servlet.config.annotation.WebMvcConfigurerAdapter; @Configuration public class MyConfiguration { @Bean public WebMvcConfigurer corsConfigurer() { return new WebMvcConfigurerAdapter() { @Override public void addCorsMappings(CorsRegistry registry) { //添加允许跨域访问的网站 registry.addMapping(&quot;/cors_req/**&quot;).allowedOrigins(&quot;http://dennis-dzqapp.rhcloud.com&quot;,&quot;http://localhost:8080&quot;); } }; } } 或者MyConfiguration2.javapackage com.example.demo.config; import org.springframework.context.annotation.Configuration; import org.springframework.web.servlet.config.annotation.CorsRegistry; import org.springframework.web.servlet.config.annotation.WebMvcConfigurerAdapter; @Configuration public class MyConfiguration2 extends WebMvcConfigurerAdapter{ @Override public void addCorsMappings(CorsRegistry registry) { registry.addMapping(&quot;/cors_req/**&quot;).allowedOrigins(&quot;https://dennis-dzqapp.rhcloud.com&quot;,&quot;http://localhost:8080&quot;); } } CorsController.javapackage com.example.demo.controller; import org.springframework.web.bind.annotation.RequestMapping; import org.springframework.web.bind.annotation.RestController; @RestController @RequestMapping(value=&quot;/cors_req&quot;) public class CorsController { @RequestMapping(value=&quot;/greeting&quot;) public String greeting(){ return &quot;hello,CorsController&quot;; } } application.propertiesserver.port=9999 验证代码$.ajax({ url: &quot;http://localhost:9999/cors_req/greeting&quot;, type: &quot;POST&quot;, data: { }, success: function(data, status, xhr) { console.log(data); alert(data); } }); 使用http://dennis-dzqapp.rhcloud.com异步调用/cors_req/greeting rest api服务 image cors实现方法二CorsController2.javapackage com.example.demo.controller; import org.springframework.web.bind.annotation.CrossOrigin; import org.springframework.web.bind.annotation.RequestMapping; import org.springframework.web.bind.annotation.RequestMethod; import org.springframework.web.bind.annotation.RestController; @RestController @RequestMapping(value=&quot;/cors_req2&quot;, method = RequestMethod.POST) public class CorsController2 { @CrossOrigin(origins = &quot;http://dennis-dzqapp.rhcloud.com&quot;) @RequestMapping(value=&quot;/greeting&quot;) public String greeting(){ return &quot;hello,CorsController2&quot;; } } 验证结果 image","tags":[{"name":"java","slug":"java","permalink":"http://dennis.pathto.top/tags/java/"},{"name":"spring","slug":"spring","permalink":"http://dennis.pathto.top/tags/spring/"},{"name":"spring-boot","slug":"spring-boot","permalink":"http://dennis.pathto.top/tags/spring-boot/"}]},{"title":"8.spring-boot-文件上传","date":"2017-08-15T15:16:17.000Z","path":"2017/08/15/spring-boot-file-pload-8/","text":"文件上传的控制器类FileUploadController.javapackage com.dennis.controller; import java.io.File; import java.io.IOException; import org.slf4j.Logger; import org.slf4j.LoggerFactory; import org.springframework.stereotype.Controller; import org.springframework.web.bind.annotation.RequestMapping; import org.springframework.web.bind.annotation.RequestParam; import org.springframework.web.bind.annotation.ResponseBody; import org.springframework.web.multipart.MultipartFile; @Controller @RequestMapping(value = &quot;/file&quot;) public class FileUploadController { private static final Logger logger = LoggerFactory.getLogger(FileUploadController.class); @RequestMapping(value = &quot;/upload&quot;) @ResponseBody public String upload(@RequestParam(&quot;myFile&quot;) MultipartFile file) { if (file.isEmpty()) { return &quot;文件为空&quot;; } // 获取文件名 String fileName = file.getOriginalFilename(); logger.info(&quot;上传的文件名为：&quot; + fileName); // 获取文件的后缀名 String suffixName = fileName.substring(fileName.lastIndexOf(&quot;.&quot;)); logger.info(&quot;上传的后缀名为：&quot; + suffixName); // 文件上传路径 String filePath = &quot;d:/mydir/&quot;; // 解决中文问题，liunx下中文路径，图片显示问题 // fileName = UUID.randomUUID() + suffixName; File dest = new File(filePath + fileName); // 检测是否存在目录 if (!dest.getParentFile().exists()) { dest.getParentFile().mkdirs(); } try { file.transferTo(dest); return &quot;上传成功&quot;; } catch (IllegalStateException e) { e.printStackTrace(); } catch (IOException e) { e.printStackTrace(); } return &quot;上传失败&quot;; } } 添加对文件上传的支持application.yamlspring: http: multipart: enabled: true #默认支持文件上传. file-size-threshold: 0 #支持文件写入磁盘. location: / # 上传文件的临时目录 max-file-size: 1Mb # 最大支持文件大小 max-request-size: 10Mb # 最大支持请求大小 客户端测试 image 日志打印2017-08-15 22:26:40.037 INFO 8044 --- [nio-8080-exec-1] c.d.controller.FileUploadController : 上传的文件名为：exception-dir-struct.jpg 2017-08-15 22:26:40.037 INFO 8044 --- [nio-8080-exec-1] c.d.controller.FileUploadController : 上传的后缀名为：.jpg 文件上传成功","tags":[{"name":"java","slug":"java","permalink":"http://dennis.pathto.top/tags/java/"},{"name":"spring","slug":"spring","permalink":"http://dennis.pathto.top/tags/spring/"},{"name":"spring-boot","slug":"spring-boot","permalink":"http://dennis.pathto.top/tags/spring-boot/"}]},{"title":"7.spring-boot-底层常用的过滤器监听器servlet开发","date":"2017-08-15T15:16:11.000Z","path":"2017/08/15/spring-boot-servlet-filter-listener-7/","text":"Web开发使用 Controller 基本上可以完成大部分需求，但是我们还可能会用到 Servlet、 Filter、Listener等等 使用注册的方法开发servlet,filter,listenerMyServlet.javapackage com.dennis.web; import java.io.IOException; import javax.servlet.ServletException; import javax.servlet.http.HttpServlet; import javax.servlet.http.HttpServletRequest; import javax.servlet.http.HttpServletResponse; public class MyServlet extends HttpServlet{ /** * */ private static final long serialVersionUID = 1L; protected void doGet(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException { doPost(request, response); } @Override protected void doPost(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException { response.getWriter().write(&quot;hello MyServlet&quot;); } } MyFilter.javapackage com.dennis.web; import java.io.IOException; import javax.servlet.Filter; import javax.servlet.FilterChain; import javax.servlet.FilterConfig; import javax.servlet.ServletException; import javax.servlet.ServletRequest; import javax.servlet.ServletResponse; public class MyFilter implements Filter { @Override public void destroy() { // TODO Auto-generated method stub } @Override public void doFilter(ServletRequest request, ServletResponse response, FilterChain chain) throws IOException, ServletException { // TODO Auto-generated method stub System.out.println(&quot;hello,MyFilter&quot;); chain.doFilter(request, response); } @Override public void init(FilterConfig arg0) throws ServletException { // TODO Auto-generated method stub } } MyListener.javapackage com.dennis.web; import javax.servlet.ServletContextEvent; import javax.servlet.ServletContextListener; public class MyListener implements ServletContextListener{ @Override public void contextDestroyed(ServletContextEvent arg0) { // TODO Auto-generated method stub System.out.println(&quot;MyListener.contextDestroyed&quot;); } @Override public void contextInitialized(ServletContextEvent arg0) { // TODO Auto-generated method stub System.out.println(&quot;MyListener.contextInitialized&quot;); } } SpringBootMybatisApplication.javapackage com.dennis; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; import org.springframework.boot.context.embedded.FilterRegistrationBean; import org.springframework.boot.context.embedded.ServletRegistrationBean; import org.springframework.boot.web.servlet.ServletListenerRegistrationBean; import org.springframework.context.annotation.Bean; import com.dennis.web.MyFilter; import com.dennis.web.MyListener; import com.dennis.web.MyServlet; @SpringBootApplication public class SpringBootMybatisApplication { public static void main(String[] args) { SpringApplication.run(SpringBootMybatisApplication.class, args); } @Bean public ServletRegistrationBean servletRegistrationBean() { return new ServletRegistrationBean(new MyServlet(), &quot;/my_servlet&quot;); } @Bean public FilterRegistrationBean filterRegistrationBean() { FilterRegistrationBean filterRegistrationBean = new FilterRegistrationBean(new MyFilter(), servletRegistrationBean()); filterRegistrationBean.addUrlPatterns(&quot;/my_servlet&quot;,&quot;/auth_uri/list&quot;); return filterRegistrationBean; } @Bean public ServletListenerRegistrationBean&lt;MyListener&gt; servletListenerRegistrationBean() { return new ServletListenerRegistrationBean&lt;MyListener&gt;(new MyListener()); } } 验证启动spring-boot项目的时候，控制台打印下面的日志 MyListener.contextInitialized 浏览器打开http://localhost:8080/my_servlet和http://localhost:8080/auth_uri/list显示 hello MyServlet 并且控制台上打印 hello,MyFilter 浏览器访问http://localhost:8080/auth_uri/envname，控制台没有打印任何hello,MyFilter的日志 使用servlet容器初始化器来添加servlet,filter,listenerMyServlet2.javapackage com.dennis.web; import java.io.IOException; import javax.servlet.ServletException; import javax.servlet.http.HttpServlet; import javax.servlet.http.HttpServletRequest; import javax.servlet.http.HttpServletResponse; public class MyServlet2 extends HttpServlet{ /** * */ private static final long serialVersionUID = 1L; protected void doGet(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException { doPost(request, response); } @Override protected void doPost(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException { response.getWriter().write(&quot;hello MyServlet2&quot;); } } MyFilter2.javapackage com.dennis.web; import java.io.IOException; import javax.servlet.Filter; import javax.servlet.FilterChain; import javax.servlet.FilterConfig; import javax.servlet.ServletException; import javax.servlet.ServletRequest; import javax.servlet.ServletResponse; public class MyFilter2 implements Filter { @Override public void destroy() { // TODO Auto-generated method stub } @Override public void doFilter(ServletRequest request, ServletResponse response, FilterChain chain) throws IOException, ServletException { // TODO Auto-generated method stub System.out.println(&quot;hello,MyFilter2&quot;); chain.doFilter(request, response); } @Override public void init(FilterConfig arg0) throws ServletException { // TODO Auto-generated method stub } } MyListener2.javapackage com.dennis.web; import javax.servlet.ServletContextEvent; import javax.servlet.ServletContextListener; public class MyListener2 implements ServletContextListener{ @Override public void contextDestroyed(ServletContextEvent arg0) { // TODO Auto-generated method stub System.out.println(&quot;MyListener.contextDestroyed2&quot;); } @Override public void contextInitialized(ServletContextEvent arg0) { // TODO Auto-generated method stub System.out.println(&quot;MyListener.contextInitialized2&quot;); } } MyServletContextInitializer.javapackage com.dennis.web; import java.util.EnumSet; import javax.servlet.DispatcherType; import javax.servlet.ServletContext; import javax.servlet.ServletException; import org.springframework.boot.web.servlet.ServletContextInitializer; public class MyServletContextInitializer implements ServletContextInitializer { @Override public void onStartup(ServletContext servletContext) throws ServletException { // TODO Auto-generated method stub servletContext.addServlet(&quot;myServlet2&quot;, new MyServlet2()).addMapping(&quot;/my_servlet2&quot;); servletContext.addFilter(&quot;myFilter2&quot;, new MyFilter2()) //添加过滤页面 .addMappingForServletNames(EnumSet.of(DispatcherType.REQUEST), true, &quot;myServlet2&quot;); servletContext.addListener(new MyListener2()); } } 在SpringBootMybatisApplication.java中添加下面的代码,把MyServletContextInitializer添加到spring容器的管理范围 @Bean public ServletContextInitializer servletContextInitializer(){ return new MyServletContextInitializer(); } 使用注解的方式实现servlet,filter,listenerMyServletContextInitializer.java添加@ServletComponentScan注解 package com.dennis; @SpringBootApplication @ServletComponentScan public class SpringBootMybatisApplication { public static void main(String[] args) { SpringApplication.run(SpringBootMybatisApplication.class, args); } } MyFilter3.java添加@WebFilter(urlPatterns={})注解 package com.dennis.web; @WebFilter(urlPatterns={})//添加需要拦截的url模式匹配 public class MyFilter3 implements Filter { @Override public void destroy() { // TODO Auto-generated method stub } @Override public void doFilter(ServletRequest request, ServletResponse response, FilterChain chain) throws IOException, ServletException { // TODO Auto-generated method stub System.out.println(&quot;hello,MyFilter3&quot;); chain.doFilter(request, response); } @Override public void init(FilterConfig arg0) throws ServletException { // TODO Auto-generated method stub } } MyListener3.java在该类中添加@WebListener注解 MyServlet3.java在该类中添加@WebServlet注解","tags":[{"name":"java","slug":"java","permalink":"http://dennis.pathto.top/tags/java/"},{"name":"spring","slug":"spring","permalink":"http://dennis.pathto.top/tags/spring/"},{"name":"spring-boot","slug":"spring-boot","permalink":"http://dennis.pathto.top/tags/spring-boot/"}]},{"title":"6.spring-boot-错误页面开发","date":"2017-08-15T15:16:06.000Z","path":"2017/08/15/spring-boot-error-page-6/","text":"默认的错误页面处理类org.springframework.boot.autoconfigure.web.BasicErrorController 添加了自定义错误处理页面的项目结构如下: image 在pom.xml中需要添加下面的依赖 &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-web&lt;/artifactId&gt; &lt;/dependency&gt; 服务器端异常会返回500的页面，会使用500.html页面返回给客户端浏览器 如果浏览器请求的资源不存在，会返回400.html的页面给客户端浏览器 一次类推，其他的错误码页面只需要在resources/public/error下面添加即可 TestExceptionPageController.java package com.dennis.controller; import org.springframework.boot.autoconfigure.web.ErrorController; import org.springframework.stereotype.Controller; import org.springframework.web.bind.annotation.RequestMapping; import org.springframework.web.bind.annotation.ResponseBody; @Controller @RequestMapping({&quot;/tepc&quot;}) public class TestExceptionPageController { @RequestMapping(value=&quot;test500&quot;) @ResponseBody public String test500(){ ErrorController xx; int i = 1/0; return &quot;hello&quot;; } } 验证http://localhost:8080/tepc/test500 由于1/0，会抛出一个运行时异常 image http://localhost:8080/tepc/xxxx 不存在这样的资源 image","tags":[{"name":"java","slug":"java","permalink":"http://dennis.pathto.top/tags/java/"},{"name":"spring","slug":"spring","permalink":"http://dennis.pathto.top/tags/spring/"},{"name":"spring-boot","slug":"spring-boot","permalink":"http://dennis.pathto.top/tags/spring-boot/"}]},{"title":"5.spring-boot和thymeleaf集成","date":"2017-08-15T15:16:00.000Z","path":"2017/08/15/spring-boot-thymeleaf-5/","text":"在spring-boot项目中添加thymeleaf依赖 &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-thymeleaf&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; 添加模板文件resources/templates/test.html &lt;!DOCTYPE html&gt; &lt;html xmlns=&quot;http://www.w3.org/1999/xhtml&quot; xmlns:th=&quot;http://www.thymeleaf.org&quot;&gt; &lt;head&gt; &lt;meta charset=&quot;UTF-8&quot; /&gt; &lt;title&gt;Insert title here&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;div th:text=&quot;${word}&quot;&gt;&lt;/div&gt; &lt;/body&gt; &lt;/html&gt; 在项目配置文件application.yaml中添加对thymeleaf的支持 spring: thymeleaf: prefix: classpath:/templates/ suffix: .html mode: HTML5 encoding: UTF-8 content-type: text/html cache: true UriController.java package com.dennis.controller; import java.util.List; import javax.annotation.Resource; import org.springframework.beans.factory.annotation.Value; import org.springframework.stereotype.Controller; import org.springframework.ui.Model; import org.springframework.web.bind.annotation.RequestMapping; import org.springframework.web.bind.annotation.RequestMethod; import org.springframework.web.bind.annotation.ResponseBody; @Controller @RequestMapping({&quot;/auth_uri&quot;}) public class UriController { @RequestMapping(value = &quot;/greeting&quot;, method = RequestMethod.GET) public String view(Model model){ model.addAttribute(&quot;word&quot;, &quot;hello,world&quot;); return &quot;test&quot;; } } 浏览器验证 image","tags":[{"name":"java","slug":"java","permalink":"http://dennis.pathto.top/tags/java/"},{"name":"spring","slug":"spring","permalink":"http://dennis.pathto.top/tags/spring/"},{"name":"spring-boot","slug":"spring-boot","permalink":"http://dennis.pathto.top/tags/spring-boot/"}]},{"title":"4.spring-boot多环境配置","date":"2017-08-15T15:15:54.000Z","path":"2017/08/15/spring-boot-multi-env-4/","text":"为什么需要使用多环境配置spring-boot项目只需要编译一次,使用不同的运行参数,就可以方便地在多种不同平台下部署，提高效率，减少出错 项目结构多环境项目配置文件结果如下: image 如果要支持多环境部署，需要在application.properties文件中添加一个属性: spring.profiles.active=dev 该属性默认激活dev配置文件application-dev.properties,如果需要激活prod配置文件，只需修改为: spring.profiles.active=prod application-dev.properties envname=dev application-prod.properties envname=prod UriController.java package com.dennis.controller; import java.util.List; import javax.annotation.Resource; import org.springframework.beans.factory.annotation.Value; import org.springframework.web.bind.annotation.RequestMapping; import org.springframework.web.bind.annotation.ResponseBody; import org.springframework.web.bind.annotation.RestController; import com.dennis.dao.AuthUriMapper; import com.dennis.model.AuthUri; @RestController @RequestMapping({&quot;/auth_uri&quot;}) public class UriController { @Value(value=&quot;${envname}&quot;) private String envname; @RequestMapping(value=&quot;/envname&quot;) public String envname(){ return envname; } } 打包项目mvn clean package 运行项目java -jar spring-boot-mybatis-0.0.1-SNAPSHOT.jar --spring.profiles.active=prod 浏览器验证 image 注意：由于spring-boot 支持yaml的方式配置项目，如果要支持多环境配置，只需要把对应的配置文件后缀名修改为yaml,内容为yaml格式即可 如我的配置如下: application.yaml mybatis: mapper-locations: classpath:mapper/*Mapper.xml config-location: classpath:mapper/config/sqlMapConfig.xml type-aliases-package: com.dennis.model spring: datasource: url: jdbc:mysql://localhost:3306/dennis?useSSL=true&amp;useLegacyDatetimeCode=false&amp;serverTimezone=Asia/Shanghai driver-class-name: com.mysql.jdbc.Driver username: root password: cculi profiles: active: dev application-dev.yaml envname: dev application-prod.yaml envname: prod","tags":[{"name":"java","slug":"java","permalink":"http://dennis.pathto.top/tags/java/"},{"name":"spring","slug":"spring","permalink":"http://dennis.pathto.top/tags/spring/"},{"name":"spring-boot","slug":"spring-boot","permalink":"http://dennis.pathto.top/tags/spring-boot/"}]},{"title":"3.spring-boot+mybatis集成","date":"2017-08-15T15:15:48.000Z","path":"2017/08/15/spring-boot-mybatis-3/","text":"根据第二章的方式创建spring-boot项目，选中mybatis框架 项目的结构和文件如下所示: image pom.xml&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt; &lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.example&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-mybatis&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;name&gt;spring-boot-mybatis&lt;/name&gt; &lt;description&gt;Demo project for Spring Boot&lt;/description&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;1.4.7.RELEASE&lt;/version&gt; &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt; &lt;/parent&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.2.1&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-thymeleaf&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; &lt;/project&gt; application.propertiesmybatis.mapper-locations=classpath:mapper/*Mapper.xml mybatis.config-location=classpath:mapper/config/sqlMapConfig.xml mybatis.type-aliases-package=com.dennis.model spring.datasource.url=jdbc:mysql://localhost:3306/dennis?useSSL=true&amp;useLegacyDatetimeCode=false&amp;serverTimezone=Asia/Shanghai spring.datasource.driver-class-name=com.mysql.jdbc.Driver spring.datasource.username=root spring.datasource.password=123456 SqlMapConfig.xml&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; ?&gt; &lt;!DOCTYPE configuration PUBLIC &quot;-//mybatis.org//DTD Config 3.0//EN&quot; &quot;http://mybatis.org/dtd/mybatis-3-config.dtd&quot;&gt; &lt;configuration&gt; &lt;/configuration&gt; SpringBootMybatisApplication.javapackage com.dennis; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; @SpringBootApplication public class SpringBootMybatisApplication { public static void main(String[] args) { SpringApplication.run(SpringBootMybatisApplication.class, args); } } AuthUri.javapackage com.dennis.model; import java.sql.Date; public class AuthUri { private String uri_id; private String uri; private Date insert_time; public String getUri_id() { return uri_id; } public void setUri_id(String uri_id) { this.uri_id = uri_id; } public String getUri() { return uri; } public void setUri(String uri) { this.uri = uri; } public Date getInsert_time() { return insert_time; } public void setInsert_time(Date insert_time) { this.insert_time = insert_time; } @Override public String toString() { return &quot;AuthUri [uri_id=&quot; + uri_id + &quot;, uri=&quot; + uri + &quot;, insert_time=&quot; + insert_time + &quot;]&quot;; } } AuthUriMapper.javapackage com.dennis.dao; import java.util.List; import org.apache.ibatis.annotations.Mapper; import org.apache.ibatis.annotations.Select; import com.dennis.model.AuthUri; @Mapper public interface AuthUriMapper { @Select(&quot;select * from auth_uri&quot;) List&lt;AuthUri&gt; list(); } UriController.javapackage com.dennis.controller; import java.util.List; import javax.annotation.Resource; import org.springframework.web.bind.annotation.RequestMapping; import org.springframework.web.bind.annotation.ResponseBody; import org.springframework.web.bind.annotation.RestController; import com.dennis.dao.AuthUriMapper; import com.dennis.model.AuthUri; @RestController @RequestMapping({&quot;/auth_uri&quot;}) public class UriController { @Resource private AuthUriMapper authUriMapper; @RequestMapping(value=&quot;/list&quot;) @ResponseBody public List&lt;AuthUri&gt; list(){ return authUriMapper.list(); } } 本项目下载地址 1git clone https://github.com/599166320/spring-boot-mybatis.git","tags":[{"name":"java","slug":"java","permalink":"http://dennis.pathto.top/tags/java/"},{"name":"spring","slug":"spring","permalink":"http://dennis.pathto.top/tags/spring/"},{"name":"spring-boot","slug":"spring-boot","permalink":"http://dennis.pathto.top/tags/spring-boot/"}]},{"title":"2.spring-boot项目创建","date":"2017-08-15T15:15:42.000Z","path":"2017/08/15/spring-boot-create-2/","text":"安装完sts之后，可以直接使用eclispe创建spring-boot 项目创建的步骤如下: image image image image","tags":[{"name":"java","slug":"java","permalink":"http://dennis.pathto.top/tags/java/"},{"name":"spring","slug":"spring","permalink":"http://dennis.pathto.top/tags/spring/"},{"name":"spring-boot","slug":"spring-boot","permalink":"http://dennis.pathto.top/tags/spring-boot/"}]},{"title":"1.Spring Tool Suite插件的安装","date":"2017-08-15T15:15:36.000Z","path":"2017/08/15/spring-boot-plugin-1/","text":"1. image 2. image","tags":[{"name":"java","slug":"java","permalink":"http://dennis.pathto.top/tags/java/"},{"name":"spring","slug":"spring","permalink":"http://dennis.pathto.top/tags/spring/"},{"name":"spring-boot","slug":"spring-boot","permalink":"http://dennis.pathto.top/tags/spring-boot/"}]},{"title":"6.redis部署哨兵集群","date":"2017-08-13T16:14:24.000Z","path":"2017/08/14/redis-6-sentinal-deploy/","text":"如何部署哨兵集群，如何基于哨兵进行故障转移，如何实现企业级的配置方案 哨兵的配置文件在源码编译安装redis之后，redis目录下面有一个配置问价sentinel.conf，这是哨兵最小的配置文件。每一个哨兵都可以去监控多个节点的maser-slaves的主从架构。有些公司，为不同的项目，部署了多个master-slaves的redis主从集群。为了解决多个redis集群的监控问题，相同的一套哨兵集群，就可以去监控不同的多个redis主从集群。 mymaster为redis主从集群分配一个逻辑的名称 sentinel monitor mymaster 127.0.0.1 6379 2 sentinel down-after-milliseconds mymaster 60000 sentinel failover-timeout mymaster 180000 sentinel parallel-syncs mymaster 1 sentinel monitor resque 192.168.1.3 6380 4 sentinel down-after-milliseconds resque 10000 sentinel failover-timeout resque 180000 sentinel parallel-syncs resque 5 sentinel monitor mymaster 127.0.0.1 6379 类似这种配置，来指定对一个master的监控，给监控的master指定的一个名称，因为后面分布式集群架构里会讲解，可以配置多个master做数据拆分 sentinel down-after-milliseconds mymaster 60000 sentinel failover-timeout mymaster 180000 sentinel parallel-syncs mymaster 1 上面的三个配置，都是针对某个监控的master配置的，给其指定上面分配的名称即可 上面这段配置，就监控了两个master node 这是最小的哨兵配置，如果发生了master-slave故障转移，或者新的哨兵进程加入哨兵集群，那么哨兵会自动更新自己的配置文件 sentinel monitor master-group-name hostname port quorum quorum的解释如下： （1）至少多少个哨兵要一致同意，master进程挂掉了，或者slave进程挂掉了，或者要启动一个故障转移操作 （2）quorum是用来识别故障的，真正执行故障转移的时候，还是要在哨兵集群执行选举，选举一个哨兵进程出来执行故障转移操作 （3）假设有5个哨兵，quorum设置了2，那么如果5个哨兵中的2个都认为master挂掉了; 2个哨兵中的一个就会做一个选举，选举一个哨兵出来，执行故障转移; 如果5个哨兵中有3个哨兵都是运行的，那么故障转移就会被允许执行 down-after-milliseconds，超过多少毫秒跟一个redis实例断了连接，哨兵就可能认为这个redis实例挂了 parallel-syncs，新的master别切换之后，同时有多少个slave被切换到去连接新master，重新做同步，数字越低，花费的时间越多 假设你的redis是1个master，4个slave 然后master宕机了，4个slave中有1个切换成了master，剩下3个slave就要挂到新的master上面去 这个时候，如果parallel-syncs是1，那么3个slave，一个一个地挂接到新的master上面去，1个挂接完，而且从新的master sync完数据之后，再挂接下一个 如果parallel-syncs是3，那么一次性就会把所有slave挂接到新的master上去 failover-timeout，执行故障转移的timeout超时时长 在eshop-cache03上再部署一个redis只要安装redis就可以了，不需要去部署redis实例的启动 wget http://downloads.sourceforge.net/tcl/tcl8.6.1-src.tar.gz tar -xzvf tcl8.6.1-src.tar.gz cd /usr/local/tcl8.6.1/unix/ ./configure make &amp;&amp; make install 使用redis-3.2.8.tar.gz（截止2017年4月的最新稳定版） tar -zxvf redis-3.2.8.tar.gz cd redis-3.2.8 make &amp;&amp; make test make install 正式的配置哨兵默认用26379端口，默认不能跟其他机器在指定端口连通，只能在本地访问 mkdir /etc/sentinal mkdir -p /var/sentinal/5000 修改各个哨兵节点的/etc/sentinel/5000.conf配置文件第一个节点: port 5000 bind 192.168.31.187 dir /var/sentinal/5000 sentinel monitor mymaster 192.168.31.187 6379 2 sentinel down-after-milliseconds mymaster 30000 sentinel failover-timeout mymaster 60000 sentinel parallel-syncs mymaster 1 第二个节点: port 5000 bind 192.168.31.19 dir /var/sentinal/5000 sentinel monitor mymaster 192.168.31.187 6379 2 sentinel down-after-milliseconds mymaster 30000 sentinel failover-timeout mymaster 60000 sentinel parallel-syncs mymaster 1 第三个节点: port 5000 bind 192.168.31.227 dir /var/sentinal/5000 sentinel monitor mymaster 192.168.31.187 6379 2 sentinel down-after-milliseconds mymaster 30000 sentinel failover-timeout mymaster 60000 sentinel parallel-syncs mymaster 1 启动哨兵进程在eshop-cache01、eshop-cache02、eshop-cache03三台机器上，分别启动三个哨兵进程，组成一个集群，观察一下日志的输出 redis-sentinel /etc/sentinal/5000.conf redis-server /etc/sentinal/5000.conf --sentinel 日志里会显示出来，每个哨兵都能去监控到对应的redis master，并能够自动发现对应的slave 哨兵之间，互相会自动进行发现，用的就是之前说的pub/sub，消息发布和订阅channel消息系统和机制 检查哨兵状态redis-cli -h 192.168.31.187 -p 5000 sentinel master mymaster SENTINEL slaves mymaster SENTINEL sentinels mymaster SENTINEL get-master-addr-by-name mymaster","tags":[{"name":"redis","slug":"redis","permalink":"http://dennis.pathto.top/tags/redis/"}]},{"title":"4.redis哨兵核心原理","date":"2017-08-13T15:55:41.000Z","path":"2017/08/13/redis-4-sentinal-core-theory/","text":"sdown和odown转换机制master对于哨兵来说，有sdown和odown两种失败状态. sdown是主观宕机，就一个哨兵计算到到master宕机了，那么就是主观宕机。 odown是客观宕机，如果quorum数量的哨兵都觉得一个master宕机了，那么就是客观宕机。 sdown达成的条件很简单，如果一个哨兵ping一个master，超过了is-master-down-after-milliseconds指定的毫秒数之后，就主观认为master宕机 sdown到odown转换的条件很简单，如果一个哨兵在指定时间内，收到了quorum指定数量的其他哨兵也认为那个master是sdown了，那么就认为是odown了，客观认为master宕机 哨兵集群的自动发现机制哨兵互相之间的发现，是通过redis的pub/sub系统实现的，每个哨兵都会往sentinel:hello这个channel里发送一个消息，这时候所有其他哨兵都可以消费到这个消息，并感知到其他的哨兵的存在. 每隔两秒钟，每个哨兵都会往自己监控的某个master+slaves对应的sentinel:hello channel里发送一个消息，内容是自己的host、ip和runid还有对这个master的监控配置 每个哨兵也会去监听自己监控的每个master+slaves对应的sentinel:hello channel，然后去感知到同样在监听这个master+slaves的其他哨兵的存在 每个哨兵还会跟其他哨兵交换对master的监控配置，互相进行监控配置的同步 slave配置的自动纠正哨兵会负责自动纠正slave的一些配置，比如slave如果要成为潜在的master候选人，哨兵会确保其他slave在复制新的master的数据; 如果slave连接到了一个错误的master上，比如故障转移之后，那么哨兵会确保它们连接到正确的master上. master选举算法如果一个master被认为odown了，而且majority哨兵都允许了主备切换，那么某个哨兵就会执行主备切换操作，此时首先要选举一个slave来 会考虑slave的一些信息 跟master断开连接的时长 slave优先级 复制offset run id 如果一个slave跟master断开连接已经超过了down-after-milliseconds的10倍，外加master宕机的时长，那么slave就被认为不适合选举为master (down-after-milliseconds * 10) + milliseconds_since_master_is_in_SDOWN_state 接下来会对slave进行排序 按照slave优先级进行排序，slave priority越低，优先级就越高 如果slave priority相同，那么看replica offset，哪个slave复制了越多的数据，offset越靠后，优先级就越高 如果上面两个条件都相同，那么选择一个run id比较小的那个slave quorum和majority每次一个哨兵要做主备切换，首先需要quorum数量的哨兵认为odown，然后选举出一个哨兵来做切换，这个哨兵还得得到majority哨兵的授权，才能正式执行切换 如果quorum &lt; majority，比如5个哨兵，majority就是3，quorum设置为2，那么就3个哨兵授权就可以执行切换 但是如果quorum &gt;= majority，那么必须quorum数量的哨兵都授权，比如5个哨兵，quorum是5，那么必须5个哨兵都同意授权，才能执行切换 configuration epoch哨兵会对一套redis master+slave进行监控，有相应的监控的配置 执行切换的那个哨兵，会从要切换到的新master（salve-&gt;master）那里得到一个configuration epoch，这就是一个version号，每次切换的version号都必须是唯一的 如果第一个选举出的哨兵切换失败了，那么其他哨兵，会等待failover-timeout时间，然后下一个哨兵接替继续执行切换，此时会重新获取一个新的configuration epoch，作为新的version号 configuraiton传播哨兵完成切换之后，会在自己本地更新生成最新的master配置，然后同步给其他的哨兵，就是通过之前说的pub/sub消息机制 这里之前的version号就很重要了，因为各种消息都是通过一个channel去发布和监听的，所以一个哨兵完成一次新的切换之后，新的master配置是跟着新的version号的 其他的哨兵都是根据版本号的大小来更新自己的master配置的","tags":[{"name":"redis","slug":"redis","permalink":"http://dennis.pathto.top/tags/redis/"}]},{"title":"3.redis sentinal架构","date":"2017-08-13T15:54:35.000Z","path":"2017/08/13/redis-3-sentinal-framewaork/","text":"哨兵的介绍sentinal，中文名是哨兵 哨兵是redis集群架构中非常重要的一个组件，主要功能如下 集群监控，负责监控redis master和slave进程是否正常工作 消息通知，如果某个redis实例有故障，那么哨兵负责发送消息作为报警通知给管理员 故障转移，如果master node挂掉了，会自动转移到slave node上 配置中心，如果故障转移发生了，通知client客户端新的master地址 哨兵本身也是分布式的，作为一个哨兵集群去运行，互相协同工作 故障转移时，判断一个master node是宕机了，需要大部分的哨兵都同意才行，涉及到了分布式选举的问题 即使部分哨兵节点挂掉了，哨兵集群还是能正常工作的，因为如果一个作为高可用机制重要组成部分的故障转移系统本身是单点的，那就很坑爹了 目前采用的是sentinal 2版本，sentinal2相对于sentinal1来说，重写了很多代码，主要是让故障转移的机制和算法变得更加健壮和简单 哨兵的核心知识（1）哨兵至少需要3个实例，来保证自己的健壮性 （2）哨兵 + redis主从的部署架构，是不会保证数据零丢失的，只能保证redis集群的高可用性 （3）对于哨兵 + redis主从这种复杂的部署架构，尽量在测试环境和生产环境，都进行充足的测试和演练 为什么redis哨兵集群只有2个节点无法正常工作？哨兵集群必须部署2个以上节点 如果哨兵集群仅仅部署了个2个哨兵实例，quorum=1节点| 名称|描述—|—|—M1 | S1 | 运行master和slave node进程R1 | S2 | 运行slave node 进程 上图只有两个节点M1和R2 Configuration: quorum = 1 master宕机，s1和s2中只要有1个哨兵认为master宕机就可以还行切换，同时s1和s2中会选举出一个哨兵来执行故障转移 同时这个时候，需要majority，也就是大多数哨兵都是运行的，2个哨兵的majority就是2（2的majority=2，3的majority=2，5的majority=3，4的majority=2），2个哨兵都运行着，就可以允许执行故障转移 但是如果整个M1和S1运行的机器宕机了，那么哨兵只有1个了，此时就没有majority来允许执行故障转移，虽然另外一台机器还有一个R1，但是故障转移不会执行 经典的3节点哨兵集群 节点 名称 描述 M1 S1 运行master R2 S2 运行slave node 进程 R3 S3 运行slave node 进程 Configuration: quorum = 2，majority 如果M1所在机器宕机了，那么三个哨兵还剩下2个，S2和S3可以一致认为master宕机，然后选举出一个来执行故障转移 同时3个哨兵的majority是2，所以还剩下的2个哨兵运行着，就可以允许执行故障转移","tags":[{"name":"redis","slug":"redis","permalink":"http://dennis.pathto.top/tags/redis/"}]},{"title":"2.redis高可用","date":"2017-08-13T15:54:05.000Z","path":"2017/08/13/redis-2-high-availability/","text":"什么是99.99%高可用？架构上，高可用性，99.99%的高可用性讲的学术，99.99%，公式，系统可用的时间 / 系统故障的时间，365天，在365天 * 99.99%的时间内，你的系统都是可以哗哗对外提供服务的，那就是高可用性，99.99%系统可用的时间 / 总的时间 = 高可用性，然后会对各种时间的概念，说一大堆解释 redis不可用是什么？单实例不可用？主从架构不可用？不可用的后果是什么？master node挂掉之后，写缓存全部失效，master不在给slave node复制数据了，这时候就相当于不可用了. 注意：如果有多个slave node,一个slave node 挂了之后，不会影响可用性的。 redis怎么才能做到高可用？redis的高可用架构，就是做到了故障转移，failover叫做主备切换。redis集群的master挂了之后，如果能够在很短的时间内，把一个slave node 切换为master,就可以实现高可用了。高可用架构使用到了哨兵.","tags":[{"name":"redis","slug":"redis","permalink":"http://dennis.pathto.top/tags/redis/"}]},{"title":"1.redis读写分离搭建","date":"2017-08-13T15:52:56.000Z","path":"2017/08/13/redis-1-rw-separation-installation/","text":"redis读写分离的安装 安装tclwget http://downloads.sourceforge.net/tcl/tcl8.6.1-src.tar.gz tar -xzvf tcl8.6.1-src.tar.gz cd /usr/local/tcl8.6.1/unix/ ./configure make &amp;&amp; make install 安装redisredis的版本是3.2.8 tar -zxvf redis-3.2.8.tar.gz cd redis-3.2.8 make &amp;&amp; make test &amp;&amp; make install redis utils目录下，有个redis_init_script脚本 将redis_init_script脚本拷贝到linux的/etc/init.d目录中，将redis_init_script重命名为redis_6379，6379是我们希望这个redis实例监听的端口号 修改redis_6379脚本的第6行的REDISPORT，设置为相同的端口号（默认就是6379） 创建两个目录：/etc/redis（存放redis的配置文件），/var/redis/6379（存放redis的持久化文件） 修改redis配置文件（默认在根目录下，redis.conf），拷贝到/etc/redis目录中，修改名称为6379.conf 修改redis.conf daemonize yes 让redis以daemon进程运行 pidfile /var/run/redis_6379.pid 设置redis的pid文件位置 port 6379 设置redis的监听端口号 dir /var/redis/6379 设置持久化文件的存储位置 让redis跟随系统启动自动启动在redis_6379脚本中，最上面，加入两行注释 # chkconfig: 2345 90 10 # description: Redis is a persistent key-value database 开机启动 1chkconfig redis_6379 on 在slave node上配置：slaveof 192.168.1.1 6379，即可 也可以使用slaveof命令 强制读写分离基于主从复制架构，实现读写分离 redis slave node只读，默认开启，slave-read-only 开启了只读的redis slave node，会拒绝所有的写操作，这样可以强制搭建成读写分离的架构 集群安全认证master上启用安全认证，requirepassmaster连接口令，masterauth 读写分离架构的测试先启动主节点，再启动从节点 访问控制修改bindbind 127.0.0.1是本地的开发调试的模式，就只能127.0.0.1本地才能访问到6379的端口. 每个redis.conf中的bind 127.0.0.1是ind自己的ip地址 在每个节点上都: iptables -A INPUT -ptcp --dport 6379 -j ACCEPT redis-cli -h ipaddr info replication 完成读写分离架构的搭建之后，可以实现,在主节点上写，在从节点上读","tags":[{"name":"redis","slug":"redis","permalink":"http://dennis.pathto.top/tags/redis/"}]},{"title":"1.kubernetes安装","date":"2017-08-11T12:50:58.000Z","path":"2017/08/11/kubernetes-installation/","text":"环境介绍及准备物理机操作系统[root@master tmp]# cat /etc/redhat-release CentOS Linux release 7.2.1511 (Core) [root@master tmp]# uname -r 3.10.0-327.el7.x86_64 服务器信息 hostname ip master,etcd,registry 10.0.0.161 node01 10.0.0.159 node02 10.0.0.160 修改主机名master: [root@master ~]#hostnamectl --static set-hostname master node01: [root@node01 ~]# hostnamectl --static set-hostname node01 node02: [root@node02 ~]# hostnamectl --static set-hostname node02 集群全部服务器修改hosts配置文件,关闭防火墙cat &gt;&gt;/etc/hosts&lt;&lt;EOF 10.0.0.161 etcd 10.0.0.161 registry 10.0.0.159 node01 10.0.0.160 node02 10.0.0.161 master EOF systemctl disable firewalld.service systemctl stop firewalld.service 部署master安装etcd安装etcd[root@master tmp]# yum install etcd -y 修改/etc/etcd/etcd.conf# [member] ETCD_NAME=master ==ETCD_DATA_DIR=&quot;/var/lib/etcd/default.etcd&quot;== ETCD_LISTEN_CLIENT_URLS=&quot;http://0.0.0.0:2379,http://0.0.0.0:4001&quot; ETCD_ADVERTISE_CLIENT_URLS=&quot;http://etcd:2379,http://etcd:4001&quot; 验证etcd[root@master ~]# systemctl start etcd [root@master ~]# etcdctl set testdir/testkey0 0 0 [root@master ~]# etcdctl get testdir/testkey0 0 [root@master ~]# etcdctl -C http://etcd:4001 cluster-health member 8e9e05c52164694d is healthy: got healthy result from http://etcd:2379 cluster is healthy [root@master ~]# etcdctl -C http://etcd:2379 cluster-health member 8e9e05c52164694d is healthy: got healthy result from http://0.0.0.0:2379 cluster is healthy 安装Docker[root@master ~]# yum install docker 配置registry配置Docker配置文件，使其允许从registry中拉取镜像。 [root@master ~]# vim /etc/sysconfig/docker OPTIONS=&apos;--selinux-enabled --log-driver=journald --signature-verification=false&apos; if [ -z &quot;${DOCKER_CERT_PATH}&quot; ]; then DOCKER_CERT_PATH=/etc/docker fi OPTIONS=&apos;--insecure-registry registry:5000&apos; 配置docker服务[root@master ~]# chkconfig docker on [root@master ~]# service docker start 安装kubernets[root@master ~]# yum install kubernetes 配置kubernetes[root@master ~]#vi /etc/kubernetes/apiserver KUBE_API_ADDRESS=&quot;--insecure-bind-address=0.0.0.0&quot; KUBE_ETCD_SERVERS=&quot;--etcd-servers=http://etcd:2379&quot; KUBE_SERVICE_ADDRESSES=&quot;--service-cluster-ip-range=10.254.0.0/16&quot; KUBE_ADMISSION_CONTROL=&quot;--admission-control=NamespaceLifecycle,NamespaceExists,LimitRanger,SecurityContextDeny,ResourceQuota&quot; KUBE_API_ARGS=&quot;&quot; [root@master ~]# vi /etc/kubernetes/config KUBE_LOGTOSTDERR=&quot;--logtostderr=true&quot; KUBE_LOG_LEVEL=&quot;--v=0&quot; KUBE_ALLOW_PRIV=&quot;--allow-privileged=false&quot; KUBE_MASTER=&quot;--master=http://master:8080&quot; 启动kubernetes[root@master ~]# systemctl enable kube-apiserver.service [root@master ~]# systemctl start kube-apiserver.service [root@master ~]# systemctl enable kube-controller-manager.service [root@master ~]# systemctl start kube-controller-manager.service [root@master ~]# systemctl enable kube-scheduler.service [root@master ~]# systemctl start kube-scheduler.service 部署node安装docker 参见2.2 安装kubernets 参见2.3 配置并启动kubernetes 在kubernetes node上需要运行以下组件： Kubelet Kubernets Proxy 相应的要更改以下几个配置信息： [root@node01 ~]# vim /etc/kubernetes/config KUBE_LOGTOSTDERR=&quot;--logtostderr=true&quot; KUBE_LOG_LEVEL=&quot;--v=0&quot; KUBE_ALLOW_PRIV=&quot;--allow-privileged=false&quot; KUBE_MASTER=&quot;--master=http://master:8080&quot; [root@node01 ~] vim /etc/kubernetes/kubelet KUBELET_ADDRESS=&quot;--address=0.0.0.0&quot; KUBELET_HOSTNAME=&quot;--hostname-override=node01&quot; KUBELET_API_SERVER=&quot;--api-servers=http://master:8080&quot; KUBELET_POD_INFRA_CONTAINER=&quot;--pod-infra-container-image=registry.access.redhat.com/rhel7/pod-infrastructure:latest&quot; KUBELET_ARGS=&quot;&quot; 启动服务并设置开机自启动[root@master ~]# systemctl enable kubelet.service [root@master ~]# systemctl start kubelet.service [root@master ~]# systemctl enable kube-proxy.service [root@master ~]# systemctl start kube-proxy.service 查看状态 在master上查看集群中节点及节点状态 [root@master ~]# kubectl -s http://master:8080 get node NAME STATUS AGE node01 Ready 3m node02 Ready 16s [root@master ~]# kubectl get nodes NAME STATUS AGE node01 Ready 3m node02 Ready 43s 至此，已经搭建了一个kubernetes集群，但目前该集群还不能很好的工作，请继续后续的步骤。 创建覆盖网络——Flannel安装Flannel在master、node上均执行如下命令，进行安装 [root@master ~]# yum install flannel 配置Flannelmaster、node上均修改/etc/sysconfig/flanneld [root@master ~]# vi /etc/sysconfig/flanneld FLANNEL_ETCD_ENDPOINTS=&quot;http://etcd:2379&quot; FLANNEL_ETCD_PREFIX=&quot;/atomic.io/network&quot; 配置etcd中关于flannel的key Flannel使用Etcd进行配置，来保证多个Flannel实例之间的配置一致性，所以需要在etcd上进行如下配置：（‘/atomic.io/network/config’这个key与上文/etc/sysconfig/flannel中的配置项FLANNEL_ETCD_PREFIX是相对应的，错误的话启动就会出错） [root@master ~]# etcdctl mk /atomic.io/network/config &apos;{ &quot;Network&quot;: &quot;10.0.0.0/16&quot; }&apos; { &quot;Network&quot;: &quot;10.0.0.0/16&quot; } 启动 启动Flannel之后，需要依次重启docker、kubernete。 在master执行： systemctl enable flanneld.service systemctl start flanneld.service service docker restart systemctl restart kube-apiserver.service systemctl restart kube-controller-manager.service systemctl restart kube-scheduler.service 在node上执行： systemctl enable flanneld.service systemctl start flanneld.service service docker restart systemctl restart kubelet.service systemctl restart kube-proxy.service 安装dashboard拉取docker镜像12docker pull registry.cn-hangzhou.aliyuncs.com/google-containers/kubernetes-dashboard-amd64:v1.6.0docker pull registry.access.redhat.com/rhel7/pod-infrastructure:latest 修改docker镜像的tag1docker tag registry.cn-hangzhou.aliyuncs.com/google-containers/kubernetes-dashboard-amd64:v1.6.0 gcr.io/google_containers/kubernetes-dashboard-amd64:v1.6.0 查看docker镜像[root@master tmp]# docker images REPOSITORY TAG IMAGE ID CREATED SIZE registry.access.redhat.com/rhel7/pod-infrastructure latest f66f4bd9b894 8 weeks ago 205.8 MB gcr.io/google_containers/kubernetes-dashboard-amd64 v1.6.0 416701f962f2 4 months ago 108.6 MB registry.cn-hangzhou.aliyuncs.com/google-containers/kubernetes-dashboard-amd64 v1.6.0 416701f962f2 4 months ago 108.6 MB [root@master tmp]#docker save registry.cn-hangzhou.aliyuncs.com/google-containers/kubernetes-dashboard-amd64 &gt; dashboard.tar [root@master tmp]#docker save registry.access.redhat.com/rhel7/pod-infrastructure &gt; podinfrastructure.tar 复制docker到node01/node02[root@master tmp]scp podinfrastructure.tar node01:~ [root@master tmp]scp podinfrastructure.tar node02:~ [root@master tmp]scp dashboard.tar node01:~ [root@master tmp]scp dashboard.tar node02:~ node01/node02生成docker镜像 docker load &lt; dashboard.tar docker load &lt; podinfrastructure.tar 配置dashboardcat &gt;dashboard.yaml&lt;&lt;EOF apiVersion: extensions/v1beta1 kind: Deployment metadata: # Keep the name in sync with image version and # gce/coreos/kube-manifests/addons/dashboard counterparts name: kubernetes-dashboard-latest namespace: kube-system spec: replicas: 1 template: metadata: labels: k8s-app: kubernetes-dashboard version: latest kubernetes.io/cluster-service: &quot;true&quot; spec: containers: - name: kubernetes-dashboard image: gcr.io/google_containers/kubernetes-dashboard-amd64:v1.6.0 resources: # keep request = limit to keep this container in guaranteed class limits: cpu: 100m memory: 50Mi requests: cpu: 100m memory: 50Mi ports: - containerPort: 9090 args: - --apiserver-host=http://10.0.0.161:8080 livenessProbe: httpGet: path: / port: 9090 initialDelaySeconds: 30 timeoutSeconds: 30 EOF cat &gt;dashboardsvc.yaml&lt;&lt;EOF apiVersion: v1 kind: Service metadata: name: kubernetes-dashboard namespace: kube-system labels: k8s-app: kubernetes-dashboard kubernetes.io/cluster-service: &quot;true&quot; spec: selector: k8s-app: kubernetes-dashboard ports: - port: 80 targetPort: 9090 EOF kubectl create -f dashboard.yaml kubectl create -f dashboardsvc.yaml 验证dashboard[root@master tmp]# kubectl get deployment --all-namespaces NAMESPACE NAME DESIRED CURRENT UP-TO-DATE AVAILABLE AGE kube-system kubernetes-dashboard-latest 1 1 1 1 1h [root@master tmp]# kubectl get svc --all-namespaces NAMESPACE NAME CLUSTER-IP EXTERNAL-IP PORT(S) AGE default kubernetes 10.0.0.1 &lt;none&gt; 443/TCP 3h kube-system kubernetes-dashboard 10.254.161.116 &lt;none&gt; 80/TCP 1h [root@master tmp]# kubectl get pod -o wide --all-namespaces NAMESPACE NAME READY STATUS RESTARTS AGE IP NODE kube-system kubernetes-dashboard-latest-2587589530-czkq5 1/1 Running 0 1h 10.0.7.2 node02 浏览http://10.0.0.161:8080/ui image","tags":[{"name":"docker","slug":"docker","permalink":"http://dennis.pathto.top/tags/docker/"},{"name":"cloud","slug":"cloud","permalink":"http://dennis.pathto.top/tags/cloud/"},{"name":"kubernetes","slug":"kubernetes","permalink":"http://dennis.pathto.top/tags/kubernetes/"},{"name":"container","slug":"container","permalink":"http://dennis.pathto.top/tags/container/"},{"name":"virtualization","slug":"virtualization","permalink":"http://dennis.pathto.top/tags/virtualization/"}]},{"title":"4.zookeeper-原理","date":"2017-08-08T15:38:48.000Z","path":"2017/08/08/4-zookeeper-principle/","text":"zookeeper原理 Zookeeper虽然在配置文件中并没有指定master和slave,但是，zookeeper工作时，是有一个节点为leader，其他则为follower,Leader是通过内部的选举机制临时产生的. zookeeper的选举机制（全新集群paxos）以一个简单的例子来说明整个选举的过程.假设有五台服务器组成的zookeeper集群,它们的id从1-5,同时它们都是最新启动的,也就是没有历史数据,在存放数据量这一点上,都是一样的.假设这些服务器依序启动,来看看会发生什么. 1) 服务器1启动,此时只有它一台服务器启动了,它发出去的报没有任何响应,所以它的选举状态一直是LOOKING状态 2) 服务器2启动,它与最开始启动的服务器1进行通信,互相交换自己的选举结果,由于两者都没有历史数据,所以id值较大的服务器2胜出,但是由于没有达到超过半数以上的服务器都同意选举它(这个例子中的半数以上是3),所以服务器1,2还是继续保持LOOKING状态. 3) 服务器3启动,根据前面的理论分析,服务器3成为服务器1,2,3中的老大,而与上面不同的是,此时有三台服务器选举了它,所以它成为了这次选举的leader. 4) 服务器4启动,根据前面的分析,理论上服务器4应该是服务器1,2,3,4中最大的,但是由于前面已经有半数以上的服务器选举了服务器3,所以它只能接收当小弟的命了. 5) 服务器5启动,同4一样,当小弟. 非全新集群的选举机制(数据恢复)那么，初始化的时候，是按照上述的说明进行选举的，但是当zookeeper运行了一段时间之后，有机器down掉，重新选举时，选举过程就相对复杂了。需要加入数据id、leader id和逻辑时钟。 数据id：数据新的id就大，数据每次更新都会更新id。 Leader id：就是我们配置的myid中的值，每个机器一个。 逻辑时钟：这个值从0开始递增,每次选举对应一个值,也就是说: 如果在同一次选举中,那么这个值应该是一致的 ; 逻辑时钟值越大,说明这一次选举leader的进程更新. 选举的标准就变成： 逻辑时钟小的选举结果被忽略，重新投票 统一逻辑时钟后，数据id大的胜出 数据id相同的情况下，leader id大的胜出,根据这个规则选出leader。","tags":[{"name":"zookeeper","slug":"zookeeper","permalink":"http://dennis.pathto.top/tags/zookeeper/"},{"name":"distributed","slug":"distributed","permalink":"http://dennis.pathto.top/tags/distributed/"}]},{"title":"3.zookeeper-使用","date":"2017-08-08T15:38:13.000Z","path":"2017/08/08/3-zookeeper-usage/","text":"zookeeper特性1、 Zookeeper：一个leader，多个follower组成的集群 2、全局数据一致：每个server保存一份相同的数据副本，client无论连接到哪个server，数据都是一致的 3、分布式读写，更新请求转发，由leader实施 4、更新请求顺序进行，来自同一个client的更新请求按其发送顺序依次执行 5、数据更新原子性，一次数据更新要么成功，要么失败 6、实时性，在一定时间范围内，client能读到最新数据 zookeeper数据结构1、层次化的目录结构，命名符合常规文件系统规范(见下图) 2、每个节点在zookeeper中叫做znode,并且其有一个唯一的路径标识 3、节点Znode可以包含数据和子节点（但是EPHEMERAL类型的节点不能有子节点，下一页详细讲解） 4、客户端应用可以在节点上设置监视器（后续详细讲解） 数据结构的图 节点类型Znode有两种类型： 短暂（ephemeral）（断开连接自己删除） 持久（persistent）（断开连接不删除） 2、Znode有四种形式的目录节点（默认是persistent ） PERSISTENT PERSISTENT_SEQUENTIAL（持久序列/test0000000019 ） EPHEMERAL EPHEMERAL_SEQUENTIAL 3、创建znode时设置顺序标识，znode名称后会附加一个值，顺序号是一个单调递增的计数器，由父节点维护 4、在分布式系统中，顺序号可以被用于为所有的事件进行全局排序，这样客户端可以通过顺序号推断事件的顺序 zookeeper命令行操作运行 zkCli.sh –server 进入命令行工具 1、使用 ls 命令来查看当前 ZooKeeper 中所包含的内容： [zk: study0:2181(CONNECTED) 1] ls / 2、创建一个新的 znode ，使用 create /zk myData 。这个命令创建了一个新的 znode 节点“ zk ”以及与它关联的字符串： [zk: study0:2181(CONNECTED) 2] create /zk &quot;myData&quot; 3、我们运行 get 命令来确认 znode 是否包含我们所创建的字符串： [zk: study0:2181(CONNECTED) 3] get /zk 监听这个节点的变化,当另外一个客户端改变/zk时,它会打出下面的 WATCHER::WatchedEvent state:SyncConnected type:NodeDataChanged path:/zk [zk: study0:2181(CONNECTED) 4] get /zk watch 4、下面我们通过 set 命令来对 zk 所关联的字符串进行设置： [zk: study0:2181(CONNECTED) 4] set /zk &quot;zsl&quot; 5、下面我们将刚才创建的 znode 删除： [zk: study0:2181(CONNECTED) 5] delete /zk 6、删除节点：rmr [zk: study0:2181(CONNECTED) 5] rmr /zk zookeeper-api应用基本使用org.apache.zookeeper.Zookeeper是客户端入口主类，负责建立与server的会话它提供了表 1 所示几类主要方法： 表1：ZooKeeper API描述 demo增删改查public class SimpleDemo { // 会话超时时间，设置为与系统默认时间一致 private static final int SESSION_TIMEOUT = 30000; // 创建 ZooKeeper 实例 ZooKeeper zk; // 创建 Watcher 实例 Watcher wh = new Watcher() { public void process(org.apache.zookeeper.WatchedEvent event) { System.out.println(event.toString()); } }; // 初始化 ZooKeeper 实例 private void createZKInstance() throws IOException { zk = new ZooKeeper(&quot;weekend01:2181&quot;, SimpleDemo.SESSION_TIMEOUT, this.wh); } private void ZKOperations() throws IOException, InterruptedException, KeeperException { System.out.println(&quot;/n1. 创建 ZooKeeper 节点 (znode ： zoo2, 数据： myData2 ，权限： OPEN_ACL_UNSAFE ，节点类型： Persistent&quot;); zk.create(&quot;/zoo2&quot;, &quot;myData2&quot;.getBytes(), Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT); System.out.println(&quot;/n2. 查看是否创建成功： &quot;); System.out.println(new String(zk.getData(&quot;/zoo2&quot;, false, null))); System.out.println(&quot;/n3. 修改节点数据 &quot;); zk.setData(&quot;/zoo2&quot;, &quot;shenlan211314&quot;.getBytes(), -1); System.out.println(&quot;/n4. 查看是否修改成功： &quot;); System.out.println(new String(zk.getData(&quot;/zoo2&quot;, false, null))); System.out.println(&quot;/n5. 删除节点 &quot;); zk.delete(&quot;/zoo2&quot;, -1); System.out.println(&quot;/n6. 查看节点是否被删除： &quot;); System.out.println(&quot; 节点状态： [&quot; + zk.exists(&quot;/zoo2&quot;, false) + &quot;]&quot;); } private void ZKClose() throws InterruptedException { zk.close(); } public static void main(String[] args) throws IOException, InterruptedException, KeeperException { SimpleDemo dm = new SimpleDemo(); dm.createZKInstance(); dm.ZKOperations(); dm.ZKClose(); } } Zookeeper的监听器工作机制 监听器是一个接口，我们的代码中可以实现Wather这个接口，实现其中的process方法，方法中即我们自己的业务逻辑。 监听器的注册是在获取数据的操作中实现： getData(path,watch)监听的事件是：节点数据变化事件 getChildren(path,watch)监听的事件是：节点下的子节点增减变化事件 zookeeper应用案例分布式应用HA||分布式锁 实现分布式应用的(主节点HA)及客户端动态更新主节点状态某分布式系统中，主节点可以有多台，可以动态上下线 任意一台客户端都能实时感知到主节点服务器的上下线 客户端实现 public class AppClient { private String groupNode = &quot;sgroup&quot;; private ZooKeeper zk; private Stat stat = new Stat(); private volatile List&lt;String&gt; serverList; /** * 连接zookeeper */ public void connectZookeeper() throws Exception { zk = new ZooKeeper(&quot;localhost:4180,localhost:4181,localhost:4182&quot;, 5000, new Watcher() { public void process(WatchedEvent event) { // 如果发生了&quot;/sgroup&quot;节点下的子节点变化事件, 更新server列表, 并重新注册监听 if (event.getType() == EventType.NodeChildrenChanged &amp;&amp; (&quot;/&quot; + groupNode).equals(event.getPath())) { try { updateServerList(); } catch (Exception e) { e.printStackTrace(); } } } }); updateServerList(); } /** * 更新server列表 */ private void updateServerList() throws Exception { List&lt;String&gt; newServerList = new ArrayList&lt;String&gt;(); // 获取并监听groupNode的子节点变化 // watch参数为true, 表示监听子节点变化事件. // 每次都需要重新注册监听, 因为一次注册, 只能监听一次事件, 如果还想继续保持监听, 必须重新注册 List&lt;String&gt; subList = zk.getChildren(&quot;/&quot; + groupNode, true); for (String subNode : subList) { // 获取每个子节点下关联的server地址 byte[] data = zk.getData(&quot;/&quot; + groupNode + &quot;/&quot; + subNode, false, stat); newServerList.add(new String(data, &quot;utf-8&quot;)); } // 替换server列表 serverList = newServerList; System.out.println(&quot;server list updated: &quot; + serverList); } /** * client的工作逻辑写在这个方法中 * 此处不做任何处理, 只让client sleep */ public void handle() throws InterruptedException { Thread.sleep(Long.MAX_VALUE); } public static void main(String[] args) throws Exception { AppClient ac = new AppClient(); ac.connectZookeeper(); ac.handle(); } } 服务器端实现 public class AppServer { private String groupNode = &quot;sgroup&quot;; private String subNode = &quot;sub&quot;; /** * 连接zookeeper * @param address server的地址 */ public void connectZookeeper(String address) throws Exception { ZooKeeperzk = new ZooKeeper( &quot;localhost:4180,localhost:4181,localhost:4182&quot;, 5000, new Watcher() { public void process(WatchedEvent event) { // 不做处理 } }); // 在&quot;/sgroup&quot;下创建子节点 // 子节点的类型设置为EPHEMERAL_SEQUENTIAL, 表明这是一个临时节点, 且在子节点的名称后面加上一串数字后缀 // 将server的地址数据关联到新创建的子节点上 String createdPath = zk.create(&quot;/&quot; + groupNode + &quot;/&quot; + subNode, address.getBytes(&quot;utf-8&quot;), Ids.OPEN_ACL_UNSAFE, CreateMode.EPHEMERAL_SEQUENTIAL); System.out.println(&quot;create: &quot; + createdPath); } /** * server的工作逻辑写在这个方法中 * 此处不做任何处理, 只让server sleep */ public void handle() throws InterruptedException { Thread.sleep(Long.MAX_VALUE); } public static void main(String[] args) throws Exception { // 在参数中指定server的地址 if (args.length == 0) { System.err.println(&quot;The first argument must be server address&quot;); System.exit(1); } AppServer as = new AppServer(); as.connectZookeeper(args[0]); as.handle(); } } 分布式共享锁的简单实现客户端A public class DistributedClient { // 超时时间 private static final int SESSION_TIMEOUT = 5000; // zookeeper server列表 private String hosts = &quot;localhost:4180,localhost:4181,localhost:4182&quot;; private String groupNode = &quot;locks&quot;; private String subNode = &quot;sub&quot;; private ZooKeeper zk; // 当前client创建的子节点 private String thisPath; // 当前client等待的子节点 private String waitPath; private CountDownLatch latch = new CountDownLatch(1); /** * 连接zookeeper */ public void connectZookeeper() throws Exception { zk = new ZooKeeper(hosts, SESSION_TIMEOUT, new Watcher() { public void process(WatchedEvent event) { try { // 连接建立时, 打开latch, 唤醒wait在该latch上的线程 if (event.getState() == KeeperState.SyncConnected) { latch.countDown(); } // 发生了waitPath的删除事件 if (event.getType() == EventType.NodeDeleted &amp;&amp; event.getPath().equals(waitPath)) { doSomething(); } } catch (Exception e) { e.printStackTrace(); } } }); // 等待连接建立 latch.await(); // 创建子节点 thisPath = zk.create(&quot;/&quot; + groupNode + &quot;/&quot; + subNode, null, Ids.OPEN_ACL_UNSAFE, CreateMode.EPHEMERAL_SEQUENTIAL); // wait一小会, 让结果更清晰一些 Thread.sleep(10); // 注意, 没有必要监听&quot;/locks&quot;的子节点的变化情况 List&lt;String&gt; childrenNodes = zk.getChildren(&quot;/&quot; + groupNode, false); // 列表中只有一个子节点, 那肯定就是thisPath, 说明client获得锁 if (childrenNodes.size() == 1) { doSomething(); } else { String thisNode = thisPath.substring((&quot;/&quot; + groupNode + &quot;/&quot;).length()); // 排序 Collections.sort(childrenNodes); int index = childrenNodes.indexOf(thisNode); if (index == -1) { // never happened } else if (index == 0) { // inddx == 0, 说明thisNode在列表中最小, 当前client获得锁 doSomething(); } else { // 获得排名比thisPath前1位的节点 this.waitPath = &quot;/&quot; + groupNode + &quot;/&quot; + childrenNodes.get(index - 1); // 在waitPath上注册监听器, 当waitPath被删除时, zookeeper会回调监听器的process方法 zk.getData(waitPath, true, new Stat()); } } } private void doSomething() throws Exception { try { System.out.println(&quot;gain lock: &quot; + thisPath); Thread.sleep(2000); // do something } finally { System.out.println(&quot;finished: &quot; + thisPath); // 将thisPath删除, 监听thisPath的client将获得通知 // 相当于释放锁 zk.delete(this.thisPath, -1); } } public static void main(String[] args) throws Exception { for (int i = 0; i &lt; 10; i++) { new Thread() { public void run() { try { DistributedClient dl = new DistributedClient(); dl.connectZookeeper(); } catch (Exception e) { e.printStackTrace(); } } }.start(); } Thread.sleep(Long.MAX_VALUE); } } 分布式多进程模式实现 public class DistributedClientMy { // 超时时间 private static final int SESSION_TIMEOUT = 5000; // zookeeper server列表 private String hosts = &quot;spark01:2181,spark02:2181,spark03:2181&quot;; private String groupNode = &quot;locks&quot;; private String subNode = &quot;sub&quot;; private boolean haveLock = false; private ZooKeeper zk; // 当前client创建的子节点 private volatile String thisPath; /** * 连接zookeeper */ public void connectZookeeper() throws Exception { zk = new ZooKeeper(&quot;spark01:2181&quot;, SESSION_TIMEOUT, new Watcher() { public void process(WatchedEvent event) { try { // 子节点发生变化 if (event.getType() == EventType.NodeChildrenChanged &amp;&amp; event.getPath().equals(&quot;/&quot; + groupNode)) { // thisPath是否是列表中的最小节点 List&lt;String&gt; childrenNodes = zk.getChildren(&quot;/&quot; + groupNode, true); String thisNode = thisPath.substring((&quot;/&quot; + groupNode + &quot;/&quot;).length()); // 排序 Collections.sort(childrenNodes); if (childrenNodes.indexOf(thisNode) == 0) { doSomething(); thisPath = zk.create(&quot;/&quot; + groupNode + &quot;/&quot; + subNode, null, Ids.OPEN_ACL_UNSAFE, CreateMode.EPHEMERAL_SEQUENTIAL); } } } catch (Exception e) { e.printStackTrace(); } } }); // 创建子节点 thisPath = zk.create(&quot;/&quot; + groupNode + &quot;/&quot; + subNode, null, Ids.OPEN_ACL_UNSAFE, CreateMode.EPHEMERAL_SEQUENTIAL); // wait一小会, 让结果更清晰一些 Thread.sleep(new Random().nextInt(1000)); // 监听子节点的变化 List&lt;String&gt; childrenNodes = zk.getChildren(&quot;/&quot; + groupNode, true); // 列表中只有一个子节点, 那肯定就是thisPath, 说明client获得锁 if (childrenNodes.size() == 1) { doSomething(); thisPath = zk.create(&quot;/&quot; + groupNode + &quot;/&quot; + subNode, null, Ids.OPEN_ACL_UNSAFE, CreateMode.EPHEMERAL_SEQUENTIAL); } } /** * 共享资源的访问逻辑写在这个方法中 */ private void doSomething() throws Exception { try { System.out.println(&quot;gain lock: &quot; + thisPath); Thread.sleep(2000); // do something } finally { System.out.println(&quot;finished: &quot; + thisPath); // 将thisPath删除, 监听thisPath的client将获得通知 // 相当于释放锁 zk.delete(this.thisPath, -1); } } public static void main(String[] args) throws Exception { DistributedClientMy dl = new DistributedClientMy(); dl.connectZookeeper(); Thread.sleep(Long.MAX_VALUE); } }","tags":[{"name":"zookeeper","slug":"zookeeper","permalink":"http://dennis.pathto.top/tags/zookeeper/"},{"name":"distributed","slug":"distributed","permalink":"http://dennis.pathto.top/tags/distributed/"}]},{"title":"2.zookeeper-安装","date":"2017-08-08T15:37:54.000Z","path":"2017/08/08/2-zookeeper-install/","text":"安装机器部署 准备3台linxu服务器 安装好JDK 上传可以使用sftp上传jdk,zookeeper到linux系统中 解压tar -zxvf zookeeper-3.4.5.tar.gz 重命名重命名文件夹zookeeper-3.4.5为zookeeper mv zookeeper-3.4.5 zookeeper 修改环境变量su – root vi /etc/profile 添加内容 export ZOOKEEPER_HOME=/home/hadoop/zookeeper export PATH=$PATH:$ZOOKEEPER_HOME/bin 重新编译文件source /etc/profile 注意：3台zookeeper都需要修改 修改配置文件cd zookeeper/conf cp zoo_sample.cfgzoo.cfg vi zoo.cfg 添加内容 ataDir=/home/hadoop/zookeeper/data dataLogDir=/home/hadoop/zookeeper/log server.1=slave1:2888:3888 server.2=slave2:2888:3888 server.3=slave3:2888:3888 创建文件夹cd /home/hadoop/zookeeper/ mkdir -m 755 data mkdir -m 755 log 在data文件夹下新建myid文件，myid的文件内容为cd data vi myid 添加内容：1 将集群下发到其他机器上scp -r /home/hadoop/zookeeper hadoop@slave2:/home/hadoop/ scp -r /home/hadoop/zookeeper hadoop@slave3:/home/hadoop/ 修改其他机器的配置文件到slave2上：修改myid为：2到slave3上：修改myid为：3 启动每台机器 zkServer.sh start 查看集群状态jps zkServer.sh status","tags":[{"name":"zookeeper","slug":"zookeeper","permalink":"http://dennis.pathto.top/tags/zookeeper/"},{"name":"distributed","slug":"distributed","permalink":"http://dennis.pathto.top/tags/distributed/"}]},{"title":"1.zookeeper-介绍","date":"2017-08-08T15:34:43.000Z","path":"2017/08/08/1-zookeeper-introduce/","text":"Zookeeper简介Zookeeper是一个分布式协调服务；就是为用户的分布式应用程序提供协调服务。 zookeeper是为别的分布式程序服务的 Zookeeper本身就是一个分布式程序（只要有半数以上节点存活，zk就能正常服务） Zookeeper所提供的服务涵盖：主从协调、服务器节点动态上下线、统一配置管理、分布式共享锁、统一名称服务……虽然说可以提供各种服务，但是zookeeper在底层其实只提供了两个功能： 管理(存储，读取)用户程序提交的数据；并为用户程序提供数据节点监听服务； Zookeeper常用应用场景数据发布与订阅（配置中心)发布与订阅模型，即所谓的配置中心，顾名思义就是发布者将数据发布到ZK节点上，供订阅者动态获取数据，实现配置信息的集中式管理和动态更新。例如全局的配置信息，服务式服务框架的服务地址列表等就非常适合使用。 应用中用到的一些配置信息放到ZK上进行集中管理。这类场景通常是这样：应用在启动的时候会主动来获取一次配置，同时，在节点上注册一个Watcher，这样一来，以后每次配置有更新的时候，都会实时通知到订阅的客户端，从来达到获取最新配置信息的目的。 分布式搜索服务中，索引的元信息和服务器集群机器的节点状态存放在ZK的一些指定节点，供各个客户端订阅使用。 分布式日志收集系统。这个系统的核心工作是收集分布在不同机器的日志。收集器通常是按照应用来分配收集任务单元，因此需要在ZK上创建一个以应用名作为path的节点P，并将这个应用的所有机器ip，以子节点的形式注册到节点P上，这样一来就能够实现机器变动的时候，能够实时通知到收集器调整任务分配。 系统中有些信息需要动态获取，并且还会存在人工手动去修改这个信息的发问。通常是暴露出接口，例如JMX接口，来获取一些运行时的信息。引入ZK之后，就不用自己实现一套方案了，只要将这些信息存放到指定的ZK节点上即可。 注意：在上面提到的应用场景中，有个默认前提是：数据量很小，但是数据更新可能会比较快的场景。 负载均衡这里说的负载均衡是指软负载均衡。在分布式环境中，为了保证高可用性，通常同一个应用或同一个服务的提供方都会部署多份，达到对等服务。而消费者就须要在这些对等的服务器中选择一个来执行相关的业务逻辑，其中比较典型的是消息中间件中的生产者，消费者负载均衡。 消息中间件中发布者和订阅者的负载均衡，linkedin开源的KafkaMQ和阿里开源的metaq都是通过zookeeper来做到生产者、消费者的负载均衡。这里以metaq为例如讲下： 生产者负载均衡：metaq发送消息的时候，生产者在发送消息的时候必须选择一台broker上的一个分区来发送消息，因此metaq在运行过程中，会把所有broker和对应的分区信息全部注册到ZK指定节点上，默认的策略是一个依次轮询的过程，生产者在通过ZK获取分区列表之后，会按照brokerId和partition的顺序排列组织成一个有序的分区列表，发送的时候按照从头到尾循环往复的方式选择一个分区来发送消息。 消费负载均衡：在消费过程中，一个消费者会消费一个或多个分区中的消息，但是一个分区只会由一个消费者来消费。 MetaQ的消费策略是： 每个分区针对同一个group只挂载一个消费者。 如果同一个group的消费者数目大于分区数目，则多出来的消费者将不参与消费。 如果同一个group的消费者数目小于分区数目，则有部分消费者需要额外承担消费任务。在某个消费者故障或者重启等情况下，其他消费者会感知到这一变化（通过 zookeeper watch消费者列表），然后重新进行负载均衡，保证所有的分区都有消费者进行消费。 命名服务(Naming Service)命名服务也是分布式系统中比较常见的一类场景。在分布式系统中，通过使用命名服务，客户端应用能够根据指定名字来获取资源或服务的地址，提供者等信息。被命名的实体通常可以是集群中的机器，提供的服务地址，远程对象等等——这些我们都可以统称他们为名字（Name）。其中较为常见的就是一些分布式服务框架中的服务地址列表。通过调用ZK提供的创建节点的API，能够很容易创建一个全局唯一的path，这个path就可以作为一个名称。 阿里巴巴集团开源的分布式服务框架Dubbo中使用ZooKeeper来作为其命名服务，维护全局的服务地址列表 在Dubbo实现中： 服务提供者在启动的时候，向ZK上的指定节点/dubbo/${serviceName}/providers目录下写入自己的URL地址，这个操作就完成了服务的发布。 服务消费者启动的时候，订阅/dubbo/${serviceName}/providers目录下的提供者URL地址， 并向/dubbo/${serviceName} /consumers目录下写入自己的URL地址。 注意，所有向ZK上注册的地址都是临时节点，这样就能够保证服务提供者和消费者能够自动感应资源的变化。另外，Dubbo还有针对服务粒度的监控，方法是订阅/dubbo/${serviceName}目录下所有提供者和消费者的信息。 分布式通知/协调ZooKeeper中特有watcher注册与异步通知机制，能够很好的实现分布式环境下不同系统之间的通知与协调，实现对数据变更的实时处理。使用方法通常是不同系统都对ZK上同一个znode进行注册，监听znode的变化（包括znode本身内容及子节点的），其中一个系统update了znode，那么另一个系统能够收到通知，并作出相应处理 另一种心跳检测机制：检测系统和被检测系统之间并不直接关联起来，而是通过zk上某个节点关联，大大减少系统耦合。 另一种系统调度模式：某系统有控制台和推送系统两部分组成，控制台的职责是控制推送系统进行相应的推送工作。管理人员在控制台作的一些操作，实际上是修改了ZK上某些节点的状态，而ZK就把这些变化通知给他们注册Watcher的客户端，即推送系统，于是，作出相应的推送任务。 另一种工作汇报模式：一些类似于任务分发系统，子任务启动后，到zk来注册一个临时节点，并且定时将自己的进度进行汇报（将进度写回这个临时节点），这样任务管理者就能够实时知道任务进度。 总之，使用zookeeper来进行分布式通知和协调能够大大降低系统之间的耦合 集群管理与Master选举集群机器监控 这通常用于那种对集群中机器状态，机器在线率有较高要求的场景，能够快速对集群中机器变化作出响应。这样的场景中，往往有一个监控系统，实时检测集群机器是否存活。过去的做法通常是：监控系统通过某种手段（比如ping）定时检测每个机器，或者每个机器自己定时向监控系统汇报“我还活着”。 这种做法可行，但是存在两个比较明显的问题： 集群中机器有变动的时候，牵连修改的东西比较多。有一定的延时。 利用ZooKeeper有两个特性，就可以实时另一种集群机器存活性监控系统 客户端在节点 x 上注册一个Watcher，那么如果 x的子节点变化了，会通知该客户端。 创建EPHEMERAL类型的节点，一旦客户端和服务器的会话结束或过期，那么该节点就会消失。例如，监控系统在 /clusterServers 节点上注册一个Watcher，以后每动态加机器，那么就往 /clusterServers 下创建一个 EPHEMERAL类型的节点：/clusterServers/{hostname}. 这样，监控系统就能够实时知道机器的增减情况，至于后续处理就是监控系统的业务了。 Master选举则是zookeeper中最为经典的应用场景了 在分布式环境中，相同的业务应用分布在不同的机器上，有些业务逻辑（例如一些耗时的计算，网络I/O处理），往往只需要让整个集群中的某一台机器进行执行，其余机器可以共享这个结果，这样可以大大减少重复劳动，提高性能，于是这个master选举便是这种场景下的碰到的主要问题。 利用ZooKeeper的强一致性，能够保证在分布式高并发情况下节点创建的全局唯一性，即：同时有多个客户端请求创建 /currentMaster 节点，最终一定只有一个客户端请求能够创建成功。利用这个特性，就能很轻易的在分布式环境中进行集群选取了。 另外，这种场景演化一下，就是动态Master选举。这就要用到?EPHEMERAL_SEQUENTIAL类型节点的特性了。 上文中提到，所有客户端创建请求，最终只有一个能够创建成功。在这里稍微变化下，就是允许所有请求都能够创建成功，但是得有个创建顺序，于是所有的请求最终在ZK上创建结果的一种可能情况是这样： /currentMaster/{sessionId}-1 ,?/currentMaster/{sessionId}-2 ,?/currentMaster/{sessionId}-3 ….. 每次选取序列号最小的那个机器作为Master，如果这个机器挂了，由于他创建的节点会马上小时，那么之后最小的那个机器就是Master了。 在搜索系统中，如果集群中每个机器都生成一份全量索引，不仅耗时，而且不能保证彼此之间索引数据一致。因此让集群中的Master来进行全量索引的生成，然后同步到集群中其它机器。另外，Master选举的容灾措施是，可以随时进行手动指定master，就是说应用在zk在无法获取master信息时，可以通过比如http方式，向一个地方获取master。 在Hbase中，也是使用ZooKeeper来实现动态HMaster的选举。在Hbase实现中，会在ZK上存储一些ROOT表的地址和HMaster的地址，HRegionServer也会把自己以临时节点（Ephemeral）的方式注册到Zookeeper中，使得HMaster可以随时感知到各个HRegionServer的存活状态，同时，一旦HMaster出现问题，会重新选举出一个HMaster来运行，从而避免了HMaster的单点问题 分布式锁分布式锁，这个主要得益于ZooKeeper为我们保证了数据的强一致性。锁服务可以分为两类，一个是保持独占，另一个是控制时序。 所谓保持独占，就是所有试图来获取这个锁的客户端，最终只有一个可以成功获得这把锁。通常的做法是把zk上的一个znode看作是一把锁，通过create znode的方式来实现。所有客户端都去创建 /distribute_lock 节点，最终成功创建的那个客户端也即拥有了这把锁。 控制时序，就是所有视图来获取这个锁的客户端，最终都是会被安排执行，只是有个全局时序了。做法和上面基本类似，只是这里 /distribute_lock 已经预先存在，客户端在它下面创建临时有序节点（这个可以通过节点的属性控制：CreateMode.EPHEMERAL_SEQUENTIAL来指定）。Zk的父节点（/distribute_lock）维持一份sequence,保证子节点创建的时序性，从而也形成了每个客户端的全局时序。 分布式队列队列方面，简单地讲有两种，一种是常规的先进先出队列，另一种是要等到队列成员聚齐之后的才统一按序执行。对于第一种先进先出队列，和分布式锁服务中的控制时序场景基本原理一致。 第二种队列其实是在FIFO队列的基础上作了一个增强。通常可以在 /queue 这个znode下预先建立一个/queue/num 节点，并且赋值为n（或者直接给/queue赋值n），表示队列大小，之后每次有队列成员加入后，就判断下是否已经到达队列大小，决定是否可以开始执行了。这种用法的典型场景是，分布式环境中，一个大任务Task A，需要在很多子任务完成（或条件就绪）情况下才能进行。这个时候，凡是其中一个子任务完成（就绪），那么就去 /taskList 下建立自己的临时时序节点（CreateMode.EPHEMERAL_SEQUENTIAL），当 /taskList 发现自己下面的子节点满足指定个数，就可以进行下一步按序进行处理了。 Zookeeper集群的角色 角色包括:Leader 和 follower （Observer）,只要集群中有半数以上节点存活，集群就能提供服务","tags":[{"name":"zookeeper","slug":"zookeeper","permalink":"http://dennis.pathto.top/tags/zookeeper/"},{"name":"distributed","slug":"distributed","permalink":"http://dennis.pathto.top/tags/distributed/"}]},{"title":"Tiled Map Editor地图编辑器","date":"2017-08-02T12:43:15.000Z","path":"2017/08/02/game-tiled-map/","text":"以前我也使用coco2d开发过一款射击类的游戏，不过地图都很丑陋。最近几天，某同事开发一个电影院座位的地图，看起来很炫，地图是使用 Tiled Map Editor地图编辑器来制作的。今天刚好有点时间，我也拿来玩玩。以后有需要的时候，也来搞搞。Tile地图是一款挺实用的工具，像小时候玩的坦克大战、冒险岛、魂斗罗、吞食天地等等的地图，都是可以使用 Tiled Map Editor地图编辑器来制作的。 下载http://www.mapeditor.org/ 界面 简单使用点新建点击新建 新图块 创建层这里创建了三个层，就使用默认那个层，然后将图块区域中的图块去填充你左边的地图 填充将对应的物品添加到对应的层上 导出.tmx文件文件-另存为：命名 确认即可 运行导出来额地图使用运行在程序中，如coco2d","tags":[{"name":"game","slug":"game","permalink":"http://dennis.pathto.top/tags/game/"},{"name":"map","slug":"map","permalink":"http://dennis.pathto.top/tags/map/"},{"name":"tools","slug":"tools","permalink":"http://dennis.pathto.top/tags/tools/"}]},{"title":"4.elasticsearch-head插件安装","date":"2017-07-30T09:18:10.000Z","path":"2017/07/30/elasticsearch-4-plugin/","text":"Elasticsearch-head插件安装篇 head插件说明 在以往的es版本有一个非常好用的插件叫head，可以方便的查看索引，集群等相关状态：5.0之后head安装支持目前只是支持插件的方式 下载和安装插件#git clone https://github.com/599166320/elasticsearch-head.git #cd elasticsearch-head #npm install #npm install -g grunt-cli #grunt server 注意：安装插件需要预先安装好nodejs和grunt,上面的安装过程可能比较久,取决于个人的网络 修改head的hostname 注意:修改hostname,是为了让其他机器的客户端浏览器也可以访问head,如果是本地访问，就不需要了 vi Gruntfile.js server: { options: { port: 9100, hostname: &apos;0.0.0.0&apos;, base: &apos;.&apos;, keepalive: true } } } 修改es的elasticsearch.yml文件添加下面的配置属性 http.cors.enabled: true http.cors.allow-origin: &quot;*&quot; 启动es/path/to/elasticsearch/bin/elasticsearch 启动head/path/to/elasticsearch-head/grunt server 访问head使用浏览器访问http://yourhostname:9100/ 通过head可以访问el集群的信息","tags":[{"name":"elasticsearch","slug":"elasticsearch","permalink":"http://dennis.pathto.top/tags/elasticsearch/"}]},{"title":"Web接口管理工具-RAP","date":"2017-07-28T15:59:58.000Z","path":"2017/07/28/tools-rap-for-web-api-management/","text":"为什么要使用RAP RAP主要用于web api的管理，简单方便.很适合复杂大型项目的团队管理，项目管理，文档编写、Mock.js、可视化、接口过渡、牛逼的文档历史版本、mock插件，支持本地部署。 如何获取RAP可以到官方github下载,如果不想为编译折腾，可以到我的github获取,https://github.com/599166320/myrap 编译RAP编译请阅读我的github README.md文件https://github.com/599166320/myrap 安装RAP1.在mysql数据库中执行初始化脚本 mysql -uroot -p123456 &lt; myrap/src/main/resources/database/initialize.sql 2.启动redis bin/redis-server 3.部署 删除tomcat/webapps全部文件,把编译得到的目标文件命名为ROOT.war,并且放到tomcat/webapps下,启动tomcat，通过http://localhost:8080 使用rap 注意:一定要完成上面的操作，否则有一些url没法正常访问 简单使用1.注册并且登录 2.创建团队 3.创建项目 4.添加,管理,测试接口","tags":[{"name":"tools","slug":"tools","permalink":"http://dennis.pathto.top/tags/tools/"}]},{"title":"jboss7解决url中文乱码遇到的坑","date":"2017-07-28T13:05:00.000Z","path":"2017/07/28/jboss-url-encoding-wenti/","text":"jboss7解决url中文乱码遇到的坑 ERROR [org.jboss.as.server] (Controller Boot Thread) JBAS015956: Caught exception during boot: org.jboss.as.controller.persistence.ConfigurationPersistenceException: JBAS014676: Failed to parse configurationCaused by: javax.xml.stream.XMLStreamException: ParseError at [row,col]:[94,9]Message: Unexpected element ‘{urn:jboss:domain:web:1.2}subsystem’ 花费了我一个晚上的时间，问了很多牛人也没有解决，通过认真查看standalone.xml元素system-properties,发现这是一个复数，我的猜想是，下面应该有很多元素，于是根据自己的猜想，找出其他system-properties,合并在一起，终于解决了这个问题.一开始我只是添加解决url get请求乱码的xml &lt;system-properties&gt; &lt;!-- URI Properties --&gt; &lt;property name=&quot;org.apache.catalina.connector.URI_ENCODING&quot; value=&quot;UTF-8&quot;/&gt; &lt;property name=&quot;org.apache.catalina.connector.USE_BODY_ENCODING_FOR_QUERY_STRING&quot; value=&quot;true&quot;/&gt; &lt;/system-properties&gt; 最终的解决方案是合并system-properties元素 &lt;system-properties&gt; &lt;!-- URI Properties --&gt; &lt;property name=&quot;org.apache.catalina.connector.URI_ENCODING&quot; value=&quot;UTF-8&quot;/&gt; &lt;property name=&quot;org.apache.catalina.connector.USE_BODY_ENCODING_FOR_QUERY_STRING&quot; value=&quot;true&quot;/&gt; &lt;property name=&quot;org.apache.coyote.http11.Http11Protocol.COMPRESSION&quot; value=&quot;on&quot;/&gt; &lt;/system-properties&gt;","tags":[{"name":"jboss","slug":"jboss","permalink":"http://dennis.pathto.top/tags/jboss/"}]},{"title":"在centos6.5系统下安装nodejs+npm+grunt","date":"2017-07-28T12:49:01.000Z","path":"2017/07/28/nodejs-npm-gunt-install/","text":"在centos6.5系统下安装nodejs+npm+grunt安装centos的yum源64位: rpm -ivh http://download.fedoraproject.org/pub/epel/6/x86_64/epel-release-6-8.noarch.rpm 32位: rpm -ivh http://download.fedoraproject.org/pub/epel/6/i386/epel-release-6-8.noarch.rpm 导入 key:rpm --import /etc/pki/rpm-gpg/RPM-GPG-KEY-EPEL-6 添加remi源rpm -ivh http://rpms.famillecollet.com/enterprise/remi-release-6.rpm rpm --import /etc/pki/rpm-gpg/RPM-GPG-KEY-remi 安装nodejssetup_5.x表示nodejs5 setup_6.x表示nodejs6 curl --silent --location https://rpm.nodesource.com/setup_5.x | bash - yum -y install nodejs 安装gruntnpm install -g grunt-cli","tags":[{"name":"nodejs","slug":"nodejs","permalink":"http://dennis.pathto.top/tags/nodejs/"}]},{"title":"《深入理解mybatis原理》 MyBatis缓存机制的设计与实现","date":"2017-07-28T02:20:54.000Z","path":"2017/07/28/mybatis-huancunshejiheshixian/","text":"本文主要讲解MyBatis非常棒的缓存机制的设计原理，给读者们介绍一下MyBatis的缓存机制的轮廓，然后会分别针对缓存机制中的方方面面展开讨论。 MyBatis将数据缓存设计成两级结构，分为一级缓存、二级缓存一级缓存是Session会话级别的缓存，位于表示一次数据库会话的SqlSession对象之中，又被称之为本地缓存。一级缓存是MyBatis内部实现的一个特性，用户不能配置，默认情况下自动支持的缓存，用户没有定制它的权利（不过这也不是绝对的，可以通过开发插件对它进行修改）；二级缓存是Application应用级别的缓存，它的是生命周期很长，跟Application的声明周期一样，也就是说它的作用范围是整个Application应用。 MyBatis中一级缓存和二级缓存的组织如下图所示： 一级缓存的工作机制一级缓存是Session会话级别的，一般而言，一个SqlSession对象会使用一个Executor对象来完成会话操作，Executor对象会维护一个Cache缓存，以提高查询性能。关于一级缓存的详细实现，我已经在《深入理解mybatis原理》 MyBatis的一级缓存实现详解 及使用注意事项 一文中有非常详尽的讨论，读者可以前去了解。 二级缓存的工作机制如上所言，一个SqlSession对象会使用一个Executor对象来完成会话操作，MyBatis的二级缓存机制的关键就是对这个Executor对象做文章。如果用户配置了”cacheEnabled=true”，那么MyBatis在为SqlSession对象创建Executor对象时，会对Executor对象加上一个装饰者：CachingExecutor，这时SqlSession使用CachingExecutor对象来完成操作请求。CachingExecutor对于查询请求，会先判断该查询请求在Application级别的二级缓存中是否有缓存结果，如果有查询结果，则直接返回缓存结果；如果缓存中没有，再交给真正的Executor对象来完成查询操作，之后CachingExecutor会将真正Executor返回的查询结果放置到缓存中，然后在返回给用户。MyBatis的二级缓存设计得比较灵活，你可以使用MyBatis自己定义的二级缓存实现；你也可以通过实现org.apache.ibatis.cache.Cache接口自定义缓存；也可以使用第三方内存缓存库，如Memcached等，这个我们会在后续的文章中详细讨论。","tags":[{"name":"mybatis","slug":"mybatis","permalink":"http://dennis.pathto.top/tags/mybatis/"}]},{"title":"关于","date":"2017-07-27T12:46:20.000Z","path":"2017/07/27/custom/","text":"个人简介一个很牛逼的人","tags":[{"name":"aboutMe","slug":"aboutMe","permalink":"http://dennis.pathto.top/tags/aboutMe/"}]},{"title":"git命令－切换分支","date":"2017-07-27T12:16:07.000Z","path":"2017/07/27/git-mingling-quehuangfenzhi/","text":"GIT一般有很多分支，我们CLONE到本地的时候一般都是MASTER分支，那么如何切换到其他分支呢？主要命令如下： 查看远程分支git branch -a 我在mxnet根目录下运行以上命令： ~/mxnet$ git branch -a * master remotes/origin/HEAD -&gt; origin/master remotes/origin/master remotes/origin/nnvm remotes/origin/piiswrong-patch-1 remotes/origin/v0.9rc1 可以看到，我们现在在master分支下 查看本地分支~/mxnet$ git branch * master 切换分支$ git checkout -b v0.9rc1 origin/v0.9rc1 Branch v0.9rc1 set up to track remote branch v0.9rc1 from origin. Switched to a new branch &apos;v0.9rc1&apos; ＃已经切换到v0.9rc1分支了 $ git branch master * v0.9rc1 ＃切换回master分支 $ git checkout master Switched to branch &apos;master&apos; Your branch is up-to-date with &apos;origin/master&apos;.","tags":[{"name":"git","slug":"git","permalink":"http://dennis.pathto.top/tags/git/"}]},{"title":"openstack之swift原理和架构","date":"2017-07-27T10:52:32.000Z","path":"2017/07/27/openstack-swift-yuanlijiagou/","text":"——Openstack Swift 开源云存储技术解析 OpenStack Swift 开源项目提供了弹性可伸缩、高可用的分布式对象存储服务，适合存储大规模非结构化数据。本文将深入介绍 Swift 的基本设计原理、对称式的系统架构和 RESTful API。 背景与概览Swift 最初是由 Rackspace 公司开发的高可用分布式对象存储服务，并于 2010 年贡献给 OpenStack 开源社区作为其最初的核心子项目之一，为其 Nova 子项目提供虚机镜像存储服务。Swift 构筑在比较便宜的标准硬件存储基础设施之上，无需采用 RAID（磁盘冗余阵列），通过在软件层面引入一致性散列技术和数据冗余性，牺牲一定程度的数据一致性来达到高可用性和可伸缩性，支持多租户模式、容器和对象读写操作，适合解决互联网的应用场景下非结构化数据存储问题。 此项目是基于 Python 开发的，采用 Apache 2.0 许可协议，可用来开发商用系统。 基本原理一致性散列（Consistent Hashing)面对海量级别的对象，需要存放在成千上万台服务器和硬盘设备上，首先要解决寻址问题，即如何将对象分布到这些设备地址上。Swift 是基于一致性散列技术，通过计算可将对象均匀分布到虚拟空间的虚拟节点上，在增加或删除节点时可大大减少需移动的数据量；虚拟空间大小通常采用 2 的 n 次幂，便于进行高效的移位操作；然后通过独特的数据结构 Ring（环）再将虚拟节点映射到实际的物理存储设备上，完成寻址过程。图 1. 一致性散列 如图 1 中所示，以逆时针方向递增的散列空间有 4 个字节长共 32 位，整数范围是[0~232-1]；将散列结果右移 m 位，可产生 232-m个虚拟节点，例如 m=29 时可产生 8 个虚拟节点。在实际部署的时候需要经过仔细计算得到合适的虚拟节点数，以达到存储空间和工作负载之间的平衡。 数据一致性模型（Consistency Model）按照 Eric Brewer 的 CAP（Consistency，Availability，Partition Tolerance）理论，无法同时满足 3 个方面，Swift 放弃严格一致性（满足 ACID 事务级别），而采用最终一致性模型（Eventual Consistency），来达到高可用性和无限水平扩展能力。为了实现这一目标，Swift 采用 Quorum 仲裁协议(Quorum 有法定投票人数的含义)： （1）定义：N：数据的副本总数；W：写操作被确认接受的副本数量；R：读操作的副本数量 （2）强一致性：R+W&gt;N，以保证对副本的读写操作会产生交集，从而保证可以读取到最新版本；如果 W=N，R=1，则需要全部更新，适合大量读少量写操作场景下的强一致性；如果 R=N，W=1，则只更新一个副本，通过读取全部副本来得到最新版本，适合大量写少量读场景下的强一致性。 （3）弱一致性：R+W&lt;=N，如果读写操作的副本集合不产生交集，就可能会读到脏数据；适合对一致性要求比较低的场景。 Swift 针对的是读写都比较频繁的场景，所以采用了比较折中的策略，即写操作需要满足至少一半以上成功 W &gt;N/2，再保证读操作与写操作的副本集合至少产生一个交集，即 R+W&gt;N。Swift 默认配置是 N=3，W=2&gt;N/2，R=1 或 2，即每个对象会存在 3 个副本，这些副本会尽量被存储在不同区域的节点上；W=2 表示至少需要更新 2 个副本才算写成功；当 R=1 时意味着某一个读操作成功便立刻返回，此种情况下可能会读取到旧版本（弱一致性模型）；当 R=2 时，需要通过在读操作请求头中增加 x-newest=true 参数来同时读取 2 个副本的元数据信息，然后比较时间戳来确定哪个是最新版本（强一致性模型）；如果数据出现了不一致，后台服务进程会在一定时间窗口内通过检测和复制协议来完成数据同步，从而保证达到最终一致性。如图 2 所示： 图 2. Quorum 协议示例 环的数据结构环是为了将虚拟节点（分区）映射到一组物理存储设备上，并提供一定的冗余度而设计的，其数据结构由以下信息组成： 存储设备列表、设备信息包括唯一标识号（id）、区域号（zone）、权重（weight）、IP 地址（ip）、端口（port）、设备名称（device）、元数据（meta）。分区到设备映射关系（replica2part2dev_id 数组)计算分区号的位移(part_shift 整数，即图 1 中的 m)以查找一个对象的计算过程为例： 图 3. 环的数据机构 层次结构 account/container/object 作为键，使用 MD5 散列算法得到一个散列值，对该散列值的前 4 个字节进行右移操作得到分区索引号，移动位数由上面的 part_shift 设置指定；按照分区索引号在分区到设备映射表（replica2part2dev_id）里查找该对象所在分区的对应的所有设备编号，这些设备会被尽量选择部署在不同区域（Zone）内，区域只是个抽象概念，它可以是某台机器，某个机架，甚至某个建筑内的机群，以提供最高级别的冗余性，建议至少部署 5 个区域；权重参数是个相对值，可以来根据磁盘的大小来调节，权重越大表示可分配的空间越多，可部署更多的分区。 Swift 为账户，容器和对象分别定义了的环，查找账户和容器的是同样的过程。 数据模型Swift 采用层次数据模型，共设三层逻辑结构：Account/Container/Object（即账户/容器/对象)，每层节点数均没有限制，可以任意扩展。这里的账户和个人账户不是一个概念，可理解为租户，用来做顶层的隔离机制，可以被多个个人账户所共同使用；容器代表封装一组对象，类似文件夹或目录；叶子节点代表对象，由元数据和内容两部分组成，如图 4 所示： 图 4. Swift 数据模型 系统架构 Swift 采用完全对称、面向资源的分布式系统架构设计，所有组件都可扩展，避免因单点失效而扩散并影响整个系统运转；通信方式采用非阻塞式 I/O 模式，提高了系统吞吐和响应能力。 图 5. Swift 系统架构 Swift 组件包括： 代理服务（Proxy Server）：对外提供对象服务 API，会根据环的信息来查找服务地址并转发用户请求至相应的账户、容器或者对象服务；由于采用无状态的 REST 请求协议，可以进行横向扩展来均衡负载。认证服务（Authentication Server）：验证访问用户的身份信息，并获得一个对象访问令牌（Token），在一定的时间内会一直有效；验证访问令牌的有效性并缓存下来直至过期时间。缓存服务（Cache Server）：缓存的内容包括对象服务令牌，账户和容器的存在信息，但不会缓存对象本身的数据；缓存服务可采用 Memcached 集群，Swift 会使用一致性散列算法来分配缓存地址。账户服务（Account Server）：提供账户元数据和统计信息，并维护所含容器列表的服务，每个账户的信息被存储在一个 SQLite 数据库中。容器服务（Container Server）：提供容器元数据和统计信息，并维护所含对象列表的服务，每个容器的信息也存储在一个 SQLite 数据库中。对象服务（Object Server）：提供对象元数据和内容服务，每个对象的内容会以文件的形式存储在文件系统中，元数据会作为文件属性来存储，建议采用支持扩展属性的 XFS 文件系统。复制服务（Replicator）：会检测本地分区副本和远程副本是否一致，具体是通过对比散列文件和高级水印来完成，发现不一致时会采用推式（Push）更新远程副本，例如对象复制服务会使用远程文件拷贝工具 rsync 来同步；另外一个任务是确保被标记删除的对象从文件系统中移除。更新服务（Updater）：当对象由于高负载的原因而无法立即更新时，任务将会被序列化到在本地文件系统中进行排队，以便服务恢复后进行异步更新；例如成功创建对象后容器服务器没有及时更新对象列表，这个时候容器的更新操作就会进入排队中，更新服务会在系统恢复正常后扫描队列并进行相应的更新处理。审计服务（Auditor）：检查对象，容器和账户的完整性，如果发现比特级的错误，文件将被隔离，并复制其他的副本以覆盖本地损坏的副本；其他类型的错误会被记录到日志中。账户清理服务（Account Reaper）：移除被标记为删除的账户，删除其所包含的所有容器和对象。API Swift 通过 Proxy Server 向外提供基于 HTTP 的 REST 服务接口，对账户、容器和对象进行 CRUD 等操作。在访问 Swift 服务之前，需要先通过认证服务获取访问令牌，然后在发送的请求中加入头部信息 X-Auth-Token。下面是请求返回账户中的容器列表的示例： GET /v1/&lt;account&gt; HTTP/1.1 Host: storage.swift.com X-Auth-Token: eaaafd18-0fed-4b3a-81b4-663c99ec1cbb 响应头部信息中包含状态码 200，容器列表包含在响应体中： HTTP/1.1 200 Ok Date: Thu, 07 Jan 2013 18:57:07 GMT Server: Apache Content-Type: text/plain; charset=UTF-8 Content-Length: 32 images movies documents backups 详细的 API 规范可以参考开发者指南。应用开发可采用 Swift 项目本身已经包含的 Python 的绑定实现；如果使用其它编程语言，可以参考 Rackspace 兼容 Swift 的 Cloud Files API，支持 Java，.Net，Ruby，PHP 等语言绑定。","tags":[{"name":"openstack","slug":"openstack","permalink":"http://dennis.pathto.top/tags/openstack/"},{"name":"swift","slug":"swift","permalink":"http://dennis.pathto.top/tags/swift/"}]},{"title":"openstack介绍","date":"2017-07-27T10:44:06.000Z","path":"2017/07/27/openstackjieshao/","text":"经常有朋友让我介绍Openstack，我就干脆写一篇Openstack的组件介绍，也算是总结一下。马上2012年就要结束了，也是到该总结的时候。去年现在的Openstack，其实官方的Keystone和Horizon还没法很好的一起工作。 我个人的理解：下面的组件全部工作良好，那么基本的一个IAAS就算比较完整，这些功能都是目前Rackspace和linode都有的。 目前官方认同的孵化项目，都会放到 https://github.com/stackforge 大家可以通过wiki的变化，了解项目目前的情况：http://wiki.openstack.org/RecentChanges 如果大家希望详细了解项目进度，可以阅读他们每次开会的纪要，包括各种问题的讨论，非常有意思：http://eavesdrop.openstack.org/meetings/ 如果希望快速了解，可以直接看这个http://eavesdrop.openstack.org/meetings/project/ 所有的项目大概进度都会在这里讨论。 Nova这个是最核心的，Nova最开始的时候，可以说是一套虚拟化管理程序，还可以管理网络和存储。不过从Essex版本后，Nova开始做减法，和网络相关的内容，包括安全组，交给Quantum负责，存储相关的交给Cinder负责。调度有关的内容，会交给新的项目Marconi。 以前还有一个nova common，这其实是各个组件都使用相同的东西，现在也专门成立一个项目：oslo，已经是核心项目。 未来Nova对各种Hyperv的支持是有差异的，KVM和XEN，基本是最好的。微软的Hyper-V算是很不错，微软投入再研发。刚才朋友还专门提到一点：就是未来计算节点，不直接查询数据库，而是通过rpc的方式，据说这是一大进步。 Nova的稳定性，其实取决于libvirt，qemu，希望未来可以能更加稳定。功能现在其实已经不是大问题。 keystone这是提供身份认证和授权的组件。任何系统，身份认证和授权，其实都比较复杂。尤其Openstack 那么庞大的项目，每个组件都需要使用统一认证和授权。 目前keystone 要做的东西其实还是很多。没法基于角色的授权，web管理用户等。当然你如果希望实现使用动态令牌认证，多因素认证，LDAP集成，这都是未来版本需要实现的功能，这些功能都已经在计划中。 目前好像要实现keystone的高可用，还是比较困难，这个就让社区慢慢解决吧。大规模部署，这也会是瓶颈。 Glance这是镜像管理。功能其实相对比较简单。不过Glance后端的存储的支持，其实一直到Folsom的版本，Glance对swift的支持，才算是比较完善。 目前Glance的镜像存储，支持本地存储，NFS，swift，sheepdog和Ceph，基本是够用了。 目前Glance的最大需求就是多个数据中心的镜像管理，如何复制，不过这个功能已经基本实现。还有就是租户私有的image管理，这些目前功能都已经实现。 个人感觉：Glance后续基本就是一个bug修复，稳定的阶段。 Quantum这是网络管理的组件，也是重头戏，Openstack的未来，基本都要靠quantum。上面介绍nova的时候，说过网络相关的内容，都会交给Quantum。不过Quantum的开发进度不是太如人意。Flosom规划实现功能，到Grizzly才实现。未来nova network的代码清理，估计到H版本都不见得可以实现。 Quantum 后端可以是商业产品或者开源。开源产品支持Openvswitch，和linux bridge。网络设备厂商都在积极参与，让他们的产品支持Quantum，目前思科，锐捷已经实现支持。 比较悲观的估计：quantum要完全满足生产的需求，例如带宽限制，mutilhost等功能，很可能需要等到2014年的I版本，真的考验耐心。 如果你关注Quantum的话，就会发现目前还是在起步阶段，无论是bug还是功能，都是非常多。 Cinder这是存储管理的组件。一直以来，很多人都很纠结AWS的EBS的实现。Openstack也终于推出了自己的存储管理组件。 Cinder存储管理主要是指虚拟机的存储管理。目前支持开源和商业化产品。开源的sheepdog，Ceph等。商业存储的支持，目前ＩＢＭ是最积极的。未来如果商业存储厂商都支持Cinder，对Openstack的商业化还是非常有利的。 对于企业来说，使用分布式作为虚拟机的存储，并不能真正节省成本，维护一套分布式存储，成本还是很高的。目前虚拟机的各种高可用，备份的问题，其实都可以把问题交给商业存储厂商来解决。 Lbaas这是实现负载均衡的项目。现在linode，Rackspace，都提供了负载均衡的服务，有了这个服务，你才有可能实现所谓的弹性扩展。这个组件是Mirantis公司和思科合作开发的。目前这个项目集成在Quantum里，不过基本算是一个独立的组件。 Lbaas后端可以是各种商业产品和开源产品。F5，Ngnix，Haproxy，LVS 为了发布的Grizzly，你应该有机会在Dashboard里设置虚拟机的负载均衡。 Horizon严格意义来说，Horizon不会为Openstack 增加一个功能，他更多的是一个演示，demo。不过对于很多用户来说，了解Openstack基本都是从Horizon，dashboard开始。从这个角度来看，他在Openstack各个项目里，显得非常重要。 Horizon的开发者，应该是最累的。需要和各个项目打角度。每个项目的功能很多都是需要通过Dashboard来展现。 大家需要注意的是：Horizon只是使用了Openstack部分API功能，很多功能，你可以根据你的需求去实现。 Swift这是对象存储的组件。对于大部分用户来说，swift不是必须的。你只有存储数量到一定级别，而且是非结构化数据才有这样的需求。很多人都问一个相同的问题：是否可以把虚拟机的存储放在swift上。简单回答：不行。你需要搞明白对象存储是干啥，擅长那些地方，那些是不行的。 swift是Openstack所有组件了最成熟的,可以在线升级版本,各种版本可以混合在一起,也就是说,1.75版本的swift可以和1.48的在一个群集里.这个是很难得的. oslo这个项目其实就是把所有组件需要用到相同的东西，集中起来，以前叫nova common，估计感觉不贴切，现在单独成立一个项目。日后大家开发新的组件，估计都需要用到oslo。 Ceilometer这是实现监控和计量的组件。这应该算是Grizzly的孵化项目。对他的了解其实很少。在Grizzly版本里，你应该可以在Dashboard里看到这个组件。 监控和计费一直是一个难题，尤其用户希望知道cpu和内存的使用情况。看看他如何解决这个问题。到时候看看同事如何调用api来解决监控和计量的问题。解决计量，计费就简单的。 http://wiki.openstack.org/Ceilometer Heat这个项目是要解决虚拟机的软件部署的问题。你的虚拟机创建好，os准备好，你还需要做很多配置才能使用，如何能实现把所有繁琐的操作简化呢？亚马逊上有一个专门的工具：AWS cloudformation。目前Openstack上，希望通过Heat来实现类似的功能。 关于这个项目，还是有很多争议。不过这个项目是Redhat发起。他们的功力是不容置疑，等Openstack成熟后，这个项目的重要性就会体现出来。 http://wiki.openstack.org/Heat 真的要实现弹性扩展，自动部署，都是需要指望这个。目前Heat已经成为孵化项目 下面的项目，基本都还是在讨论阶段，不过成为孵化项目的可能性很大。 Moniker这是实现dns功能的组件。其实如果你用过AWS，你就知道这个功能是必不可少。新浪目前的已经加上了这个功能，每个虚拟机，都会自动有一个dns记录。 https://github.com/stackforge/moniker 估计集成到Dashboard里，还是需要等待一段时间啊。目前该项目开发还是非常积极。 marconi此项目用于解决openstack 消息队列的扩展问题。据说这是Rackspce推出的项目，就是为了解决他们生产中遇到消息队列的问题。 Marconi – Message Bus for OpenStack","tags":[{"name":"openstack","slug":"openstack","permalink":"http://dennis.pathto.top/tags/openstack/"}]}]